[DatabaseConnectionString]
instance_name: gabsam
user: tpcds1
host: 192.168.202.222
service: gabsam
port: 1521
password: tpc

[EnvironmentSettings]
# Boolean determining whether script messages are logged to disk
write_to_disk: true
# Booleans determining whether script messages are logged to screen
write_to_screen: true
# Log file name where messages will be persisted (if write_to_disk is enabled)
log_file_name: msg_log

[SparkContext]
app_name: ICS5200
master: local
spark_executor_memory: 1g
spark_driver_memory: 1g
spark_max_result_size: 1g
# Number of cores dedicated to Spark Executors
spark_executor_cores: 1
spark_cores_max: 30
# Number of RDD partitions which will be manifested by the Spark Context. This value should be the same as that of Spark
# executors.
spark_rdd_partitions: 64
# Number of allocated parallelism
spark_default_parallelism: 64
# Number of allocated shuffle partitions
spark_shuffle_partitions: 64
# Determines whether Spark will log context/runtime data
spark_logConf: false

[DataGeneration]
# Path in which TPC data is generated in
data_generated_directory: /mnt/raid5/DataGeneration_ICS5200
# Path in which TPC sq; is generated in
sql_generated_directory: /home/gabriels/ICS5200/src/sql/Runtime
# Determines whether data is generated for TPC-DS suite
tpcds_data_generation: false
# Determines whether data is generated for TPC-E suite
tpce_data_generation: false
# Determines whether sql is generated for TPC-DS suite
tpcds_sql_generation: true
# Determines whether sql is generated for TPC-E suite
tpce_sql_generation: false
# Size in Gigabytes for generated data
data_size: 1
# Degree of parallellism used for data generation
parallel_degree: 10

[DataLoading]
# Determines whether data is loaded into database instance for TPC-DS suite
tpcds_loading: true
# Determines whether data is loaded into database instance for TPC-E suite
tpce_loading: false

[WorkloadGeneration]
# Determines time of workload execution (for the largest time window), defined as a decimal value eg:(2.25 - 2 hours, 15 minutes)
outer_workload_time_window: 1.5
# Determines time of workload execution (for the smallest time windows), defined as a decimal value eg:(2.25 - 2 hours, 15 minutes).
# Recommended to be a factor of the 'outer_workload_time_length' parameter, so as to fit perfectly these time slots
inner_workload_time_window: 0.5
# Determines range from which eligable sql can be used for a particular workload
sql_sample_range: 1-104
# Determines range from which eligable dml can be used for a particular workload
dml_sample_range: 1-43
# Determines random number of executed queries for workload generation eg: (4-6) equates to between 4 and 6 random query executions
sql_sample: 4-6
# Determines random number of executed dml for workload generation eg: (4-6) equates to between 4 and 6 random query executions
num_dml: 4-6
# Determines random time interval (rapidness) with which the workload staggers itself eg:(0.05-0.1) equates to a query executed randomized between 3mins-6mins
# This parameter is used per inner time window
outer_interval: 0.1-0.2
# Determines random time interval (rapidness) with which the workload staggers itself eg:(0.05-0.1) equates to a query executed randomized between 3mins-6mins
# This parameter is used per inner time window
inner_interval: 0.05-0.1
# Number of repetitions that each query can be executed up to per inner_work time window
repeats_degree: 2
# Parallel Degree - maximum number of allowed parallel executions per small time window
parallel_degree: 2