2018-08-11 16:11:13: Connected to database [gabsam] with user [tpcds1]
2018-08-11 16:11:13: Connection pool instantiated with [1] connections
2018-08-11 16:11:19: Gracefully disabled Spark nodes..
2018-08-11 16:11:23: Enabled master node..
2018-08-11 16:11:26: Enabled slave node..
2018-08-11 16:11:31: ('spark.cores.max', '20')
2018-08-11 16:11:31: ('spark.executor.memory', '2g')
2018-08-11 16:11:31: ('spark.driver.host', 'cisk.rs2.com')
2018-08-11 16:11:31: ('spark.executor.id', 'driver')
2018-08-11 16:11:31: ('spark.driver.port', '35976')
2018-08-11 16:11:31: ('spark.python.worker.reuse', 'True')
2018-08-11 16:11:31: ('spark.app.id', 'app-20180811161130-0000')
2018-08-11 16:11:31: ('spark.driver.maxResultSize', '1g')
2018-08-11 16:11:31: ('spark.default.parallelism', '80')
2018-08-11 16:11:31: ('spark.sql.shuffle.partitions', '80')
2018-08-11 16:11:31: ('spark.executor.instances', '20')
2018-08-11 16:11:31: ('spark.logConf', 'False')
2018-08-11 16:11:31: ('spark.rdd.compress', 'True')
2018-08-11 16:11:31: ('spark.driver.memory', '2g')
2018-08-11 16:11:31: ('spark.serializer.objectStreamReset', '100')
2018-08-11 16:11:31: ('spark.executor.cores', '1')
2018-08-11 16:11:31: ('spark.master', 'spark://cisk.rs2.com:7077')
2018-08-11 16:11:31: ('spark.submit.deployMode', 'client')
2018-08-11 16:11:31: ('spark.executorEnv.PYTHONPATH', '$PYTHONPATH:/home/gabriels/ICS5200')
2018-08-11 16:11:31: ('spark.ui.showConsoleProgress', 'true')
2018-08-11 16:11:31: ('spark.app.name', 'ICS5200')
2018-08-11 16:12:32: Connected to database [gabsam] with user [tpcds1]
2018-08-11 16:12:32: Connection pool instantiated with [1] connections
2018-08-11 16:12:37: Gracefully disabled Spark nodes..
2018-08-11 16:12:39: Enabled master node..
2018-08-11 16:12:42: Enabled slave node..
2018-08-11 16:12:45: ('spark.cores.max', '20')
2018-08-11 16:12:45: ('spark.executor.memory', '2g')
2018-08-11 16:12:45: ('spark.driver.host', 'cisk.rs2.com')
2018-08-11 16:12:45: ('spark.app.id', 'app-20180811161244-0000')
2018-08-11 16:12:45: ('spark.driver.port', '33504')
2018-08-11 16:12:45: ('spark.executor.id', 'driver')
2018-08-11 16:12:45: ('spark.python.worker.reuse', 'True')
2018-08-11 16:12:45: ('spark.driver.maxResultSize', '1g')
2018-08-11 16:12:45: ('spark.default.parallelism', '80')
2018-08-11 16:12:45: ('spark.sql.shuffle.partitions', '80')
2018-08-11 16:12:45: ('spark.executor.instances', '20')
2018-08-11 16:12:45: ('spark.logConf', 'False')
2018-08-11 16:12:45: ('spark.rdd.compress', 'True')
2018-08-11 16:12:45: ('spark.driver.memory', '2g')
2018-08-11 16:12:45: ('spark.serializer.objectStreamReset', '100')
2018-08-11 16:12:45: ('spark.executor.cores', '1')
2018-08-11 16:12:45: ('spark.master', 'spark://cisk.rs2.com:7077')
2018-08-11 16:12:45: ('spark.submit.deployMode', 'client')
2018-08-11 16:12:45: ('spark.executorEnv.PYTHONPATH', '$PYTHONPATH:/home/gabriels/ICS5200')
2018-08-11 16:12:45: ('spark.ui.showConsoleProgress', 'true')
2018-08-11 16:12:45: ('spark.app.name', 'ICS5200')
2018-08-11 16:15:03: Connected to database [gabsam] with user [tpcds1]
2018-08-11 16:15:03: Connection pool instantiated with [1] connections
2018-08-11 16:15:07: Gracefully disabled Spark nodes..
2018-08-11 16:15:09: Enabled master node..
2018-08-11 16:15:12: Enabled slave node..
2018-08-11 16:15:14: ('spark.cores.max', '20')
2018-08-11 16:15:14: ('spark.executor.memory', '2g')
2018-08-11 16:15:14: ('spark.app.id', 'app-20180811161514-0000')
2018-08-11 16:15:14: ('spark.driver.host', 'cisk.rs2.com')
2018-08-11 16:15:14: ('spark.driver.port', '29460')
2018-08-11 16:15:14: ('spark.executor.id', 'driver')
2018-08-11 16:15:14: ('spark.python.worker.reuse', 'True')
2018-08-11 16:15:14: ('spark.driver.maxResultSize', '1g')
2018-08-11 16:15:14: ('spark.default.parallelism', '80')
2018-08-11 16:15:14: ('spark.sql.shuffle.partitions', '80')
2018-08-11 16:15:14: ('spark.executor.instances', '20')
2018-08-11 16:15:14: ('spark.logConf', 'False')
2018-08-11 16:15:14: ('spark.rdd.compress', 'True')
2018-08-11 16:15:14: ('spark.driver.memory', '2g')
2018-08-11 16:15:14: ('spark.serializer.objectStreamReset', '100')
2018-08-11 16:15:14: ('spark.executor.cores', '1')
2018-08-11 16:15:14: ('spark.master', 'spark://cisk.rs2.com:7077')
2018-08-11 16:15:14: ('spark.submit.deployMode', 'client')
2018-08-11 16:15:14: ('spark.executorEnv.PYTHONPATH', '$PYTHONPATH:/home/gabriels/ICS5200')
2018-08-11 16:15:14: ('spark.ui.showConsoleProgress', 'true')
2018-08-11 16:15:14: ('spark.app.name', 'ICS5200')
2018-08-11 16:18:31: Connected to database [gabsam] with user [tpcds1]
2018-08-11 16:18:31: Connection pool instantiated with [1] connections
2018-08-11 16:18:35: Gracefully disabled Spark nodes..
2018-08-11 16:18:37: Enabled master node..
2018-08-11 16:18:40: Enabled slave node..
2018-08-11 16:18:43: ('spark.cores.max', '20')
2018-08-11 16:18:43: ('spark.executor.memory', '2g')
2018-08-11 16:18:43: ('spark.driver.host', 'cisk.rs2.com')
2018-08-11 16:18:43: ('spark.executor.id', 'driver')
2018-08-11 16:18:43: ('spark.python.worker.reuse', 'True')
2018-08-11 16:18:43: ('spark.driver.maxResultSize', '1g')
2018-08-11 16:18:43: ('spark.default.parallelism', '80')
2018-08-11 16:18:43: ('spark.sql.shuffle.partitions', '80')
2018-08-11 16:18:43: ('spark.executor.instances', '20')
2018-08-11 16:18:43: ('spark.logConf', 'False')
2018-08-11 16:18:43: ('spark.rdd.compress', 'True')
2018-08-11 16:18:43: ('spark.driver.memory', '2g')
2018-08-11 16:18:43: ('spark.serializer.objectStreamReset', '100')
2018-08-11 16:18:43: ('spark.app.id', 'app-20180811161842-0000')
2018-08-11 16:18:43: ('spark.executor.cores', '1')
2018-08-11 16:18:43: ('spark.master', 'spark://cisk.rs2.com:7077')
2018-08-11 16:18:43: ('spark.submit.deployMode', 'client')
2018-08-11 16:18:43: ('spark.driver.port', '24152')
2018-08-11 16:18:43: ('spark.executorEnv.PYTHONPATH', '$PYTHONPATH:/home/gabriels/ICS5200')
2018-08-11 16:18:43: ('spark.ui.showConsoleProgress', 'true')
2018-08-11 16:18:43: ('spark.app.name', 'ICS5200')
2018-08-11 16:19:48: Connected to database [gabsam] with user [tpcds1]
2018-08-11 16:19:48: Connection pool instantiated with [1] connections
2018-08-11 16:19:52: Gracefully disabled Spark nodes..
2018-08-11 16:19:55: Enabled master node..
2018-08-11 16:19:58: Enabled slave node..
2018-08-11 16:20:00: ('spark.cores.max', '20')
2018-08-11 16:20:00: ('spark.executor.memory', '2g')
2018-08-11 16:20:00: ('spark.executor.id', 'driver')
2018-08-11 16:20:00: ('spark.python.worker.reuse', 'True')
2018-08-11 16:20:00: ('spark.driver.maxResultSize', '1g')
2018-08-11 16:20:00: ('spark.default.parallelism', '80')
2018-08-11 16:20:00: ('spark.sql.shuffle.partitions', '80')
2018-08-11 16:20:00: ('spark.executor.instances', '20')
2018-08-11 16:20:00: ('spark.app.id', 'app-20180811162000-0000')
2018-08-11 16:20:00: ('spark.logConf', 'False')
2018-08-11 16:20:00: ('spark.rdd.compress', 'True')
2018-08-11 16:20:00: ('spark.driver.host', 'tempvcenter.rs2.com')
2018-08-11 16:20:00: ('spark.driver.memory', '2g')
2018-08-11 16:20:00: ('spark.serializer.objectStreamReset', '100')
2018-08-11 16:20:00: ('spark.executor.cores', '1')
2018-08-11 16:20:00: ('spark.master', 'spark://cisk.rs2.com:7077')
2018-08-11 16:20:00: ('spark.submit.deployMode', 'client')
2018-08-11 16:20:00: ('spark.driver.port', '32976')
2018-08-11 16:20:00: ('spark.executorEnv.PYTHONPATH', '$PYTHONPATH:/home/gabriels/ICS5200')
2018-08-11 16:20:00: ('spark.ui.showConsoleProgress', 'true')
2018-08-11 16:20:00: ('spark.app.name', 'ICS5200')
2018-08-11 16:20:33: Connected to database [gabsam] with user [tpcds1]
2018-08-11 16:20:33: Connection pool instantiated with [1] connections
2018-08-11 16:20:36: Gracefully disabled Spark nodes..
2018-08-11 16:20:38: Enabled master node..
2018-08-11 16:20:41: Enabled slave node..
2018-08-11 16:20:44: ('spark.cores.max', '20')
2018-08-11 16:20:44: ('spark.executor.memory', '2g')
2018-08-11 16:20:44: ('spark.driver.host', 'cisk.rs2.com')
2018-08-11 16:20:44: ('spark.app.id', 'app-20180811162043-0000')
2018-08-11 16:20:44: ('spark.executor.id', 'driver')
2018-08-11 16:20:44: ('spark.python.worker.reuse', 'True')
2018-08-11 16:20:44: ('spark.driver.maxResultSize', '1g')
2018-08-11 16:20:44: ('spark.default.parallelism', '80')
2018-08-11 16:20:44: ('spark.sql.shuffle.partitions', '80')
2018-08-11 16:20:44: ('spark.executor.instances', '20')
2018-08-11 16:20:44: ('spark.logConf', 'False')
2018-08-11 16:20:44: ('spark.rdd.compress', 'True')
2018-08-11 16:20:44: ('spark.driver.memory', '2g')
2018-08-11 16:20:44: ('spark.driver.port', '20117')
2018-08-11 16:20:44: ('spark.serializer.objectStreamReset', '100')
2018-08-11 16:20:44: ('spark.executor.cores', '1')
2018-08-11 16:20:44: ('spark.master', 'spark://cisk.rs2.com:7077')
2018-08-11 16:20:44: ('spark.submit.deployMode', 'client')
2018-08-11 16:20:44: ('spark.executorEnv.PYTHONPATH', '$PYTHONPATH:/home/gabriels/ICS5200')
2018-08-11 16:20:44: ('spark.ui.showConsoleProgress', 'true')
2018-08-11 16:20:44: ('spark.app.name', 'ICS5200')
2018-08-11 16:20:44: Starting generation of report..
2018-08-11 16:20:45: Report generation complete
2018-08-11 16:20:45: Script Complete!
-------------------------------------
2018-08-11 16:38:39: Connected to database [gabsam] with user [tpcds1]
2018-08-11 16:38:39: Connection pool instantiated with [1] connections
2018-08-11 16:38:42: Gracefully disabled Spark nodes..
2018-08-11 16:38:45: Enabled master node..
2018-08-11 16:38:47: Enabled slave node..
2018-08-11 16:38:50: ('spark.cores.max', '20')
2018-08-11 16:38:50: ('spark.executor.memory', '2g')
2018-08-11 16:38:50: ('spark.driver.port', '19165')
2018-08-11 16:38:50: ('spark.executor.id', 'driver')
2018-08-11 16:38:50: ('spark.python.worker.reuse', 'True')
2018-08-11 16:38:50: ('spark.driver.maxResultSize', '1g')
2018-08-11 16:38:50: ('spark.default.parallelism', '80')
2018-08-11 16:38:50: ('spark.sql.shuffle.partitions', '80')
2018-08-11 16:38:50: ('spark.executor.instances', '20')
2018-08-11 16:38:50: ('spark.logConf', 'False')
2018-08-11 16:38:50: ('spark.rdd.compress', 'True')
2018-08-11 16:38:50: ('spark.driver.host', 'tempvcenter.rs2.com')
2018-08-11 16:38:50: ('spark.driver.memory', '2g')
2018-08-11 16:38:50: ('spark.serializer.objectStreamReset', '100')
2018-08-11 16:38:50: ('spark.app.id', 'app-20180811163849-0000')
2018-08-11 16:38:50: ('spark.executor.cores', '1')
2018-08-11 16:38:50: ('spark.master', 'spark://cisk.rs2.com:7077')
2018-08-11 16:38:50: ('spark.submit.deployMode', 'client')
2018-08-11 16:38:50: ('spark.executorEnv.PYTHONPATH', '$PYTHONPATH:/home/gabriels/ICS5200')
2018-08-11 16:38:50: ('spark.ui.showConsoleProgress', 'true')
2018-08-11 16:38:50: ('spark.app.name', 'ICS5200')
2018-08-11 16:38:51: Starting generation of report..
2018-08-11 16:38:51: Skipped record due to following exception: [ORA-00904: "TPC_TYPE": invalid identifier]
2018-08-11 16:40:06: Connected to database [gabsam] with user [tpcds1]
2018-08-11 16:40:06: Connection pool instantiated with [1] connections
2018-08-11 16:40:10: Gracefully disabled Spark nodes..
2018-08-11 16:40:12: Enabled master node..
2018-08-11 16:40:15: Enabled slave node..
2018-08-11 16:40:17: ('spark.cores.max', '20')
2018-08-11 16:40:17: ('spark.executor.memory', '2g')
2018-08-11 16:40:17: ('spark.driver.host', 'cisk.rs2.com')
2018-08-11 16:40:17: ('spark.executor.id', 'driver')
2018-08-11 16:40:17: ('spark.python.worker.reuse', 'True')
2018-08-11 16:40:17: ('spark.driver.maxResultSize', '1g')
2018-08-11 16:40:17: ('spark.default.parallelism', '80')
2018-08-11 16:40:17: ('spark.sql.shuffle.partitions', '80')
2018-08-11 16:40:17: ('spark.app.id', 'app-20180811164017-0000')
2018-08-11 16:40:17: ('spark.executor.instances', '20')
2018-08-11 16:40:17: ('spark.logConf', 'False')
2018-08-11 16:40:17: ('spark.rdd.compress', 'True')
2018-08-11 16:40:17: ('spark.driver.memory', '2g')
2018-08-11 16:40:17: ('spark.serializer.objectStreamReset', '100')
2018-08-11 16:40:17: ('spark.executor.cores', '1')
2018-08-11 16:40:17: ('spark.master', 'spark://cisk.rs2.com:7077')
2018-08-11 16:40:17: ('spark.submit.deployMode', 'client')
2018-08-11 16:40:17: ('spark.executorEnv.PYTHONPATH', '$PYTHONPATH:/home/gabriels/ICS5200')
2018-08-11 16:40:17: ('spark.driver.port', '34545')
2018-08-11 16:40:17: ('spark.ui.showConsoleProgress', 'true')
2018-08-11 16:40:17: ('spark.app.name', 'ICS5200')
2018-08-11 16:40:18: Starting generation of report..
2018-08-11 16:40:18: Skipped record due to following exception: [ORA-00904: "TPC_TYPE": invalid identifier]
2018-08-11 16:41:34: Connected to database [gabsam] with user [tpcds1]
2018-08-11 16:41:34: Connection pool instantiated with [1] connections
2018-08-11 16:41:37: Gracefully disabled Spark nodes..
2018-08-11 16:41:40: Enabled master node..
2018-08-11 16:41:43: Enabled slave node..
2018-08-11 16:41:45: ('spark.cores.max', '20')
2018-08-11 16:41:45: ('spark.app.id', 'app-20180811164145-0000')
2018-08-11 16:41:45: ('spark.executor.memory', '2g')
2018-08-11 16:41:45: ('spark.driver.port', '26392')
2018-08-11 16:41:45: ('spark.driver.host', 'cisk.rs2.com')
2018-08-11 16:41:45: ('spark.executor.id', 'driver')
2018-08-11 16:41:45: ('spark.python.worker.reuse', 'True')
2018-08-11 16:41:45: ('spark.driver.maxResultSize', '1g')
2018-08-11 16:41:45: ('spark.default.parallelism', '80')
2018-08-11 16:41:45: ('spark.sql.shuffle.partitions', '80')
2018-08-11 16:41:45: ('spark.executor.instances', '20')
2018-08-11 16:41:45: ('spark.logConf', 'False')
2018-08-11 16:41:45: ('spark.rdd.compress', 'True')
2018-08-11 16:41:45: ('spark.driver.memory', '2g')
2018-08-11 16:41:45: ('spark.serializer.objectStreamReset', '100')
2018-08-11 16:41:45: ('spark.executor.cores', '1')
2018-08-11 16:41:45: ('spark.master', 'spark://cisk.rs2.com:7077')
2018-08-11 16:41:45: ('spark.submit.deployMode', 'client')
2018-08-11 16:41:45: ('spark.executorEnv.PYTHONPATH', '$PYTHONPATH:/home/gabriels/ICS5200')
2018-08-11 16:41:45: ('spark.ui.showConsoleProgress', 'true')
2018-08-11 16:41:45: ('spark.app.name', 'ICS5200')
2018-08-11 16:41:46: Starting generation of report..
2018-08-11 16:42:21: Connected to database [gabsam] with user [tpcds1]
2018-08-11 16:42:21: Connection pool instantiated with [1] connections
2018-08-11 16:42:27: Gracefully disabled Spark nodes..
2018-08-11 16:42:30: Enabled master node..
2018-08-11 16:42:33: Enabled slave node..
2018-08-11 16:42:35: ('spark.cores.max', '20')
2018-08-11 16:42:35: ('spark.executor.memory', '2g')
2018-08-11 16:42:35: ('spark.driver.host', 'cisk.rs2.com')
2018-08-11 16:42:35: ('spark.executor.id', 'driver')
2018-08-11 16:42:35: ('spark.python.worker.reuse', 'True')
2018-08-11 16:42:35: ('spark.driver.maxResultSize', '1g')
2018-08-11 16:42:35: ('spark.default.parallelism', '80')
2018-08-11 16:42:35: ('spark.sql.shuffle.partitions', '80')
2018-08-11 16:42:35: ('spark.executor.instances', '20')
2018-08-11 16:42:35: ('spark.driver.port', '16970')
2018-08-11 16:42:35: ('spark.logConf', 'False')
2018-08-11 16:42:35: ('spark.rdd.compress', 'True')
2018-08-11 16:42:35: ('spark.app.id', 'app-20180811164235-0000')
2018-08-11 16:42:35: ('spark.driver.memory', '2g')
2018-08-11 16:42:35: ('spark.serializer.objectStreamReset', '100')
2018-08-11 16:42:35: ('spark.executor.cores', '1')
2018-08-11 16:42:35: ('spark.master', 'spark://cisk.rs2.com:7077')
2018-08-11 16:42:35: ('spark.submit.deployMode', 'client')
2018-08-11 16:42:35: ('spark.executorEnv.PYTHONPATH', '$PYTHONPATH:/home/gabriels/ICS5200')
2018-08-11 16:42:35: ('spark.ui.showConsoleProgress', 'true')
2018-08-11 16:42:35: ('spark.app.name', 'ICS5200')
2018-08-11 16:42:36: Starting generation of report..
2018-08-11 16:49:25: Connected to database [gabsam] with user [tpcds1]
2018-08-11 16:49:25: Connection pool instantiated with [1] connections
2018-08-11 16:49:28: Gracefully disabled Spark nodes..
2018-08-11 16:49:30: Enabled master node..
2018-08-11 16:49:33: Enabled slave node..
2018-08-11 16:49:36: ('spark.cores.max', '20')
2018-08-11 16:49:36: ('spark.executor.memory', '2g')
2018-08-11 16:49:36: ('spark.driver.host', 'cisk.rs2.com')
2018-08-11 16:49:36: ('spark.executor.id', 'driver')
2018-08-11 16:49:36: ('spark.python.worker.reuse', 'True')
2018-08-11 16:49:36: ('spark.driver.maxResultSize', '1g')
2018-08-11 16:49:36: ('spark.default.parallelism', '80')
2018-08-11 16:49:36: ('spark.sql.shuffle.partitions', '80')
2018-08-11 16:49:36: ('spark.app.id', 'app-20180811164935-0000')
2018-08-11 16:49:36: ('spark.executor.instances', '20')
2018-08-11 16:49:36: ('spark.driver.port', '31979')
2018-08-11 16:49:36: ('spark.logConf', 'False')
2018-08-11 16:49:36: ('spark.rdd.compress', 'True')
2018-08-11 16:49:36: ('spark.driver.memory', '2g')
2018-08-11 16:49:36: ('spark.serializer.objectStreamReset', '100')
2018-08-11 16:49:36: ('spark.executor.cores', '1')
2018-08-11 16:49:36: ('spark.master', 'spark://cisk.rs2.com:7077')
2018-08-11 16:49:36: ('spark.submit.deployMode', 'client')
2018-08-11 16:49:36: ('spark.executorEnv.PYTHONPATH', '$PYTHONPATH:/home/gabriels/ICS5200')
2018-08-11 16:49:36: ('spark.ui.showConsoleProgress', 'true')
2018-08-11 16:49:36: ('spark.app.name', 'ICS5200')
2018-08-11 16:49:36: Starting generation of report..
2018-08-11 16:50:36: Report generation complete
2018-08-11 16:50:36: Starting generation of report..
