{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schedule Top Consumer Profiling\n",
    "\n",
    "This notebook deals with outlier detection, particularly from the SQL domain. This work attributes itself to detection of high consumers within a database system, particularly flagging those SQL which stand out in terms of computation time/resources required to execute.\n",
    "\n",
    "Due to the high dimensionality of the available data points, unsupervised machine learning techniques will be applied to this problem, so as to isolate data anamolies and flag them as potential bottlenecks.\n",
    "\n",
    "### Module Installation and Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy: 1.1.0\n",
      "numpy: 1.16.1\n",
      "pandas: 0.24.1\n",
      "sklearn: 0.19.0\n"
     ]
    }
   ],
   "source": [
    "# scipy\n",
    "import scipy as sc\n",
    "print('scipy: %s' % sc.__version__)\n",
    "# numpy\n",
    "import numpy as np\n",
    "print('numpy: %s' % np.__version__)\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "# pandas\n",
    "import pandas as pd\n",
    "print('pandas: %s' % pd.__version__)\n",
    "# scikit-learn\n",
    "import sklearn as sk\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,roc_curve,roc_auc_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "print('sklearn: %s' % sk.__version__)\n",
    "# math\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Config\n",
    "parallel_degree = 2\n",
    "tpcds='TPCDS10' # Schema upon which to operate test\n",
    "nrows=None\n",
    "black_list = ['TIMESTAMP','SQL_ID'] # Columns which will be ignored during type conversion, and later used for aggregation\n",
    "\n",
    "y_label = ['CPU_TIME_DELTA','OPTIMIZER_COST','EXECUTIONS_DELTA','ELAPSED_TIME_DELTA']\n",
    "y_label2 = ['COST','CARDINALITY','BYTES','IO_COST','TEMP_SPACE','TIME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from file into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cd02490d5e37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#rep_vsql_plan_path = root_dir + '/rep_vsql_plan.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mrep_hist_snapshot_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrep_hist_snapshot_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mrep_vsql_plan_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrep_vsql_plan_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4000000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nrows'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1993\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1994\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1995\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1996\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m     \"\"\"\n\u001b[0;32m    574\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Root path\n",
    "root_dir = 'C:/Users/gabriel.sammut/University/Data_ICS5200/Schedule/' + tpcds\n",
    "#root_dir = 'D:/Projects/Datagenerated_ICS5200/Schedule/' + tpcds\n",
    "\n",
    "# Open Data\n",
    "rep_hist_snapshot_path = root_dir + '/rep_hist_snapshot.csv'\n",
    "rep_vsql_plan_path = root_dir + '/rep_vsql_plan.csv'\n",
    "#rep_hist_snapshot_path = root_dir + '/rep_hist_snapshot.csv'\n",
    "#rep_vsql_plan_path = root_dir + '/rep_vsql_plan.csv'\n",
    "\n",
    "rep_hist_snapshot_df = pd.read_csv(rep_hist_snapshot_path, nrows=nrows)\n",
    "rep_vsql_plan_df = pd.read_csv(rep_vsql_plan_path, nrows=4000000)\n",
    "\n",
    "def prettify_header(headers):\n",
    "    \"\"\"\n",
    "    Cleans header list from unwated character strings\n",
    "    \"\"\"\n",
    "    header_list = []\n",
    "    [header_list.append(header.replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"\").replace(\",\",\"\")) for header in headers]\n",
    "    return header_list\n",
    "\n",
    "rep_hist_snapshot_df.columns = prettify_header(rep_hist_snapshot_df.columns.values)\n",
    "rep_vsql_plan_df.columns = prettify_header(rep_vsql_plan_df.columns.values)\n",
    "print(rep_hist_snapshot_df.columns)\n",
    "print('------------------------------------------')\n",
    "print(rep_vsql_plan_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_na_columns(df, headers):\n",
    "    \"\"\"\n",
    "    Return columns which consist of NAN values\n",
    "    \"\"\"\n",
    "    na_list = []\n",
    "    for head in headers:\n",
    "        if df[head].isnull().values.any():\n",
    "            na_list.append(head)\n",
    "    return na_list\n",
    "\n",
    "print('N/A Columns\\n')\n",
    "print('\\n REP_HIST_SNAPSHOT Features ' + str(len(rep_hist_snapshot_df.columns)) + ': ' + str(get_na_columns(df=rep_hist_snapshot_df,headers=rep_hist_snapshot_df.columns)) + \"\\n\")\n",
    "print('REP_VSQL_PLAN Features ' + str(len(rep_vsql_plan_df.columns)) + ': ' + str(get_na_columns(df=rep_vsql_plan_df,headers=rep_vsql_plan_df.columns)) + \"\\n\")\n",
    "\n",
    "def fill_na(df):\n",
    "    \"\"\"\n",
    "    Replaces NA columns with 0s\n",
    "    \"\"\"\n",
    "    df = df.replace('', 0)\n",
    "    return df.fillna(0)\n",
    "\n",
    "# Populating NaN values with amount '0'\n",
    "rep_hist_snapshot_df = fill_na(df=rep_hist_snapshot_df)\n",
    "rep_vsql_plan_df = fill_na(df=rep_vsql_plan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type conversion\n",
    "\n",
    "Each column is converted into a column of type values which are Integer64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_numeric_overflows(x):\n",
    "    \"\"\"\n",
    "    Accepts a dataframe column, and \n",
    "    \"\"\"\n",
    "    try:\n",
    "        #df = df.astype('int64')\n",
    "        x1 = pd.DataFrame([x],dtype='int64')\n",
    "    except ValueError:\n",
    "        x = 9223372036854775807 # Max int size\n",
    "    return x\n",
    "\n",
    "for col in rep_hist_snapshot_df.columns:\n",
    "    try:\n",
    "        rep_hist_snapshot_df[col].astype('int64',inplace=True)\n",
    "    except:\n",
    "        if col not in black_list:\n",
    "            rep_hist_snapshot_df.drop(columns=col, inplace=True)\n",
    "            print('Dropped column [' + col + ']')\n",
    "\n",
    "print('-------------------------------------------------------------')\n",
    "\n",
    "for col in rep_vsql_plan_df.columns:\n",
    "    try:\n",
    "        rep_vsql_plan_df[col] = rep_vsql_plan_df[col].astype('int64')\n",
    "    except OverflowError:\n",
    "        #\n",
    "        # Handles numeric overflow conversions by replacing such values with max value inside the dataset.\n",
    "        rep_vsql_plan_df[col] = rep_vsql_plan_df[col].apply(handle_numeric_overflows)\n",
    "        rep_vsql_plan_df[col] = rep_vsql_plan_df[col].astype('int64')\n",
    "    except Exception as e:\n",
    "        if col not in black_list:\n",
    "            rep_vsql_plan_df.drop(columns=col, inplace=True)\n",
    "            print('Dropped column [' + col + ']')\n",
    "print(rep_hist_snapshot_df.columns)\n",
    "print(rep_vsql_plan_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme Outlier Removal\n",
    "\n",
    "Although the scope of this experiment is to seclude, isolate and detect outliers, dataset outlier detection for extreme outliers is still carried out. Without this early outlier detection mechanism, particular datasets (specifically REP_VSQL_PLAN) contain extreme outliers which heavily skew the entire dataset in their favour. These points are relativdely few, and can therefore be eliminated from the dataset straighout without consequence. To detect these type of extreme outliers, a .001 and .999 lower/upper quartile threshold is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, columns, lower_threshold=.25, upper_threshold=.75):\n",
    "    print(\"Before Outlier Removal: \" + str(df.shape))\n",
    "    for col_name in columns:\n",
    "        q1 = df[col_name].quantile(lower_threshold)\n",
    "        q3 = df[col_name].quantile(upper_threshold)\n",
    "        iqr = q3-q1 #Interquartile range\n",
    "        fence_low  = q1-1.5*iqr\n",
    "        fence_high = q3+1.5*iqr\n",
    "        df = df.loc[(df[col_name] > fence_low) & (df[col_name] < fence_high)]\n",
    "    print(\"After Outlier Removal: \" + str(df.shape))\n",
    "    return df\n",
    "\n",
    "print('Outlier Removal for REP_HIST_SNAPSHOT:')\n",
    "rep_hist_snapshot_df = remove_outliers(rep_hist_snapshot_df,y_label,lower_threshold=.001,upper_threshold=.999)\n",
    "\n",
    "print('Outlier Removal for REP_VSQL_PLAN:')\n",
    "rep_vsql_plan_df = remove_outliers(rep_vsql_plan_df,y_label2,lower_threshold=.001,upper_threshold=.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating table data\n",
    "\n",
    "Changes all dataframe shapes to be similar to each other, where in a number of snap_id timestamps are cojoined with instance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Header Lengths [Before Pivot]')\n",
    "print('REP_HIST_SNAPSHOT: ' + str(len(rep_hist_snapshot_df.columns)))\n",
    "print('REP_VSQL_PLAN: ' + str(len(rep_vsql_plan_df.columns)))\n",
    "\n",
    "# Group By Values by SNAP_ID, PLAN_HASH_VALUE , sum all metrics (for table REP_HIST_SNAPSHOT)\n",
    "rep_hist_snapshot_df = rep_hist_snapshot_df.groupby(['SNAP_ID','PLAN_HASH_VALUE']).sum()\n",
    "rep_hist_snapshot_df.reset_index(inplace=True)\n",
    "\n",
    "# Group By Values by PLAN_HASH_VALUE,TIMESTAMP, sum all metrics (for table REP_VSQL_PLAN)\n",
    "rep_vsql_plan_df = rep_vsql_plan_df.groupby(['TIMESTAMP','SQL_ID','ID']).sum()\n",
    "rep_vsql_plan_df.reset_index(inplace=True)\n",
    "\n",
    "print('\\nHeader Lengths [After Pivot]')\n",
    "print('REP_HIST_SNAPSHOT: ' + str(len(rep_hist_snapshot_df.columns)))\n",
    "print('REP_VSQL_PLAN: ' + str(len(rep_vsql_plan_df.columns)) + \"\\n\")\n",
    "print(rep_hist_snapshot_df.columns)\n",
    "print(rep_vsql_plan_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ordering\n",
    "\n",
    "Sorting of datasets in order of:\n",
    "\n",
    "* REP_HIST_SNAPSHOT - SNAP_ID\n",
    "* REP_VSQL_PLAN - TIMESTAMP, SQL_ID, ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_hist_snapshot_df.sort_values(by=['SNAP_ID'], ascending=True, inplace=True)\n",
    "rep_vsql_plan_df.sort_values(by=['TIMESTAMP','SQL_ID','ID'], ascending=True, inplace=True)\n",
    "\n",
    "# Deleting black list columns (these will not be required further in the experiment)\n",
    "#rep_hist_snapshot_df.drop(columns=black_list, inplace=True)\n",
    "rep_vsql_plan_df.drop(columns=black_list, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat Line Selection Removal\n",
    "\n",
    "In this step, redundant features are dropped. Features are considered redundant if exhibit a standard deviation of 0 (meaning no change in value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before')\n",
    "print(rep_hist_snapshot_df.shape)\n",
    "print(rep_vsql_plan_df.shape)\n",
    "\n",
    "def drop_flatline_columns(df):\n",
    "    columns = df.columns\n",
    "    flatline_features = []\n",
    "    for i in range(len(columns)):\n",
    "        try:\n",
    "            std = df[columns[i]].std()\n",
    "            if std == 0:\n",
    "                flatline_features.append(columns[i])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #print('Features which are considered flatline:\\n')\n",
    "    #for col in flatline_features:\n",
    "    #    print(col)\n",
    "    print('\\nShape before dropping features: [' + str(df.shape) + ']')\n",
    "    df = df.drop(columns=flatline_features)\n",
    "    print('Shape after dropping features: [' + str(df.shape) + ']')\n",
    "    print('Dropped a total [' + str(len(flatline_features)) + ']')\n",
    "    return df\n",
    "\n",
    "rep_hist_snapshot_df = drop_flatline_columns(df=rep_hist_snapshot_df)\n",
    "rep_vsql_plan_df = drop_flatline_columns(df=rep_vsql_plan_df)\n",
    "\n",
    "dropped_columns_rep_hist_snapshot = ['SNAP_ID',\n",
    "                                       'PLAN_HASH_VALUE',\n",
    "                                       'OPTIMIZER_ENV_HASH_VALUE',\n",
    "                                       'LOADED_VERSIONS',\n",
    "                                       'VERSION_COUNT',\n",
    "                                       'PARSING_SCHEMA_ID',\n",
    "                                       'PARSING_USER_ID']\n",
    "dropped_columns_rep_vsql_plan = ['PLAN_HASH_VALUE',\n",
    "                                 'ID',\n",
    "                                 'OBJECT#',\n",
    "                                 'PARENT_ID',\n",
    "                                 'SEARCH_COLUMNS']\n",
    "rep_hist_snapshot_df.drop(columns=dropped_columns_rep_hist_snapshot, inplace=True)\n",
    "rep_vsql_plan_df.drop(columns=dropped_columns_rep_vsql_plan, inplace=True)\n",
    "\n",
    "print('\\nAfter')\n",
    "print(rep_hist_snapshot_df.shape)\n",
    "print(rep_vsql_plan_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guaging Outliers (REP_HIST_SNAPSHOT)\n",
    "\n",
    "Uses the following labels and plots them (scatter plots), so as to showcase the presence of outliers:\n",
    "* CPU_TIME_DELTA\n",
    "* OPTIMIZER_COST\n",
    "* EXECUTIONS_DELTA\n",
    "* ELAPSED_TIME_DELTA\n",
    "\n",
    "### Scatter Plots (REP_HIST_SNAPSHOT)\n",
    "\n",
    "The following section caters to scatter plots between all labels, specified in the following configuration:\n",
    "\n",
    "------------------------------------------\n",
    "* CPU_TIME_DELTA vs OPTIMIZER_COST\n",
    "* CPU_TIME_DELTA vs EXECUTIONS_DELTA\n",
    "* CPU_TIME_DELTA vs ELAPSED_TIME_DELTA\n",
    "------------------------------------------\n",
    "* OPTIMIZER_COST vs CPU_TIME_DELTA\n",
    "* OPTIMIZER_COST vs EXECUTIONS_DELTA\n",
    "* OPTIMIZER_COST vs ELAPSED_TIME_DELTA\n",
    "------------------------------------------\n",
    "* EXECUTIONS_DELTA vs CPU_TIME_DELTA\n",
    "* EXECUTIONS_DELTA vs OPTIMIZER_COST\n",
    "* EXECUTIONS_DELTA vs ELAPSED_TIME_DELTA\n",
    "------------------------------------------\n",
    "* ELAPSED_TIME_DELTA vs CPU_TIME_DELTA\n",
    "* ELAPSED_TIME_DELTA vs OPTIMIZER_COST\n",
    "* ELAPSED_TIME_DELTA vs EXECUTIONS_DELTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_label = ['CPU_TIME_DELTA','OPTIMIZER_COST','EXECUTIONS_DELTA','ELAPSED_TIME_DELTA']\n",
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "rep_hist_snapshot_df.plot.scatter(x='CPU_TIME_DELTA',\n",
    "                                  y='OPTIMIZER_COST',\n",
    "                                  c='DarkBlue')\n",
    "rep_hist_snapshot_df.plot.scatter(x='CPU_TIME_DELTA',\n",
    "                                  y='EXECUTIONS_DELTA',\n",
    "                                  c='DarkBlue')\n",
    "rep_hist_snapshot_df.plot.scatter(x='CPU_TIME_DELTA',\n",
    "                                  y='ELAPSED_TIME_DELTA',\n",
    "                                  c='DarkBlue')\n",
    "plt.show()\n",
    "print('--------------------------------------------------------')\n",
    "rep_hist_snapshot_df.plot.scatter(x='OPTIMIZER_COST',\n",
    "                                  y='CPU_TIME_DELTA',\n",
    "                                  c='DarkBlue')\n",
    "rep_hist_snapshot_df.plot.scatter(x='OPTIMIZER_COST',\n",
    "                                  y='EXECUTIONS_DELTA',\n",
    "                                  c='DarkBlue')\n",
    "rep_hist_snapshot_df.plot.scatter(x='OPTIMIZER_COST',\n",
    "                                  y='ELAPSED_TIME_DELTA',\n",
    "                                  c='DarkBlue')\n",
    "plt.show()\n",
    "print('--------------------------------------------------------')\n",
    "rep_hist_snapshot_df.plot.scatter(x='EXECUTIONS_DELTA',\n",
    "                                  y='CPU_TIME_DELTA',\n",
    "                                  c='DarkBlue')\n",
    "rep_hist_snapshot_df.plot.scatter(x='EXECUTIONS_DELTA',\n",
    "                                  y='OPTIMIZER_COST',\n",
    "                                  c='DarkBlue')\n",
    "rep_hist_snapshot_df.plot.scatter(x='EXECUTIONS_DELTA',\n",
    "                                  y='ELAPSED_TIME_DELTA',\n",
    "                                  c='DarkBlue')\n",
    "plt.show()\n",
    "print('--------------------------------------------------------')\n",
    "rep_hist_snapshot_df.plot.scatter(x='ELAPSED_TIME_DELTA',\n",
    "                                  y='CPU_TIME_DELTA',\n",
    "                                  c='DarkBlue')\n",
    "rep_hist_snapshot_df.plot.scatter(x='ELAPSED_TIME_DELTA',\n",
    "                                  y='OPTIMIZER_COST',\n",
    "                                  c='DarkBlue')\n",
    "rep_hist_snapshot_df.plot.scatter(x='ELAPSED_TIME_DELTA',\n",
    "                                  y='EXECUTIONS_DELTA',\n",
    "                                  c='DarkBlue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plots / Outlier Plots (REP_HIST_SNAPSHOT)\n",
    "\n",
    "Outlier plots for all targetted labels:\n",
    "\n",
    "* CPU_TIME_DELTA\n",
    "* OPTIMIZER_COST\n",
    "* EXECUTIONS_DELTA\n",
    "* ELAPSED_TIME_DELTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "plt.boxplot(rep_hist_snapshot_df['CPU_TIME_DELTA'].values)\n",
    "plt.title('CPU_TIME_DELTA')\n",
    "plt.show()\n",
    "plt.boxplot(rep_hist_snapshot_df['OPTIMIZER_COST'].values)\n",
    "plt.title('OPTIMIZER_COST')\n",
    "plt.show()\n",
    "plt.boxplot(rep_hist_snapshot_df['EXECUTIONS_DELTA'].values)\n",
    "plt.title('EXECUTIONS_DELTA')\n",
    "plt.show()\n",
    "plt.boxplot(rep_hist_snapshot_df['ELAPSED_TIME_DELTA'].values)\n",
    "plt.title('ELAPSED_TIME_DELTA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Label Values (REP_HIST_SNAPSHOT)\n",
    "\n",
    "This section plots the top hundred values per label, order from highest to lowest. Targetted labels are as follows:\n",
    "\n",
    "* CPU_TIME_DELTA\n",
    "* OPTIMIZER_COST\n",
    "* EXECUTIONS_DELTA\n",
    "* ELAPSED_TIME_DELTA\n",
    "\n",
    "NB: Due to the vector nature of the dataset set, this section considers the established above labels in a univariate nature. Data matrixes are respectively ordered per column label, ranked according to the sorted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 100\n",
    "label = 'CPU_TIME_DELTA'\n",
    "rep_hist_snapshot_df2 = rep_hist_snapshot_df.sort_values(by=label, ascending=False)\n",
    "rep_hist_snapshot_df2[[label]][0:limit].plot(kind='bar', title =label, figsize=(20, 15), legend=True, fontsize=12)\n",
    "label = 'OPTIMIZER_COST'\n",
    "rep_hist_snapshot_df2 = rep_hist_snapshot_df.sort_values(by=label, ascending=False)\n",
    "rep_hist_snapshot_df2[[label]][0:limit].plot(kind='bar', title =label, figsize=(20, 15), legend=True, fontsize=12)\n",
    "label = 'EXECUTIONS_DELTA'\n",
    "rep_hist_snapshot_df2 = rep_hist_snapshot_df.sort_values(by=label, ascending=False,)\n",
    "rep_hist_snapshot_df2[[label]][0:limit].plot(kind='bar', title =label, figsize=(20, 15), legend=True, fontsize=12)\n",
    "label = 'ELAPSED_TIME_DELTA'\n",
    "rep_hist_snapshot_df2 = rep_hist_snapshot_df.sort_values(by=label, ascending=False)\n",
    "rep_hist_snapshot_df2[[label]][0:limit].plot(kind='bar', title =label, figsize=(20, 15), legend=True, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guaging Outliers (REP_VSQL_PLAN)\n",
    "\n",
    "Uses the following labels and plots them, so as to showcase the presence of outliers:\n",
    "* COST\n",
    "* CARDINALITY\n",
    "* BYTES\n",
    "* CPU_COST\n",
    "* IO_COST\n",
    "* TEMP_SPACE\n",
    "* TIME\n",
    "\n",
    "### Scatter Plots (REP_VSQL_PLAN)\n",
    "\n",
    "The following section caters fro scatter plots between all labels as follows:\n",
    "\n",
    "------------------------------------------\n",
    "* COST vs CARDINALITY\n",
    "* COST vs BYTES\n",
    "* COST vs IO_COST\n",
    "* COST vs TEMP_SPACE\n",
    "* COST vs TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y_label2 = ['COST','CARDINALITY','BYTES','IO_COST','TEMP_SPACE','TIME']\n",
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "rep_vsql_plan_df.plot.scatter(x='COST',\n",
    "                              y='CARDINALITY',\n",
    "                              c='DarkBlue')\n",
    "rep_vsql_plan_df.plot.scatter(x='COST',\n",
    "                              y='BYTES',\n",
    "                              c='DarkBlue')\n",
    "rep_vsql_plan_df.plot.scatter(x='COST',\n",
    "                              y='IO_COST',\n",
    "                              c='DarkBlue')\n",
    "rep_vsql_plan_df.plot.scatter(x='COST',\n",
    "                              y='TEMP_SPACE',\n",
    "                              c='DarkBlue')\n",
    "rep_vsql_plan_df.plot.scatter(x='COST',\n",
    "                              y='TIME',\n",
    "                              c='DarkBlue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plots / Outlier Plots (REP_VSQL_PLAN)\n",
    "\n",
    "Outlier plots for all targetted labels:\n",
    "\n",
    "* COST\n",
    "* CARDINALITY\n",
    "* BYTES\n",
    "* IO_COST\n",
    "* TEMP_SPACE\n",
    "* TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "plt.boxplot(rep_vsql_plan_df['COST'].values)\n",
    "plt.title('COST')\n",
    "plt.show()\n",
    "plt.boxplot(rep_vsql_plan_df['CARDINALITY'].values)\n",
    "plt.title('CARDINALITY')\n",
    "plt.show()\n",
    "plt.boxplot(rep_vsql_plan_df['BYTES'].values)\n",
    "plt.title('BYTES')\n",
    "plt.show()\n",
    "plt.boxplot(rep_vsql_plan_df['IO_COST'].values)\n",
    "plt.title('IO_COST')\n",
    "plt.show()\n",
    "plt.boxplot(rep_vsql_plan_df['TEMP_SPACE'].values)\n",
    "plt.title('TEMP_SPACE')\n",
    "plt.show()\n",
    "plt.boxplot(rep_vsql_plan_df['TIME'].values)\n",
    "plt.title('TIME')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Label Values (REP_VSQL_PLAN)\n",
    "\n",
    "This section plots the top hundred values per label, order from highest to lowest. Targetted labels are as follows:\n",
    "\n",
    "* COST\n",
    "* CARDINALITY\n",
    "* BYTES\n",
    "* IO_COST\n",
    "* TEMP_SPACE\n",
    "* TIME\n",
    "\n",
    "NB: Due to the vector nature of the dataset set, this section considers the established above labels in a univariate nature. Data matrixes are respectively ordered per column label, ranked according to the sorted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 100\n",
    "label = 'COST'\n",
    "rep_vsql_plan_df2 = rep_vsql_plan_df.sort_values(by=label, ascending=False)\n",
    "rep_vsql_plan_df2[[label]][0:limit].plot(kind='bar', title =label, figsize=(20, 15), legend=True, fontsize=12)\n",
    "label = 'CARDINALITY'\n",
    "rep_vsql_plan_df2 = rep_vsql_plan_df.sort_values(by=label, ascending=False)\n",
    "rep_vsql_plan_df2[[label]][0:limit].plot(kind='bar', title =label, figsize=(20, 15), legend=True, fontsize=12)\n",
    "label = 'BYTES'\n",
    "rep_vsql_plan_df2 = rep_vsql_plan_df.sort_values(by=label, ascending=False)\n",
    "rep_vsql_plan_df2[[label]][0:limit].plot(kind='bar', title =label, figsize=(20, 15), legend=True, fontsize=12)\n",
    "label = 'IO_COST'\n",
    "rep_vsql_plan_df2 = rep_vsql_plan_df.sort_values(by=label, ascending=False)\n",
    "rep_vsql_plan_df2[[label]][0:limit].plot(kind='bar', title =label, figsize=(20, 15), legend=True, fontsize=12)\n",
    "label = 'TEMP_SPACE'\n",
    "rep_vsql_plan_df2 = rep_vsql_plan_df.sort_values(by=label, ascending=False)\n",
    "rep_vsql_plan_df2[[label]][0:limit].plot(kind='bar', title =label, figsize=(20, 15), legend=True, fontsize=12)\n",
    "label = 'TIME'\n",
    "rep_vsql_plan_df2 = rep_vsql_plan_df.sort_values(by=label, ascending=False)\n",
    "rep_vsql_plan_df2[[label]][0:limit].plot(kind='bar', title =label, figsize=(20, 15), legend=True, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top K-NN Outlier Detection\n",
    "\n",
    "This section attempts at identifying outliers using a Top K-NN approach. A distance based measure is used to retrieve a number of top consumer vectors, measured by euclidean distance. A base point is used to measure all other vectors to this minimum point. The threshold point is an imaginary vector, calculated to be the minimum most point in the dataset.\n",
    "\n",
    "Once the minimum vector is established, all other vectors are compared to it, judged by the euclidean distance between the vector in question, and the established threshold vector. The achieved distance and repsective data vector are then sorted from biggest distance to lowest. A Top N (Where N is the number of captured outliers) approach is used to retrieve the highest (most expensive) vectors in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopKNNWrapper:\n",
    "    \"\"\"\n",
    "    This class is an attempt at approaching the outlier through a nearest neighbour solution. All datapoints\n",
    "    within the dataset are measured (in euclidean) to an imaginary, minimal threshold vector, and ranked \n",
    "    accordingly. Vectors with the highest achieved distance are most likely to be considered as outliers.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X):\n",
    "        \"\"\"\n",
    "        Class constructor\n",
    "        \n",
    "        :param: X - Pandas dataframe consisting of input features\n",
    "        \n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.df = X\n",
    "        self.X = RobustScaler().fit_transform(X.values)\n",
    "        print(self.X)\n",
    "    \n",
    "    def __get_minimum_vector(self):\n",
    "        \"\"\"\n",
    "        Returns numpy vector, corresponding to smallest possible point in relation to dataset\n",
    "        \n",
    "        :return: Numpy array, represneting the most minimal of vectors possible in the entire dataset\n",
    "        \"\"\"\n",
    "        return np.amin(self.X, axis=0)\n",
    "    \n",
    "    def get_top_K_outliers(self, topK):\n",
    "        \"\"\"\n",
    "        Returns a number of dataset outliers, where topK is an integer denoting the number of top outliers to \n",
    "        be retrieved.\n",
    "        \n",
    "        :param: topK - Integer denoting outlier amount to retrieve\n",
    "        \n",
    "        :return: List of Outliers, ordered by euclidean distance. Each element in the list is composed of\n",
    "                 another list with the following structure: [Dataframe row index, Euclidean distance To threshold]\n",
    "        \"\"\"\n",
    "        distance_matrix = [] # [index, distance]\n",
    "        minimal_vector = self.__get_minimum_vector()\n",
    "        euc_dist = euclidean_distances(self.X, minimal_vector.reshape(1, -1))\n",
    "        for i in range(0, len(euc_dist)):\n",
    "            distance_matrix.append([i, euc_dist[i]])\n",
    "        distance_matrix = np.array(distance_matrix)\n",
    "        distance_matrix = distance_matrix[np.argsort(distance_matrix[:, 1])[::-1]]\n",
    "        outliers = distance_matrix[0:topK]\n",
    "        print(outliers)\n",
    "        return outliers\n",
    "    \n",
    "    def plot_outliers(self, topK):\n",
    "        \"\"\"\n",
    "        Plots Euclidean distances gauged from threshold point\n",
    "        \n",
    "        :param: topK - Integer denoting outlier amount to retrieve\n",
    "        \n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        outliers = self.get_top_K_outliers(topK)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.bar(np.arange(len(outliers[:,1])), outliers[:,1], align='center');\n",
    "        plt.title('Top KNN Distance From Minimum Vector')\n",
    "        plt.show()        \n",
    "\n",
    "topK = 100\n",
    "\n",
    "# REP_HIST_SNAPSHOT\n",
    "print('REP_HIST_SNAPSHOT Top [' + str(topK) + '] outliers!')\n",
    "tkw = TopKNNWrapper(X=rep_hist_snapshot_df)\n",
    "outliers = tkw.get_top_K_outliers(topK=topK)\n",
    "tkw.plot_outliers(topK=topK)\n",
    "\n",
    "print('------------------------------------------------------')\n",
    "\n",
    "# REP_VSQL_PLAN\n",
    "print('REP_VSQL_PLAN Top [' + str(topK) + '] outliers!')\n",
    "tkw = TopKNNWrapper(X=rep_vsql_plan_df)\n",
    "outliers = tkw.get_top_K_outliers(topK=topK)\n",
    "tkw.plot_outliers(topK=topK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering (K=2)\n",
    "\n",
    "This setion contains attempts at clustering data (separation between inliers and outliers). Through an unsupervised approach, K-Means will be used to distinguish between one vector and another - clustering the dataset into two subsets. Therefore, the dataset can be categorized into 2 classes:\n",
    "\n",
    "* Inlier\n",
    "* Outlier\n",
    "\n",
    "Initial attempts will target K=2, and then visualize centroid to gauge their effectiveness in the achieved clustering. K is eventually varied across a range of values, which will be used to achieve better clustering results. The following section will simply plot centroid positioning in relation to dataset features, so as to visualize how effective centroid positioning is carried out - https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "\n",
    "This work is motivated through works presented below:\n",
    "***\n",
    "__An Approach to Outlier Detection of Software Measurement Data using the K-means Clustering Method__ - http://koasas.kaist.ac.kr/bitstream/10203/3308/1/2007_09%20An%20Approach%20to%20Outlier%20Detection%20of%20Software%20Measurement%20Data%20using%20the%20K-means%20Clustering%20Method.pdf\n",
    "\n",
    "_By considering the characteristics of software measurement data, we choose the k-means clustering method to the outlier detection method. According to the survey work, the k-means clustering is an unsupervised method and can support high-dimensional data. Given a data matrix composed of observations and variables, the objective is to cluster the observations into groups that are internally homogeneous and heterogeneous from group to group. The\n",
    "of the k-means clustering method indicates the number of groups which is established a priori by expert. To calculate the degree of homogeneity and heterogeneity, the k-means clustering method employs the Euclidean  distance as a measure of the similarity between observations and groups. The distance function using the Euclidean distance is denoted as:_\n",
    "\n",
    "<div style=\"width:image width px; font-size:80%; text-align:center;\"><img src='Images/euclidean_distance_formula.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"padding-bottom:0.5em;\" /><b>Euclidean Distance Formula</b></div>\n",
    "\n",
    "_where there are 'K' clusters 'S', and 'U' is the centroid or mean point of all the points. We eliminate the detail operational flow of the k-means algorithm to save the space._\n",
    "***\n",
    "__k-means-: A unified approach to clustering and outlier detection__ - https://pdfs.semanticscholar.org/70f4/5be50599f12a1b682a192c3c48ebda0bb1c4.pdf\n",
    "\n",
    "_In this paper we will propose a generalization of the k-means problem with the aim of simultaneously clustering data and discovering outliers. A naive approach is to apply  the k-means algorithm and list as outliers the top points that are the furthest away from their nearest cluster centers.  However, there is a subtle point that needs to be noted: the k-means algorithm itself is extremely sensitive to outliers, and such outliers may have a disproportionate impact on the final cluster configuration.  This can result in many false negatives: i.e., data points that should be declared outliers are masked by the  clustering  and  also  false  positives: data points that are incorrectly labeled as outliers. Thus what is required is a more robust version of the k-means algorithm that gracefully handles the presence of outliers._\n",
    "\n",
    "<div style=\"width:image width px; font-size:80%; text-align:center;\"><img src='Images/k_means_clustering.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"padding-bottom:0.5em;\" /><b>The k-means algorithm is extremely sensitive to outliers.  By removing two points (1) and (2), we can obtain  much  tighter  clusters  (the  bold  circle  near  3). The objective of this paper is to obtain a tight clustering and report the outliers in an automatic fashion.</b></div>\n",
    "\n",
    "_Our main contributions are the following:_\n",
    "* _We formulate the (k,l)-means problem of simultaneously discovering clusters and outliers as an NP-hard optimization problem.  The optimization problem paves the way for a systematic and formal analysis of the outlier detection problem._\n",
    "* _We propose the k-means-- (k-means minus minus) algorithm, which given an input parameter of (k,l) will discover k clusters and l outliers in a unified fashion. We show that the k-means-- algorithm provably converges to a local optima and the running time is linear in the number of data points. The algorithm extends to cases when the similarity metric is a Bregman divergence._\n",
    "***\n",
    "\n",
    "### REP_HIST_SNAPSHOT K-Means Application\n",
    "\n",
    "Applying REP_HIST_SNAPSHOT labels through K-Means (K=2)\n",
    "\n",
    "NB: Only a value of K=2 is considered at this stage. This over-simplification of K serves only to get a better\n",
    "understanding of the centroid positioning for the unsupervised algorithm. A more robust testing script is presented further on in this experiment, in an effort to fully exhaust K configurations and the respective scored metrics, for table REP_HIST_SNAPSHOT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_col_pos(df, target_label):\n",
    "    \"\"\"\n",
    "    Iterates over column, and retrieves position of col in dataset\n",
    "    \n",
    "    :param: df           - Pandas dataframe consisting of input features\n",
    "    :param: target_label - String denoting label column name\n",
    "    \n",
    "    :return: Integer denoting label position in the data matrix\n",
    "    \"\"\"\n",
    "    columns = df.columns\n",
    "    index = -1\n",
    "    for i in range(0,len(columns)):\n",
    "        if columns[i].lower() == target_label.lower():\n",
    "            index = i\n",
    "            break\n",
    "    return index\n",
    "\n",
    "K = 2\n",
    "\n",
    "# Training Unsupervised K-Means Model (K=2) for data matrix REP_VSQL_PLAN \n",
    "kmeans_hist = KMeans(n_clusters=K, random_state=0).fit(rep_hist_snapshot_df.values)\n",
    "print(kmeans_hist)\n",
    "print(kmeans_hist.labels_)\n",
    "unique, counts = np.unique(kmeans_hist.labels_, return_counts=True)\n",
    "print('Unique: ' + str(unique))\n",
    "print('Counts: ' + str(counts))\n",
    "#\n",
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "##################################\n",
    "plt.scatter(x=rep_hist_snapshot_df.values[:,get_col_pos(rep_hist_snapshot_df, 'ELAPSED_TIME_DELTA')],\n",
    "            y=rep_hist_snapshot_df.values[:,get_col_pos(rep_hist_snapshot_df, 'CPU_TIME_DELTA')],\n",
    "            c='b')\n",
    "plt.scatter(x=kmeans_hist.cluster_centers_[:,get_col_pos(rep_hist_snapshot_df, 'ELAPSED_TIME_DELTA')],\n",
    "            y=kmeans_hist.cluster_centers_[:,get_col_pos(rep_hist_snapshot_df, 'CPU_TIME_DELTA')],\n",
    "            c='r')\n",
    "plt.title('ELAPSED_TIME_DELTA vs CPU_TIME_DELTA')\n",
    "plt.xlabel('ELAPSED_TIME_DELTA')\n",
    "plt.ylabel('CPU_TIME_DELTA')\n",
    "plt.show()\n",
    "##################################\n",
    "plt.scatter(x=rep_hist_snapshot_df.values[:,get_col_pos(rep_hist_snapshot_df, 'ELAPSED_TIME_DELTA')],\n",
    "            y=rep_hist_snapshot_df.values[:,get_col_pos(rep_hist_snapshot_df, 'OPTIMIZER_COST')],\n",
    "            c='b')\n",
    "plt.scatter(x=kmeans_hist.cluster_centers_[:,get_col_pos(rep_hist_snapshot_df, 'ELAPSED_TIME_DELTA')],\n",
    "            y=kmeans_hist.cluster_centers_[:,get_col_pos(rep_hist_snapshot_df, 'OPTIMIZER_COST')],\n",
    "            c='r')\n",
    "plt.title('ELAPSED_TIME_DELTA vs OPTIMIZER_COST')\n",
    "plt.xlabel('ELAPSED_TIME_DELTA')\n",
    "plt.ylabel('OPTIMIZER_COST')\n",
    "plt.show()\n",
    "##################################\n",
    "plt.scatter(x=rep_hist_snapshot_df.values[:,get_col_pos(rep_hist_snapshot_df, 'ELAPSED_TIME_DELTA')],\n",
    "            y=rep_hist_snapshot_df.values[:,get_col_pos(rep_hist_snapshot_df, 'EXECUTIONS_DELTA')],\n",
    "            c='b')\n",
    "plt.scatter(x=kmeans_hist.cluster_centers_[:,get_col_pos(rep_hist_snapshot_df, 'ELAPSED_TIME_DELTA')],\n",
    "            y=kmeans_hist.cluster_centers_[:,get_col_pos(rep_hist_snapshot_df, 'EXECUTIONS_DELTA')],\n",
    "            c='r')\n",
    "plt.title('ELAPSED_TIME_DELTA vs EXECUTIONS_DELTA')\n",
    "plt.xlabel('ELAPSED_TIME_DELTA')\n",
    "plt.ylabel('EXECUTIONS_DELTA')\n",
    "plt.show()\n",
    "#\n",
    "print('Vector presented to pertain to class 0:')\n",
    "for i in range(len(kmeans_hist.labels_)):\n",
    "    if kmeans_hist.labels_[i] == 0:\n",
    "        print(rep_hist_snapshot_df.iloc[i])\n",
    "        break\n",
    "print('\\n\\nVector presented to pertain to class 1:')\n",
    "for i in range(len(kmeans_hist.labels_)):\n",
    "    if kmeans_hist.labels_[i] == 1:\n",
    "        print(rep_hist_snapshot_df.iloc[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REP_VSQL_PLAN K-Means Application\n",
    "\n",
    "Applying REP_VSQL_PLAN labels through K-Means (K=2)\n",
    "\n",
    "NB: Only a value of K=2 is considered at this stage. This over-simplification of K serves only to get a better\n",
    "understanding of the centroid positioning for the unsupervised algorithm. A more robust testing script is presented further on in this experiment, in an effort to fully exhaust K configurations and the respective scored metrics, for table REP_VSQL_PLAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K = 2\n",
    "\n",
    "# Training Unsupervised K-Means Model (K=2) for data matrix REP_VSQL_PLAN \n",
    "kmeans_vsql = KMeans(n_clusters=K, random_state=0).fit(rep_vsql_plan_df.values)\n",
    "print(kmeans_vsql)\n",
    "print(kmeans_vsql.labels_)\n",
    "unique, counts = np.unique(kmeans_vsql.labels_, return_counts=True)\n",
    "print('Unique: ' + str(unique))\n",
    "print('Counts: ' + str(counts))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "##################################\n",
    "plt.scatter(x=rep_vsql_plan_df.values[:,get_col_pos(rep_vsql_plan_df, 'COST')],\n",
    "            y=rep_vsql_plan_df.values[:,get_col_pos(rep_vsql_plan_df, 'CARDINALITY')],\n",
    "            c='b')\n",
    "plt.scatter(x=kmeans_hist.cluster_centers_[:,get_col_pos(rep_vsql_plan_df, 'COST')],\n",
    "            y=kmeans_hist.cluster_centers_[:,get_col_pos(rep_vsql_plan_df, 'CARDINALITY')],\n",
    "            c='r')\n",
    "plt.title('COST vs CARDINALITY')\n",
    "plt.xlabel('COST')\n",
    "plt.ylabel('CARDINALITY')\n",
    "plt.show()\n",
    "##################################\n",
    "plt.scatter(x=rep_vsql_plan_df.values[:,get_col_pos(rep_vsql_plan_df, 'COST')],\n",
    "            y=rep_vsql_plan_df.values[:,get_col_pos(rep_vsql_plan_df, 'BYTES')],\n",
    "            c='b')\n",
    "plt.scatter(x=kmeans_hist.cluster_centers_[:,get_col_pos(rep_vsql_plan_df, 'COST')],\n",
    "            y=kmeans_hist.cluster_centers_[:,get_col_pos(rep_vsql_plan_df, 'BYTES')],\n",
    "            c='r',)\n",
    "plt.title('COST vs BYTES')\n",
    "plt.xlabel('COST')\n",
    "plt.ylabel('BYTES')\n",
    "plt.show()\n",
    "##################################\n",
    "plt.scatter(x=rep_vsql_plan_df.values[:,get_col_pos(rep_vsql_plan_df, 'COST')],\n",
    "            y=rep_vsql_plan_df.values[:,get_col_pos(rep_vsql_plan_df, 'IO_COST')],\n",
    "            c='b')\n",
    "plt.scatter(x=kmeans_hist.cluster_centers_[:,get_col_pos(rep_vsql_plan_df, 'COST')],\n",
    "            y=kmeans_hist.cluster_centers_[:,get_col_pos(rep_vsql_plan_df, 'IO_COST')],\n",
    "            c='r')\n",
    "plt.title('COST vs IO_COST')\n",
    "plt.xlabel('COST')\n",
    "plt.ylabel('IO_COST')\n",
    "plt.show()\n",
    "##################################\n",
    "plt.scatter(x=rep_vsql_plan_df.values[:,get_col_pos(rep_vsql_plan_df, 'COST')],\n",
    "            y=rep_vsql_plan_df.values[:,get_col_pos(rep_vsql_plan_df, 'TEMP_SPACE')],\n",
    "            c='b')\n",
    "plt.scatter(x=kmeans_hist.cluster_centers_[:,get_col_pos(rep_vsql_plan_df, 'COST')],\n",
    "            y=kmeans_hist.cluster_centers_[:,get_col_pos(rep_vsql_plan_df, 'TEMP_SPACE')],\n",
    "            c='r')\n",
    "plt.title('COST vs TEMP_SPACE')\n",
    "plt.xlabel('COST')\n",
    "plt.ylabel('TEMP_SPACE')\n",
    "plt.show()\n",
    "##################################\n",
    "plt.scatter(x=rep_vsql_plan_df.values[:,get_col_pos(rep_vsql_plan_df, 'COST')],\n",
    "            y=rep_vsql_plan_df.values[:,get_col_pos(rep_vsql_plan_df, 'TIME')],\n",
    "            c='b')\n",
    "plt.scatter(x=kmeans_hist.cluster_centers_[:,get_col_pos(rep_vsql_plan_df, 'COST')],\n",
    "            y=kmeans_hist.cluster_centers_[:,get_col_pos(rep_vsql_plan_df, 'TIME')],\n",
    "            c='r')\n",
    "plt.title('COST vs TIME')\n",
    "plt.xlabel('COST')\n",
    "plt.ylabel('TIME')\n",
    "plt.show()\n",
    "\n",
    "print('Vector presented to pertain to class 0:')\n",
    "for i in range(len(kmeans_vsql.labels_)):\n",
    "    if kmeans_vsql.labels_[i] == 0:\n",
    "        print(rep_vsql_plan_df.iloc[i])\n",
    "        break\n",
    "print('\\n\\nVector presented to pertain to class 1:')\n",
    "for i in range(len(kmeans_vsql.labels_)):\n",
    "    if kmeans_vsql.labels_[i] == 1:\n",
    "        print(rep_vsql_plan_df.iloc[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering\n",
    "\n",
    "So as to verify the success of the clustering attempts, the achieved clustering labels require to be compared\n",
    "to what is assumed to be the actual label predictions. These 'actual' clusters will be assumed to coincide with\n",
    "the data matrix average - if a particular data vector is larger/smaller than the mean threshold, it will coincide in one cluster or the other.\n",
    "\n",
    "Data Formatting - Input data is normalized through a Robust scaler before fit to the K-Means model. The Robustness of the scaler is relavent here due to the pre-knowledge that data which will be dealt with contains a number of outliers \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidateKMeans:\n",
    "    \"\"\"\n",
    "    Wrapper class for the KMeans algorithm, so as to validate the clustering it has achieved\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, k, parallel_degree):\n",
    "        \"\"\"\n",
    "        Class constructor. This method ensures that the input data matrix is normalized through a Robust \n",
    "        Scaler\n",
    "        \n",
    "        ;param: X               - Pandas dataframe consisting of the feature matrix\n",
    "        :param: k               - Integer denoting the 'K' hyper parameter variable\n",
    "        :param: parallel_degree - Integer denoting the parallel degree used to train the K-Means model\n",
    "        \n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.df = X\n",
    "        self.X = RobustScaler().fit_transform(X.values)\n",
    "        self.k = k\n",
    "        self.model = KMeans(n_clusters=self.k, random_state=0, init='k-means++',n_jobs=parallel_degree)\n",
    "        self.model.fit(self.X)\n",
    "        self.__y_labels = self.model.labels_\n",
    "        self.scorings = []\n",
    "        print(self.model)\n",
    "         \n",
    "    def __get_threshold_vector(self):\n",
    "        \"\"\"\n",
    "        Calculates a threshold vector. Anything above this threshold is determined to be an outlier.\n",
    "        Threshold is determined to be the 3rd standard deviation interval.\n",
    "        \n",
    "        :return: Numpy vector which serves as the threshold, determining whether inlier/outlier.\n",
    "        \"\"\"\n",
    "        mean = np.mean(self.X)\n",
    "        std = np.std(self.X)\n",
    "        std3 = np.multiply(std, 3)\n",
    "        return np.add(mean, std3)\n",
    "    \n",
    "    def __calculate_expected_labels(self):\n",
    "        \"\"\"\n",
    "        Estimates label clustering by comparing them to a threshold mean value. These labels\n",
    "        will be used to gauge a scoring for the unsupervised clustering achieved by the K-Means algorithm.\n",
    "        \n",
    "        :return: A list of integers, consisting of the expected labels. The list returned by this function is\n",
    "        used to evaulate the K-Means clustered label outputs.\n",
    "        \"\"\"\n",
    "        thresh_vect = self.__get_threshold_vector()\n",
    "        mean_labels = []\n",
    "        for vector in self.X:\n",
    "            if np.greater(vector, thresh_vect).any():\n",
    "                mean_labels.append(1)\n",
    "            else:\n",
    "                mean_labels.append(0)\n",
    "        return mean_labels\n",
    "    \n",
    "    def outlier_score_precision(self):\n",
    "        \"\"\"\n",
    "        Returns a score which evaluates the accuracy with the number of isolated outliers. The closer to 0 \n",
    "        the score, the more accurate the evaluation.\n",
    "        \n",
    "        :return: Integer output denoting euclidean error score (Squared and Square Rooted to achieve a \n",
    "        positive value).\n",
    "        \"\"\"\n",
    "        if self.scorings is None or len(self.scorings) == 0:\n",
    "            raise ValueError('Scorings list is empty!')\n",
    "        elif len(self.scorings) > 2:\n",
    "            raise ValueError('Scorings list length is greater than 2! Must be composed of the following structure [scoring1, scoring2]')\n",
    "        \n",
    "        return math.sqrt((self.scorings[1] - self.scorings[0])**2)\n",
    "    \n",
    "    def label_centroids(self):\n",
    "        \"\"\"\n",
    "        This function labels centroid vectors, denoting whether a centroid belongs to one class (inlier) or the\n",
    "        other (outlier)\n",
    "        \n",
    "        :return: List of centroids, denoted by a class [0='Inlier',1='Outlier']\n",
    "        \"\"\"\n",
    "        centroids = self.model.cluster_centers_\n",
    "        mean_vect = self.__get_threshold_vector()\n",
    "        categorized_labels = [] # [[Self_Classified_Label,Centroid_Label],[Self_Classified_Label,Centroid_Label],...]\n",
    "        for i in range(len(centroids)):\n",
    "            if np.greater(centroids[i], mean_vect).any():\n",
    "                categorized_labels.append([1,i])\n",
    "            else:\n",
    "                categorized_labels.append([0,i])\n",
    "        return categorized_labels\n",
    "    \n",
    "    def evaluate_clusters(self):\n",
    "        \"\"\"\n",
    "        Evaluates cluster predictions (output cluster predictions) and matches them to the estimated cluster\n",
    "        labels (which are respectively considered to be greater than 3 standard deviations).\n",
    "        \n",
    "        NB: Roc Curve is outputting as a a triangle rather than a well spread out curve. The reson for this is\n",
    "        due to the binary label output denoted by the problem at hand - https://qiita.com/bmj0114/items/460424c110a8ce22d945\n",
    "        \n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        y = self.__calculate_expected_labels()\n",
    "        yhat = []\n",
    "        labelled_centroids = self.label_centroids()\n",
    "        print('Labeled Centroids: ' + str(labelled_centroids))\n",
    "        \n",
    "        for label in self.__y_labels:\n",
    "            for x, i in labelled_centroids:\n",
    "                if label == i:\n",
    "                    yhat.append(x)\n",
    "                    break\n",
    "        \n",
    "        print('Total Clusters [' + str(self.k) + ']\\nDistribution:')\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        print('Expected Label Distribution')\n",
    "        for i in range(len(unique)):\n",
    "            print('Label [' + str(unique[i]) + '] -> Count [' + str(counts[i]) + ']')\n",
    "            if unique[i] == 1:\n",
    "                self.scorings.append(counts[i])\n",
    "        unique, counts = np.unique(yhat, return_counts=True)\n",
    "        print('Clustered Label Distribution')\n",
    "        for i in range(len(unique)):\n",
    "            print('Label [' + str(unique[i]) + '] -> Count [' + str(counts[i]) + ']')\n",
    "            if unique[i] == 1:\n",
    "                self.scorings.append(counts[i])\n",
    "        \n",
    "        f1s = f1_score(y, yhat, average='binary')\n",
    "        print(\"\\n----\\nAccuracy: \" + str(accuracy_score(y, yhat)))\n",
    "        print(\"F-Score: \" + str(f1s))\n",
    "        print(\"---\")\n",
    "        print(\"Outlier Score Precision [\" + str(self.outlier_score_precision()) + \"]\")\n",
    "        \n",
    "        fpr_RF, tpr_RF, thresholds_RF = roc_curve(y, yhat)\n",
    "        auc_RF = roc_auc_score(y, yhat)\n",
    "        print('AUC RF:%.3f'% auc_RF)\n",
    "        plt.plot(fpr_RF, tpr_RF,'r-',label = 'RF AUC: %.3f'%auc_RF)\n",
    "        plt.plot([0,1],[0,1],'k-',label='random')\n",
    "        plt.plot([0,0,1,1],[0,1,1,1],'g-',label='perfect')\n",
    "        plt.legend()\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.show()\n",
    "        \n",
    "        return f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exhausting K\n",
    "\n",
    "Iterating over a number of K values, whilst gauging K under different number of combinations. Each K denotes the number of clusters as to group the data with. In turn, each cluster is then further categorized into 2 groups, those pertaining to:\n",
    "* Inliers\n",
    "* Outliers\n",
    "\n",
    "Accuracy, Precision, Recall & FScore metrics will be used to evaluate the effectiveness of each K-Means choice, with each experiment executed 3 times to anticipate for random variants of centroid positioning (Initial positioning is handled by K-Means++). Clustered amounts will be compared to a rough, hard placed metric, which determines any points to be outliers if they contain a data point above the 99th % standard deviation threshold.\n",
    "\n",
    "An additional metric (apart from those mentioned above) will be used during the evaluation of this experiment. Particular focus will be given to the number of clustered outlier points, discounting inliers all together. The score fluctuates at 0 < x < 2 , where in a score of 0 denotes perfect accuracy.\n",
    "\n",
    "NB: Achieved accuracy and F-Score Measures (Precision & Recall) are relatively unstable through this experiment. Therefore the following metrics are used to gauge the quality of the achieved results:\n",
    "* Error Score measured in worth of delta score (Number of scored outliers in comparison to actual outlier count).\n",
    "* ROC-Curve of True + False Positives achieved by the outlier detection mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def exhaust_k_possibilities(df):\n",
    "    \"\"\"\n",
    "    Method which attempts to exhaust a number of K options for the input pandas dataframe.\n",
    "    K Attempts will be attempted in steps of 2, so as to speed up the K finding process.\n",
    "\n",
    "    :param - df (Dataframe of type Pandas)\n",
    "    \n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    k_experiment_scorings = [] # k, score\n",
    "    for k in range(2, len(df.columns), 2):\n",
    "        print('Experiment start -------------[' + str(k) + ']-------------')\n",
    "        experiment_scorings = []\n",
    "        for i in range(3):\n",
    "            validInstance = ValidateKMeans(df, k, parallel_degree)\n",
    "            score = validInstance.evaluate_clusters()\n",
    "            experiment_scorings.append(score)\n",
    "        k_experiment_scorings.append([k, sum(experiment_scorings)/len(experiment_scorings)])\n",
    "        print('Experiment end -------------[' + str(k) + ']-------------')\n",
    "    \n",
    "    print('Estimating most optimum K score...')\n",
    "    final_score, final_k = 0,0\n",
    "    for k,score in k_experiment_scorings:\n",
    "        if score > final_score:\n",
    "            final_k = k\n",
    "            final_score = score # The closer score is to 0, the more accuracte the number of clustered outliers\n",
    "    print('\\n\\nExperiment Conclusion: K[' + str(final_k) + '] - score[' + str(final_score) + ']')\n",
    "    print(k_experiment_scorings)\n",
    "\n",
    "print('Experiment: REP_HIST_SNAPSHOT K-MEANS GRID SEARCH')\n",
    "exhaust_k_possibilities(df=rep_hist_snapshot_df)\n",
    "print('\\n\\n\\nExperiment: REP_VSQL_PLAN K-MEANS GRID SEARCH')\n",
    "exhaust_k_possibilities(df=rep_vsql_plan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest Outlier Detection\n",
    "\n",
    "This section moves past K-Means clustering prediction, and attempts to detect / flag outliers using the Isolation Forest ensemble algorithm.\n",
    "\n",
    "Return the anomaly score of each sample using the IsolationForest algorithm\n",
    "\n",
    "The IsolationForest ‘isolates’ observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature.\n",
    "\n",
    "Since recursive partitioning can be represented by a tree structure, the number of splittings required to isolate a sample is equivalent to the path length from the root node to the terminating node.\n",
    "\n",
    "This path length, averaged over a forest of such random trees, is a measure of normality and our decision function.\n",
    "\n",
    "Random partitioning produces noticeably shorter paths for anomalies. Hence, when a forest of random trees collectively produce shorter path lengths for particular samples, they are highly likely to be anomalies.\n",
    "\n",
    "This work is motivated through works presented below:\n",
    "***\n",
    "__Isolation Forest__ - https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf?q=isolation-forest\n",
    "\n",
    "Most existing model-based approaches to anomaly detection construct a profile of normal instances, then identify instances that do not conform to the normal profile as anomalies. Notable examples such as statistical methods, classification-based methods, and clustering-based methods all use this general approach. Two major drawbacks of this approach are: \n",
    "(i) the anomaly detector is optimized to profile normal instances, but not optimized to detect anomalies—as a consequence, the results of anomaly detection might not be as good as expected, causing too many false alarms (having normal instances identified as anomalies) or too few anomalies being detected; \n",
    "(ii) many existing methods are constrained to low dimensional data and small data size because of their high computational\n",
    "complexity.\n",
    "\n",
    "This paper proposes a different type of model-based method that explicitly isolates anomalies rather than profiles normal instances. To achieve this, our proposed method takes advantage of two anomalies’ quantitative properties: \n",
    "i) they are the minority consisting of fewer instances and \n",
    "ii) they have attribute-values that are very different from those of normal instances. \n",
    "\n",
    "In other words, anomalies are ‘few and different’, which make them more susceptible to isolation than normal points. We show in this paper that a tree structure can be constructed effectively to isolate every single instance. Because of their susceptibility to isolation, anomalies are isolated closer to the root of the tree; whereas normal points are isolated at the deeper end of the tree. This isolation characteristic of tree forms the basis of our method to detect anomalies, and we call this tree Isolation Tree or iTree.\n",
    "\n",
    "<div style=\"width:image width px; font-size:80%; text-align:center;\"><img src='Images/Iforest.jpg' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"padding-bottom:0.5em;\" /><b>Average path length convergence (Outliers have shorter depth than inliers, making them easier to detect)</b></div>\n",
    "\n",
    "Apart from the key difference of isolation versus profiling, iForest is distinguished from existing model-based, distance-based and density-based methods in the follow ways:\n",
    "* The isolation characteristic of iTrees enables them to build partial models and exploit sub-sampling to an extent that is not feasible in existing methods. Since a large part of an iTree that isolates normal points is not needed for anomaly detection; it does not need to be constructed. A small sample size produces better iTrees because the swamping and masking effects are reduced.\n",
    "* iForest utilizes no distance or density measures to detect anomalies. This eliminates major computational cost of distance calculation in all distance-based methods and density-based methods.\n",
    "* iForest has a linear time complexity with a low constant and a low memory requirement. To our best knowledge, the best-performing existing method achieves only approximate linear time complexity with high memory usage.\n",
    "* iForest has the capacity to scale up to handle extremely large data size and high-dimensional problems with a large number of irrelevant attributes.\n",
    "***\n",
    "__Ensembles for Unsupervised Outlier Detection: Challenges and Research Questions__ - https://www.kdd.org/exploration_files/V15-01-02-Zimek.pdf\n",
    "\n",
    "External Evaluation - If given a ground truth dataset where we know, for each object, whether it actually is an outlier or not, two ways of measuring the quality of the outlier detection result are commonly used in the literature. The first, more widely used measure of success is based on receiver operating characteristic (ROC) curves. ROC curves plot the true positive rate against the false positive rate. The resulting, monotone curves are usually turned into a measure by computing the area under this curve (AUC). This allows to display several results in a single graph and to compare the results numerically. For a random ranking result, both rates (true positive rate and false positive rate) will grow at the same rate, resulting in an area that approximately fills half of the space. For a perfect result, returning all outliers first and only then returning the inliers (i.e., we have 100% true positives before we even get the first false positive), the area under the corresponding curve will cover the available space completely, i.e., the maximal ROC AUC value is 1.0. Intuitively, the ROC AUC value can be seen as the probability that a pair of two randomly chosen objects, one positive example (outlier) and one negative example (inlier), is sorted correctly (i.e., the outlier is ranked before the inlier) [29]. ROC curves and ROC AUC analysis inherently treat the class imbalance problem by using the relative frequencies which makes them particularly popular for evaluation of outlier detection.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsolationForestWrapper:\n",
    "    \"\"\"\n",
    "    This class wraps up logic to the Isolation Forest Outlier Detection functionality.\n",
    "    \"\"\"\n",
    "    #\n",
    "    def __init__(self, X, contamination=.1, parallel_degree=1):\n",
    "        \"\"\"\n",
    "        Constructor Method\n",
    "        \n",
    "        :param X - Pandas Dataframe\n",
    "        :param contamination - Real value\n",
    "        :param parallel_degree - Parellization parameter\n",
    "        \n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.X = X.values\n",
    "        self.model = IsolationForest(n_estimators=100, max_samples=256, contamination=contamination, random_state=0, n_jobs=parallel_degree)\n",
    "        self.model.fit(self.X)\n",
    "        self.scorings = []\n",
    "        print(self.model)\n",
    "        \n",
    "    def __get_threshold_vector(self):\n",
    "        \"\"\"\n",
    "        Calculates a vector threshold, above which will be used to identify outliers. This method is used for evaluating the \n",
    "        trained machine-learning model.\n",
    "        \n",
    "        :return: Numpy vector which represents a threshold vector\n",
    "        \"\"\"\n",
    "        mean = np.mean(self.X)\n",
    "        std = np.std(self.X)\n",
    "        std3 = np.multiply(std, 3)\n",
    "        return np.add(mean, std3)\n",
    "    \n",
    "    def __calculate_expected_labels(self):\n",
    "        \"\"\"\n",
    "        Estimates label clustering by comparing them to a threshold mean value. These labels will be used to gauge a scoring \n",
    "        for the unsupervised clustering achieved by the IForest algorithm.\n",
    "        \n",
    "        :return: A list of the expected output labels.\n",
    "        \"\"\"\n",
    "        mean_vect = self.__get_threshold_vector()\n",
    "        mean_labels = []\n",
    "        for vector in self.X:\n",
    "            if np.greater(vector, mean_vect).any():\n",
    "                mean_labels.append(-1)\n",
    "            else:\n",
    "                mean_labels.append(1)\n",
    "        return mean_labels\n",
    "    \n",
    "    def retrieve_scorings(self):\n",
    "        \"\"\"\n",
    "        This method retrieves the per vector IForest scorings, after the model has been trained.\n",
    "        \n",
    "        :return: List of Iforest scorings\n",
    "        \"\"\"\n",
    "        return self.model.decision_function(self.X)\n",
    "    \n",
    "    def plot_scorings(self):\n",
    "        \"\"\"\n",
    "        Distributes into 50 bin histogram.\n",
    "        \n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        scores = self.retrieve_scorings()\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.hist(scores, bins=50);\n",
    "        plt.title('Isolation Forest Scorings')\n",
    "        plt.show()\n",
    "    \n",
    "    def predict_labels(self):\n",
    "        \"\"\"\n",
    "        Caries out predicton on feature matrix 'X'\n",
    "        \n",
    "        :return: List of predicted output labels.\n",
    "        \"\"\"\n",
    "        return self.model.predict(self.X) \n",
    "    \n",
    "    def outlier_score_accuracy(self):\n",
    "        \"\"\"\n",
    "        Returns a score which evaluates the accuracy with the number of isolated outliers. The closer to 0 the score, the more accurate the evaluation\n",
    "        \n",
    "        :return: Positive Integer (Squared and Square Rooted) denoting the delta scoring between predicted and actual\n",
    "        \"\"\"\n",
    "        if self.scorings is None or len(self.scorings) == 0:\n",
    "            raise ValueError('Scorings list is empty!')\n",
    "        elif len(self.scorings) > 2:\n",
    "            raise ValueError('Scorings list length is greater than 2! Must be composed of the following structure [scoring1, scoring2]')\n",
    "        \n",
    "        return math.sqrt((self.scorings[1] - self.scorings[0])**2)\n",
    "    \n",
    "    def evaluate_labels(self):\n",
    "        \"\"\"\n",
    "        This function calculates the expected inlier and outlier vectors based on a statistical threshold, and then matches\n",
    "        these expectations to the IForest predictions. Results are plotted, and gauge by scored ROC score, and lowest error delta\n",
    "        \n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        y = self.__calculate_expected_labels()\n",
    "        yhat = self.predict_labels()\n",
    "        \n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        print('Expected Label Distribution')\n",
    "        for i in range(len(unique)):\n",
    "            print('Label [' + str(unique[i]) + '] -> Count [' + str(counts[i]) + ']')\n",
    "            if unique[i] == -1:\n",
    "                self.scorings.append(counts[i])\n",
    "        unique, counts = np.unique(yhat, return_counts=True)\n",
    "        print('Isolated Label Distribution')\n",
    "        for i in range(len(unique)):\n",
    "            print('Label [' + str(unique[i]) + '] -> Count [' + str(counts[i]) + ']')\n",
    "            if unique[i] == -1:\n",
    "                self.scorings.append(counts[i])\n",
    "        \n",
    "        f1s = f1_score(y, yhat, average='binary')\n",
    "        print(\"\\n----\\nAccuracy: \" + str(accuracy_score(y, yhat)))\n",
    "        print(\"F-Score: \" + str(f1s))\n",
    "        print('---')\n",
    "        print(\"Outlier Score Precision [\" + str(self.outlier_score_accuracy()) + \"]\")\n",
    "        \n",
    "        fpr_RF, tpr_RF, thresholds_RF = roc_curve(y, yhat)\n",
    "        print(fpr_RF)\n",
    "        print(tpr_RF)\n",
    "        auc_RF = roc_auc_score(y, yhat)\n",
    "        print('AUC RF:%.3f'% auc_RF)\n",
    "        plt.plot(fpr_RF, tpr_RF,'r-',label = 'RF AUC: %.3f'%auc_RF)\n",
    "        plt.plot([0,1],[0,1],'k-',label='random')\n",
    "        plt.plot([0,0,1,1],[0,1,1,1],'g-',label='perfect')\n",
    "        plt.legend()\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.show()\n",
    "        \n",
    "        return f1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exhausting C\n",
    "\n",
    "Iterating over a number of c (contamination) values, whilst gauging c under different number of combinations. Each c denotes the parametric value for a particular IForest implementation. Each parameterized value is gauged according to how well the following are categorized as:\n",
    "* Inliers\n",
    "* Outliers\n",
    "\n",
    "Accuracy, Precision, Recall & FScore metrics will be used to evaluate the effectiveness of each IForest contamination parameter. Inlier / Outlier values will be compared to a rough, hard placed metric, which determines any points to be inliers or outliers if they contain a data point above the 99th % standard deviation threshold.\n",
    "\n",
    "An additional metric (apart from those mentioned above) will be used during the evaluation of this experiment. Particular focus will be given to the number of clustered outlier points, discounting inliers all together. The score fluctuates at 0 < x < 1 , where in a score of 0 denotes perfect accuracy. This is considered to be the delta error.\n",
    "\n",
    "NB: Achieved accuracy and F-Score Measures (Precision & Recall) are relatively unstable through this experiment. Therefore the following metrics are used to gauge the quality of the achieved results:\n",
    "* Error Score measured in worth of delta score (Number of scored outliers in comparison to actual outlier count).\n",
    "* ROC-Curve of True + False Positives achieved by the outlier detection mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def exhaust_contamination_possibilities(df):\n",
    "    \"\"\"\n",
    "    Method which attempts to exhaust a number of contamination options for the input pandas dataframe.\n",
    "    A number of attempts will be attempted so to evaluate the best contamination value.\n",
    "\n",
    "    :param - df (Dataframe of type Pandas)\n",
    "    \n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    k_experiment_scorings = [] # k, score\n",
    "    #for c in range(.2, 2, .2):\n",
    "    contamination = .1\n",
    "    threshold = 1\n",
    "    while contamination <= threshold:\n",
    "        print('Experiment start -------------[' + str(contamination) + ']-------------')\n",
    "        experiment_scorings = []\n",
    "        for i in range(3):\n",
    "            ifw = IsolationForestWrapper(X=df, contamination=contamination, parallel_degree=parallel_degree)\n",
    "            ifw.plot_scorings()\n",
    "            score = ifw.evaluate_labels()\n",
    "            experiment_scorings.append(score)\n",
    "        k_experiment_scorings.append([contamination, sum(experiment_scorings)/len(experiment_scorings)]) # ['Contamination value','average accuracy from 3 runs']\n",
    "        print('Experiment end -------------[' + str(contamination) + ']-------------')\n",
    "        contamination += .1\n",
    "    \n",
    "    print('Estimating most optimum contamination score...')\n",
    "    final_score, final_c = 0,0\n",
    "    for c, score in k_experiment_scorings:\n",
    "        if score > final_score:\n",
    "            final_score = score\n",
    "            final_c = c\n",
    "    print('\\n\\nExperiment Conclusion: Best Contamination[' + str(final_c) + '] - Minimum (Best) Error Score[' + str(final_score) + ']')\n",
    "\n",
    "# REP_HIST_SNAPSHOT\n",
    "print('Experiment: REP_HIST_SNAPSHOT CONTAMINATION GRID SEARCH')\n",
    "exhaust_contamination_possibilities(df=rep_hist_snapshot_df)\n",
    "\n",
    "# REP_VSQL_PLAN\n",
    "print('Experiment: REP_VSQL_PLAN CONTAMINATION GRID SEARCH')\n",
    "exhaust_contamination_possibilities(df=rep_vsql_plan_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
