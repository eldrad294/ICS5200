{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schedule TPC-DS 1 Dimensional Reduction (REP_HIST_SNAPSHOT)\n",
    "\n",
    "This notebook is dedicated to dataset profiling. In this notebook, dimensional reduction techniques will be implemented so as to categorize which features belay the most information to address the problem at hand - Workload Prediction. Due to the vast feature space which have been gathered during a workload's execution, manual techniques at determining which are most detrimental is not sufficient. \n",
    "\n",
    "Therefore the following work puts emphasis on automated techniques so as to determine out of the vast feature space which are most important to base future models upon. The proposed techniques will focus on each of the proposed four datasets:\n",
    "\n",
    "* __REP_HIST_SNAPSHOT__\n",
    "* REP_HIST_SYSMETRIC_SUMMARY\n",
    "* REP_HIST_SYSSTAT\n",
    "* REP_VSQL_PLAN\n",
    "\n",
    "Further more, dimensionality reduction will be covered from two different aspects. First, feature selection techniques will be implemented to elimate features which are considered unimportant using entropy based measures. Once a number of 'static' features are pruned from the original dataset, the remainding features are then processed through a Singular Value Decomposition process, where in features are reduced through PCA (Principal Compoenent Analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, chi2, RFE\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Cell\n",
    "\n",
    "Tweak parametric changes from this cell to influence outcome of experiment.\n",
    "\n",
    "* tpcds - Schema upon which to operate test\n",
    "* debug_mode - Determines whether to plot graphs or not, useful for development purposes\n",
    "* low_quartile_limit - Lower Quartile threshold to detect outliers\n",
    "* upper_quartile_limit - Upper Quartile threshold to detect outliers\n",
    "* test_split - Denotes which Data Split to operate under when it comes to training / validation\n",
    "* nrows - Number of rows to read from csv file\n",
    "* top_n_features - Number of top features to focus on\n",
    "* parallel_degree - Number of parallel threads to train models with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Config\n",
    "tpcds='TPCDS1' \n",
    "debug_mode=True\n",
    "low_quartile_limit = .001  \n",
    "upper_quartile_limit = .999\n",
    "test_split=.3 # \n",
    "nrows=10000\n",
    "top_n_features=45  # Calculated as half the anticipated data set feature count.\n",
    "parallel_degree=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from file into Pandas Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SNAP_ID', 'DBID', 'INSTANCE_NUMBER', 'SQL_ID', 'PLAN_HASH_VALUE',\n",
      "       'OPTIMIZER_COST', 'OPTIMIZER_MODE', 'OPTIMIZER_ENV_HASH_VALUE',\n",
      "       'SHARABLE_MEM', 'LOADED_VERSIONS', 'VERSION_COUNT', 'MODULE', 'ACTION',\n",
      "       'SQL_PROFILE', 'FORCE_MATCHING_SIGNATURE', 'PARSING_SCHEMA_ID',\n",
      "       'PARSING_SCHEMA_NAME', 'PARSING_USER_ID', 'FETCHES_TOTAL',\n",
      "       'FETCHES_DELTA', 'END_OF_FETCH_COUNT_TOTAL', 'END_OF_FETCH_COUNT_DELTA',\n",
      "       'SORTS_TOTAL', 'SORTS_DELTA', 'EXECUTIONS_TOTAL', 'EXECUTIONS_DELTA',\n",
      "       'PX_SERVERS_EXECS_TOTAL', 'PX_SERVERS_EXECS_DELTA', 'LOADS_TOTAL',\n",
      "       'LOADS_DELTA', 'INVALIDATIONS_TOTAL', 'INVALIDATIONS_DELTA',\n",
      "       'PARSE_CALLS_TOTAL', 'PARSE_CALLS_DELTA', 'DISK_READS_TOTAL',\n",
      "       'DISK_READS_DELTA', 'BUFFER_GETS_TOTAL', 'BUFFER_GETS_DELTA',\n",
      "       'ROWS_PROCESSED_TOTAL', 'ROWS_PROCESSED_DELTA', 'CPU_TIME_TOTAL',\n",
      "       'CPU_TIME_DELTA', 'ELAPSED_TIME_TOTAL', 'ELAPSED_TIME_DELTA',\n",
      "       'IOWAIT_TOTAL', 'IOWAIT_DELTA', 'CLWAIT_TOTAL', 'CLWAIT_DELTA',\n",
      "       'APWAIT_TOTAL', 'APWAIT_DELTA', 'CCWAIT_TOTAL', 'CCWAIT_DELTA',\n",
      "       'DIRECT_WRITES_TOTAL', 'DIRECT_WRITES_DELTA', 'PLSEXEC_TIME_TOTAL',\n",
      "       'PLSEXEC_TIME_DELTA', 'JAVEXEC_TIME_TOTAL', 'JAVEXEC_TIME_DELTA',\n",
      "       'IO_OFFLOAD_ELIG_BYTES_TOTAL', 'IO_OFFLOAD_ELIG_BYTES_DELTA',\n",
      "       'IO_INTERCONNECT_BYTES_TOTAL', 'IO_INTERCONNECT_BYTES_DELTA',\n",
      "       'PHYSICAL_READ_REQUESTS_TOTAL', 'PHYSICAL_READ_REQUESTS_DELTA',\n",
      "       'PHYSICAL_READ_BYTES_TOTAL', 'PHYSICAL_READ_BYTES_DELTA',\n",
      "       'PHYSICAL_WRITE_REQUESTS_TOTAL', 'PHYSICAL_WRITE_REQUESTS_DELTA',\n",
      "       'PHYSICAL_WRITE_BYTES_TOTAL', 'PHYSICAL_WRITE_BYTES_DELTA',\n",
      "       'OPTIMIZED_PHYSICAL_READS_TOTAL', 'OPTIMIZED_PHYSICAL_READS_DELTA',\n",
      "       'CELL_UNCOMPRESSED_BYTES_TOTAL', 'CELL_UNCOMPRESSED_BYTES_DELTA',\n",
      "       'IO_OFFLOAD_RETURN_BYTES_TOTAL', 'IO_OFFLOAD_RETURN_BYTES_DELTA',\n",
      "       'BIND_DATA', 'FLAG', 'CON_DBID', 'CON_ID', 'SQL_TEXT', 'COMMAND_TYPE',\n",
      "       'STARTUP_TIME', 'BEGIN_INTERVAL_TIME', 'END_INTERVAL_TIME',\n",
      "       'FLUSH_ELAPSED', 'SNAP_LEVEL', 'ERROR_COUNT', 'SNAP_FLAG',\n",
      "       'SNAP_TIMEZONE'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Table [REP_HIST_SNAPSHOT] - (10000, 90)\n"
     ]
    }
   ],
   "source": [
    "# Root path\n",
    "#root_dir = 'C:/Users/gabriel.sammut/University/Data_ICS5200/Schedule/' + tpcds\n",
    "root_dir = 'D:/Projects/Datagenerated_ICS5200/Schedule/' + tpcds\n",
    "\n",
    "# Open Data\n",
    "rep_hist_snapshot_path = root_dir + '/rep_hist_snapshot.csv'\n",
    "\n",
    "rep_hist_snapshot_df = pd.read_csv(rep_hist_snapshot_path,nrows=nrows)\n",
    "\n",
    "def prettify_header(headers):\n",
    "    \"\"\"\n",
    "    Cleans header list from unwated character strings\n",
    "    \"\"\"\n",
    "    header_list = []\n",
    "    [header_list.append(header.replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"\").replace(\",\",\"\")) for header in headers]\n",
    "    return header_list\n",
    "\n",
    "rep_hist_snapshot_df.columns = prettify_header(rep_hist_snapshot_df.columns.values)\n",
    "print(rep_hist_snapshot_df.columns)\n",
    "print('\\n\\nTable [REP_HIST_SNAPSHOT] - ' + str(rep_hist_snapshot_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "\n",
    "The correlation of resources consumed (y) per snapshot (X) define our feature space. Since the objective here is to attempt to predict what resources will be incurred ahead of time, the problem can be defined as a number of questions:\n",
    "\n",
    "* Q: What resources can I predict to be in usage at point N in time?\n",
    "* Q: What resources should I be predicting that accurately portray a schedule's workload?\n",
    "* Q: What knowledge/data do I have ahead of time which I can use to base my predictions off?\n",
    "\n",
    "Due to the vast feature space in the available metrics monitored and captured during a workload's execution, it is important to rank which attribute is most beneficial than others. Additionally, it is important to analyze such features individually, and considerate of other features in two types of analysis:\n",
    "\n",
    "* Univariate Analysis\n",
    "* Multivariate Analysis\n",
    "\n",
    "Furthermore, multiple types of feature ranking / analysis techniques ara available, amongst which will be considered:\n",
    "\n",
    "* Filter Methods\n",
    "* Wrapper Methods\n",
    "* Embedded Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "We apply a number of preprocessing techniques to the presented dataframes, particularly to normalize and/or scale feature vectors into a more suitable representation for downstream estimators:\n",
    "\n",
    "Relative Links:\n",
    "* http://scikit-learn.org/stable/modules/preprocessing.html\n",
    "* https://machinelearningmastery.com/improve-model-accuracy-with-data-pre-processing/\n",
    "* https://machinelearningmastery.com/normalize-standardize-time-series-data-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for NaN Values\n",
    "\n",
    "Checking dataframes for potential missing values/data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table REP_HIST_SNAPSHOT: ['OPTIMIZER_COST', 'OPTIMIZER_MODE', 'OPTIMIZER_ENV_HASH_VALUE', 'LOADED_VERSIONS', 'MODULE', 'ACTION', 'SQL_PROFILE', 'PARSING_SCHEMA_ID', 'PARSING_SCHEMA_NAME', 'PARSING_USER_ID', 'FETCHES_TOTAL', 'FETCHES_DELTA', 'END_OF_FETCH_COUNT_TOTAL', 'END_OF_FETCH_COUNT_DELTA', 'SORTS_TOTAL', 'SORTS_DELTA', 'EXECUTIONS_TOTAL', 'EXECUTIONS_DELTA', 'PX_SERVERS_EXECS_TOTAL', 'PX_SERVERS_EXECS_DELTA', 'LOADS_TOTAL', 'LOADS_DELTA', 'INVALIDATIONS_TOTAL', 'INVALIDATIONS_DELTA', 'PARSE_CALLS_TOTAL', 'DISK_READS_TOTAL', 'DISK_READS_DELTA', 'BUFFER_GETS_TOTAL', 'BUFFER_GETS_DELTA', 'ROWS_PROCESSED_TOTAL', 'ROWS_PROCESSED_DELTA', 'CPU_TIME_TOTAL', 'ELAPSED_TIME_TOTAL', 'IOWAIT_TOTAL', 'IOWAIT_DELTA', 'CLWAIT_TOTAL', 'CLWAIT_DELTA', 'APWAIT_TOTAL', 'APWAIT_DELTA', 'CCWAIT_TOTAL', 'CCWAIT_DELTA', 'DIRECT_WRITES_TOTAL', 'DIRECT_WRITES_DELTA', 'PLSEXEC_TIME_TOTAL', 'PLSEXEC_TIME_DELTA', 'JAVEXEC_TIME_TOTAL', 'JAVEXEC_TIME_DELTA', 'IO_OFFLOAD_ELIG_BYTES_TOTAL', 'IO_OFFLOAD_ELIG_BYTES_DELTA', 'IO_INTERCONNECT_BYTES_TOTAL', 'IO_INTERCONNECT_BYTES_DELTA', 'PHYSICAL_READ_REQUESTS_TOTAL', 'PHYSICAL_READ_REQUESTS_DELTA', 'PHYSICAL_READ_BYTES_TOTAL', 'PHYSICAL_READ_BYTES_DELTA', 'PHYSICAL_WRITE_REQUESTS_TOTAL', 'PHYSICAL_WRITE_REQUESTS_DELTA', 'PHYSICAL_WRITE_BYTES_TOTAL', 'PHYSICAL_WRITE_BYTES_DELTA', 'OPTIMIZED_PHYSICAL_READS_TOTAL', 'OPTIMIZED_PHYSICAL_READS_DELTA', 'CELL_UNCOMPRESSED_BYTES_TOTAL', 'CELL_UNCOMPRESSED_BYTES_DELTA', 'IO_OFFLOAD_RETURN_BYTES_TOTAL', 'IO_OFFLOAD_RETURN_BYTES_DELTA', 'BIND_DATA', 'FLAG']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_na_columns(df):\n",
    "    \"\"\"\n",
    "    Return columns which consist of NAN values\n",
    "    \"\"\"\n",
    "    na_list = []\n",
    "    for head in df.columns:\n",
    "        if df[head].isnull().values.any():\n",
    "            na_list.append(head)\n",
    "    return na_list\n",
    "\n",
    "print(\"Table REP_HIST_SNAPSHOT: \" + str(get_na_columns(df=rep_hist_snapshot_df)) + \"\\n\\n\")\n",
    "\n",
    "def fill_na(df):\n",
    "    \"\"\"\n",
    "    Replaces NA columns with 0s\n",
    "    \"\"\"\n",
    "    return df.fillna(0)\n",
    "\n",
    "# Populating NaN values with amount '0'\n",
    "rep_hist_snapshot_df = fill_na(df=rep_hist_snapshot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding\n",
    "\n",
    "Since this experiment deals with prediction of upcoming SQL_IDs, respectice SQL_ID strings need to labelled as a numeric representation. Label Encoder will be used here to convert SQL_ID's into a numeric format, which are in turn used for training. Evaluation (achieved predictions) is done so also in numeric format, at which point the label encoder is eventually used to decode back the labels into the original, respetive SQL_ID representation.\n",
    "\n",
    "This section of the experiment additionally converts the targetted label into a binarized version of the previous achieved categorical numeric values.\n",
    "\n",
    "* https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------BEFORE----------\n",
      "(10000, 90)\n",
      "   SNAP_ID        DBID  INSTANCE_NUMBER         SQL_ID  PLAN_HASH_VALUE  \\\n",
      "0    43414  2634225673                1  03ggjrmy0wa1w       3995561526   \n",
      "1    43414  2634225673                1  06dymzb481vnd       3652725360   \n",
      "2    43414  2634225673                1  0aq14dznn91rg        389704395   \n",
      "3    43414  2634225673                1  0f60bzgt9127c       4070789595   \n",
      "4    43414  2634225673                1  0ga8vk4nftz45       3344603960   \n",
      "5    43414  2634225673                1  13a9r2xkx1bxb       2888767244   \n",
      "6    43414  2634225673                1  13ys8ux8xvrbm                0   \n",
      "7    43414  2634225673                1  14f5ngrj3cc5h       2481783843   \n",
      "8    43414  2634225673                1  1jhyrdp21f2q6       1487882830   \n",
      "9    43414  2634225673                1  1pv23p59mjs0v        773196278   \n",
      "\n",
      "   OPTIMIZER_COST OPTIMIZER_MODE  OPTIMIZER_ENV_HASH_VALUE  SHARABLE_MEM  \\\n",
      "0           877.0       ALL_ROWS              2.580874e+08         78554   \n",
      "1         21525.0       ALL_ROWS              3.207305e+09        518602   \n",
      "2           836.0       ALL_ROWS              2.580874e+08         78385   \n",
      "3           312.0       ALL_ROWS              2.580874e+08        105537   \n",
      "4           300.0       ALL_ROWS              2.580874e+08        128838   \n",
      "5           281.0       ALL_ROWS              2.580874e+08        152609   \n",
      "6             1.0       ALL_ROWS              2.537083e+09        154339   \n",
      "7           442.0       ALL_ROWS              2.580874e+08         79002   \n",
      "8           838.0       ALL_ROWS              2.580874e+08        179345   \n",
      "9           177.0       ALL_ROWS              2.580874e+08         54027   \n",
      "\n",
      "   LOADED_VERSIONS      ...        \\\n",
      "0              3.0      ...         \n",
      "1              5.0      ...         \n",
      "2              3.0      ...         \n",
      "3              4.0      ...         \n",
      "4              5.0      ...         \n",
      "5              4.0      ...         \n",
      "6              4.0      ...         \n",
      "7              3.0      ...         \n",
      "8              7.0      ...         \n",
      "9              2.0      ...         \n",
      "\n",
      "                                            SQL_TEXT COMMAND_TYPE  \\\n",
      "0  select /*+  parallel_index(t, \"CS_BILL_CUSTOME...            3   \n",
      "1  with inv as\\n(select w_warehouse_name,w_wareho...            3   \n",
      "2  select /*+  parallel_index(t, \"CS_BILL_HDEMO_S...            3   \n",
      "3  select /*+  parallel_index(t, \"SYS_C0021464\",6...            3   \n",
      "4  select /*+  parallel_index(t, \"INV_WAREHOUSE_S...            3   \n",
      "5  select /*+  parallel_index(t, \"SS_STORE_SK_IND...            3   \n",
      "6  insert into sys.wri$_optstat_opr_tasks (op_id,...            2   \n",
      "7  select /*+  parallel_index(t, \"WS_SHIP_ADDR_SK...            3   \n",
      "8  select /*+  parallel_index(t, \"CS_SHIP_HDEMO_S...            3   \n",
      "9  select /*+  parallel_index(t, \"SR_CUSTOMER_SK_...            3   \n",
      "\n",
      "          STARTUP_TIME         BEGIN_INTERVAL_TIME  \\\n",
      "0  2018-10-04 23:04:59  2018-11-16 17:33:34.367000   \n",
      "1  2018-10-04 23:04:59  2018-11-16 17:33:34.367000   \n",
      "2  2018-10-04 23:04:59  2018-11-16 17:33:34.367000   \n",
      "3  2018-10-04 23:04:59  2018-11-16 17:33:34.367000   \n",
      "4  2018-10-04 23:04:59  2018-11-16 17:33:34.367000   \n",
      "5  2018-10-04 23:04:59  2018-11-16 17:33:34.367000   \n",
      "6  2018-10-04 23:04:59  2018-11-16 17:33:34.367000   \n",
      "7  2018-10-04 23:04:59  2018-11-16 17:33:34.367000   \n",
      "8  2018-10-04 23:04:59  2018-11-16 17:33:34.367000   \n",
      "9  2018-10-04 23:04:59  2018-11-16 17:33:34.367000   \n",
      "\n",
      "            END_INTERVAL_TIME   FLUSH_ELAPSED SNAP_LEVEL  ERROR_COUNT  \\\n",
      "0  2018-11-16 17:34:37.060000  0:00:00.100000          1            0   \n",
      "1  2018-11-16 17:34:37.060000  0:00:00.100000          1            0   \n",
      "2  2018-11-16 17:34:37.060000  0:00:00.100000          1            0   \n",
      "3  2018-11-16 17:34:37.060000  0:00:00.100000          1            0   \n",
      "4  2018-11-16 17:34:37.060000  0:00:00.100000          1            0   \n",
      "5  2018-11-16 17:34:37.060000  0:00:00.100000          1            0   \n",
      "6  2018-11-16 17:34:37.060000  0:00:00.100000          1            0   \n",
      "7  2018-11-16 17:34:37.060000  0:00:00.100000          1            0   \n",
      "8  2018-11-16 17:34:37.060000  0:00:00.100000          1            0   \n",
      "9  2018-11-16 17:34:37.060000  0:00:00.100000          1            0   \n",
      "\n",
      "   SNAP_FLAG  SNAP_TIMEZONE  \n",
      "0          1        1:00:00  \n",
      "1          1        1:00:00  \n",
      "2          1        1:00:00  \n",
      "3          1        1:00:00  \n",
      "4          1        1:00:00  \n",
      "5          1        1:00:00  \n",
      "6          1        1:00:00  \n",
      "7          1        1:00:00  \n",
      "8          1        1:00:00  \n",
      "9          1        1:00:00  \n",
      "\n",
      "[10 rows x 90 columns]\n",
      "----------AFTER----------\n",
      "(10000, 90)\n",
      "   SNAP_ID        DBID  INSTANCE_NUMBER  SQL_ID  PLAN_HASH_VALUE  \\\n",
      "0    43414  2634225673                1       0       3995561526   \n",
      "1    43414  2634225673                1       1       3652725360   \n",
      "2    43414  2634225673                1       2        389704395   \n",
      "3    43414  2634225673                1       3       4070789595   \n",
      "4    43414  2634225673                1       4       3344603960   \n",
      "5    43414  2634225673                1       5       2888767244   \n",
      "6    43414  2634225673                1       6                0   \n",
      "7    43414  2634225673                1       7       2481783843   \n",
      "8    43414  2634225673                1       8       1487882830   \n",
      "9    43414  2634225673                1       9        773196278   \n",
      "\n",
      "   OPTIMIZER_COST  OPTIMIZER_MODE  OPTIMIZER_ENV_HASH_VALUE  SHARABLE_MEM  \\\n",
      "0           877.0               0              2.580874e+08         78554   \n",
      "1         21525.0               0              3.207305e+09        518602   \n",
      "2           836.0               0              2.580874e+08         78385   \n",
      "3           312.0               0              2.580874e+08        105537   \n",
      "4           300.0               0              2.580874e+08        128838   \n",
      "5           281.0               0              2.580874e+08        152609   \n",
      "6             1.0               0              2.537083e+09        154339   \n",
      "7           442.0               0              2.580874e+08         79002   \n",
      "8           838.0               0              2.580874e+08        179345   \n",
      "9           177.0               0              2.580874e+08         54027   \n",
      "\n",
      "   LOADED_VERSIONS      ...        SQL_TEXT  COMMAND_TYPE  STARTUP_TIME  \\\n",
      "0              3.0      ...               0             3             0   \n",
      "1              5.0      ...               1             3             0   \n",
      "2              3.0      ...               2             3             0   \n",
      "3              4.0      ...               3             3             0   \n",
      "4              5.0      ...               4             3             0   \n",
      "5              4.0      ...               5             3             0   \n",
      "6              4.0      ...               6             2             0   \n",
      "7              3.0      ...               7             3             0   \n",
      "8              7.0      ...               8             3             0   \n",
      "9              2.0      ...               9             3             0   \n",
      "\n",
      "   BEGIN_INTERVAL_TIME  END_INTERVAL_TIME  FLUSH_ELAPSED  SNAP_LEVEL  \\\n",
      "0                    0                  0              0           1   \n",
      "1                    0                  0              0           1   \n",
      "2                    0                  0              0           1   \n",
      "3                    0                  0              0           1   \n",
      "4                    0                  0              0           1   \n",
      "5                    0                  0              0           1   \n",
      "6                    0                  0              0           1   \n",
      "7                    0                  0              0           1   \n",
      "8                    0                  0              0           1   \n",
      "9                    0                  0              0           1   \n",
      "\n",
      "   ERROR_COUNT  SNAP_FLAG  SNAP_TIMEZONE  \n",
      "0            0          1              0  \n",
      "1            0          1              0  \n",
      "2            0          1              0  \n",
      "3            0          1              0  \n",
      "4            0          1              0  \n",
      "5            0          1              0  \n",
      "6            0          1              0  \n",
      "7            0          1              0  \n",
      "8            0          1              0  \n",
      "9            0          1              0  \n",
      "\n",
      "[10 rows x 90 columns]\n"
     ]
    }
   ],
   "source": [
    "class LabelEncoder:\n",
    "    \"\"\"\n",
    "    Scikit Label Encoder was acting up with the following error whilst using the transform function, even though I tripled \n",
    "    checked that the passed data was exactly the same as the one used for training:\n",
    "    \n",
    "    * https://stackoverflow.com/questions/46288517/getting-valueerror-y-contains-new-labels-when-using-scikit-learns-labelencoder\n",
    "    \n",
    "    So I have rebuilt a similar functionality to categorize my data into numeric digits, as the LabelEncoder is supposed to do.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.__class_map = {}\n",
    "        self.__integer_counter = 0\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        :param - X: python list\n",
    "        \"\"\"\n",
    "        for val in X:\n",
    "            if val not in self.__class_map:\n",
    "                self.__class_map[val] = self.__integer_counter\n",
    "                self.__integer_counter += 1\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        param - X: python list\n",
    "        \"\"\"\n",
    "        encoded_map = []\n",
    "        for val in X:\n",
    "            if val in self.__class_map:\n",
    "                value = self.__class_map[val]\n",
    "                encoded_map.append(value)\n",
    "            else:\n",
    "                raise ValueError('Label Mismatch - Encountered a label which was not trained on.')\n",
    "        return encoded_map\n",
    "    \n",
    "    def get_class_map(self):\n",
    "        \"\"\"\n",
    "        Returns original classes as a list\n",
    "        \"\"\"\n",
    "        class_map = []\n",
    "        for key, value in self.__class_map.items():\n",
    "            class_map.append(key)\n",
    "        return class_map\n",
    "    \n",
    "    def get_encoded_map(self):\n",
    "        \"\"\"\n",
    "        Returns class encodings as a list\n",
    "        \"\"\"\n",
    "        encoded_map = []\n",
    "        for key, value in self.__class_map.items():\n",
    "            encoded_map.append(value)\n",
    "        return encoded_map\n",
    "\n",
    "print('-'*10 + 'BEFORE' + '-'*10)\n",
    "print(rep_hist_snapshot_df.shape)\n",
    "print(rep_hist_snapshot_df.head(10))\n",
    "\n",
    "for col in rep_hist_snapshot_df.columns:\n",
    "    first_ten_vals = rep_hist_snapshot_df[col].iloc[0:nrows]\n",
    "    try:\n",
    "        for val in first_ten_vals:\n",
    "            val = int(val)\n",
    "        continue  # If value is type casted successfully, then move on to the next value since it doesn't require label encoding\n",
    "    except ValueError:\n",
    "        le = LabelEncoder()  # Encode column with labels\n",
    "        val_list = rep_hist_snapshot_df[col].tolist()\n",
    "        le.fit(val_list)\n",
    "        transformed_map = le.transform(val_list)\n",
    "        rep_hist_snapshot_df[col] = pd.DataFrame(transformed_map, columns=[col])\n",
    "\n",
    "print('-'*10 + 'AFTER' + '-'*10)\n",
    "print(rep_hist_snapshot_df.shape)\n",
    "print(rep_hist_snapshot_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Negative Values\n",
    "\n",
    "A function which retrieves a count per column for nay negative values it might contain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------WITH NEGATIVE VALUES---------------\n",
      "Table REP_HIST_SNAPSHOT: [['IO_OFFLOAD_RETURN_BYTES_TOTAL', 519]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "---------------WITHOUT NEGATIVE VALUES---------------\n",
      "Table REP_HIST_SNAPSHOT: [['IO_OFFLOAD_RETURN_BYTES_TOTAL', 519]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NegativeHandler:\n",
    "    \"\"\"\n",
    "    This class contains logic pertaining to handling of negative values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        Class constructor.\n",
    "        :param df:      (Pandas) Data matrix containing data.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.__df = df\n",
    "        self.__headers = df.columns\n",
    "\n",
    "    def count_neg_df(self):\n",
    "        \"\"\"\n",
    "        Return columns with respective negative value count.\n",
    "        :return: (List) Retrieves list of row positions denoting negative occurance.\n",
    "        \"\"\"\n",
    "        neg_list = []\n",
    "        for head in self.__headers:\n",
    "            count = 0\n",
    "            try:\n",
    "                count = sum(n < 0 for n in self.__df[head].values.flatten())\n",
    "            except Exception:\n",
    "                pass\n",
    "                #print('Non numeric column [' + head + ']')\n",
    "            if count > 0:\n",
    "                neg_list.append([head,count])\n",
    "        return neg_list\n",
    "\n",
    "    def fill_neg(self):\n",
    "        \"\"\"\n",
    "        Sets any data anomilies resulting in negative values to 0\n",
    "        :return: (Pandas) Dataframe with ammended negative values.\n",
    "        \"\"\"\n",
    "        headers = self.count_neg_df()\n",
    "        df = self.__df\n",
    "        for head in headers:\n",
    "            try:\n",
    "                df[df[head] < 0] = 0\n",
    "            except Exception:\n",
    "                pass\n",
    "                #print('Non numeric column [' + head + ']')\n",
    "        return df\n",
    "\n",
    "nh = NegativeHandler(df=rep_hist_snapshot_df)\n",
    "    \n",
    "# Check For Negative Values within dataframes\n",
    "print('---------------WITH NEGATIVE VALUES---------------')\n",
    "print(\"Table REP_HIST_SNAPSHOT: \" + str(nh.count_neg_df()) + \"\\n\\n\")\n",
    "\n",
    "# Replace Negative Values with a minimal threshold of 0\n",
    "rep_hist_snapshot_df = nh.fill_neg()\n",
    "\n",
    "# Check For Negative Values within dataframes\n",
    "print('\\n\\n---------------WITHOUT NEGATIVE VALUES---------------')\n",
    "print(\"Table REP_HIST_SNAPSHOT: \" + str(nh.count_neg_df()) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redundant Feature Removal\n",
    "\n",
    "In this step, redundant features are dropped. Features are considered redundant if exhibit a standard devaition of 0 (meaning no change in value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping feature [DBID]\n",
      "Dropping feature [INSTANCE_NUMBER]\n",
      "Dropping feature [SQL_PROFILE]\n",
      "Dropping feature [CLWAIT_TOTAL]\n",
      "Dropping feature [CLWAIT_DELTA]\n",
      "Dropping feature [JAVEXEC_TIME_TOTAL]\n",
      "Dropping feature [JAVEXEC_TIME_DELTA]\n",
      "Dropping feature [IO_OFFLOAD_ELIG_BYTES_TOTAL]\n",
      "Dropping feature [IO_OFFLOAD_ELIG_BYTES_DELTA]\n",
      "Dropping feature [OPTIMIZED_PHYSICAL_READS_TOTAL]\n",
      "Dropping feature [OPTIMIZED_PHYSICAL_READS_DELTA]\n",
      "Dropping feature [CELL_UNCOMPRESSED_BYTES_TOTAL]\n",
      "Dropping feature [CELL_UNCOMPRESSED_BYTES_DELTA]\n",
      "Dropping feature [CON_DBID]\n",
      "Dropping feature [CON_ID]\n",
      "Dropping feature [STARTUP_TIME]\n",
      "Dropping feature [SNAP_LEVEL]\n",
      "Dropping feature [ERROR_COUNT]\n",
      "Dropping feature [SNAP_FLAG]\n",
      "Dropping feature [SNAP_TIMEZONE]\n",
      "\n",
      "Shape before changes: [(10000, 90)]\n",
      "Shape after changes: [(10000, 70)]\n",
      "Dropped a total [20]\n"
     ]
    }
   ],
   "source": [
    "class DropFlatline:\n",
    "\n",
    "    @staticmethod\n",
    "    def drop_flatline_columns(df):\n",
    "        \"\"\"\n",
    "        This function removes columns with a flat standard deviation of 0.\n",
    "        \"\"\"\n",
    "        columns = df.columns\n",
    "        flatline_features = []\n",
    "        for i in range(len(columns)):\n",
    "            try:\n",
    "                std = df[columns[i]].std()\n",
    "                if std == 0:\n",
    "                    flatline_features.append(columns[i])\n",
    "                    print('Dropping feature [' + columns[i]  + ']')\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        print('\\nShape before changes: [' + str(df.shape) + ']')\n",
    "        df = df.drop(columns=flatline_features)\n",
    "        print('Shape after changes: [' + str(df.shape) + ']')\n",
    "        print('Dropped a total [' + str(len(flatline_features)) + ']')\n",
    "        return df\n",
    "\n",
    "rep_hist_snapshot_df = DropFlatline.drop_flatline_columns(df=rep_hist_snapshot_df)\n",
    "rep_hist_snapshot_headers = rep_hist_snapshot_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Feature Distribution & Skewness\n",
    "\n",
    "In order to decide between a normalization strategy, it is important to understand the underlying data spread. Understanding of dataset mean, variance, skewness on a per column/feature basis helps determine whether a standardization or normalization strategy should be utilized on the datasets.\n",
    "\n",
    "### Plotting Data Distribution\n",
    "\n",
    "To better decide which normalization technique ought to be utilized for the technique at hand, a number of feature columns will be plotted as histograms to better convey the distribution spread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Visualizer:\n",
    "    \"\"\"\n",
    "    This class contains a number of methods dedicated to plotting the underlying data.\n",
    "    \"\"\"\n",
    "    def __init__(self, df=None, tpc_type=None, table=None):\n",
    "        \"\"\"\n",
    "        Constructor method.\n",
    "        :param df:             (Pandas) Data matrix.\n",
    "        :param tpc_type:       (String) TPC type, used for plot title purposes.\n",
    "        :param table:          (String) Denotes which table is being access, used for plot title/label purposes.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.__df = df\n",
    "        self.__tpc_type = tpc_type\n",
    "        self.__table = table\n",
    "        \n",
    "    def plot_hist(self, bin_size=10, feature_column=None):\n",
    "        \"\"\"\n",
    "        Plots histogram distribution, split into a number of buckets.\n",
    "        :param bin_size: (Integer) Denotes number of histogram buckets to split data into.\n",
    "        :param feature_column: (String) Denotes which column to plot.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        df = self.__df\n",
    "\n",
    "        try:\n",
    "            df['SNAP_ID'] = df['SNAP_ID'].astype(float)\n",
    "            df[feature_column] = df[feature_column].astype(float)\n",
    "\n",
    "            max_val = df[feature_column].max()\n",
    "            start_snap, end_snap = int(df['SNAP_ID'].min()), int(df['SNAP_ID'].max())\n",
    "\n",
    "            df[feature_column].hist(bins=10,figsize=(12,8))\n",
    "            plt.ylabel(feature_column)\n",
    "            plt.xlabel('Bin Ranges Of ' + str(int(max_val/bin_size)))\n",
    "            plt.title(self.__tpc_type + ' Table ' + self.__table.upper() + '.' + str(feature_column) + \" between \" + str(start_snap) + \" - \" + str(end_snap))\n",
    "            plt.show()\n",
    "        except Exception:\n",
    "            print('Could not plot column: ' + feature_column)\n",
    "\n",
    "    def plot_scatter(self, feature_column=None):\n",
    "        \"\"\"\n",
    "        Plots scatter plots vs SNAP_ID.\n",
    "        :param feature_column: (String) Denotes which column to plot.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        df = self.__df\n",
    "\n",
    "        try:\n",
    "            df['SNAP_ID'] = df['SNAP_ID'].astype(int)\n",
    "            df[feature_column] = df[feature_column].astype(int)\n",
    "            start_snap, end_snap = int(df['SNAP_ID'].min()), int(df['SNAP_ID'].max())\n",
    "\n",
    "            df.plot.scatter(x='SNAP_ID',\n",
    "                            y=feature_column,\n",
    "                            figsize=(12,8))\n",
    "            plt.ylabel(feature_column)\n",
    "            plt.xlabel('SNAP ID')\n",
    "            plt.title(self.__tpc_type + ' Table ' + self.__table.upper() + '.' + str(feature_column) + \" between \" + str(start_snap) + \" - \" + str(end_snap))\n",
    "            plt.show()\n",
    "        except Exception:\n",
    "            print('Could not plot column: ' + feature_column)\n",
    "\n",
    "    def plot_boxplot(self, feature_columns=None):\n",
    "        \"\"\"\n",
    "        Plots quartile plots to estimate mean and sigma (std dev).\n",
    "        :param feature_colums: (List) List of feature columns. Overrides parameter used in class constructor.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        df = self.__df\n",
    "\n",
    "        try:\n",
    "            for feature_column in feature_columns:\n",
    "                df[feature_column] = df[feature_column].astype(int)\n",
    "            df.boxplot(column=feature_columns, figsize=(12,8), grid=True)\n",
    "            plt.title(self.__tpc_type + ' ' + str(feature_columns))\n",
    "            plt.show()\n",
    "        except Exception:\n",
    "            print('Could not plot column: ' + feature_column)\n",
    "\n",
    "vis = Visualizer(df=rep_hist_snapshot_df, \n",
    "                 tpc_type=tpcds, \n",
    "                 table='rep_hist_snapshot')\n",
    "\n",
    "if debug_mode is False:\n",
    "    \n",
    "    # Plotting Histograms of data distribution\n",
    "    for header in rep_hist_snapshot_headers:\n",
    "        print('REP_HIST_SNAPSHOT - ' + header + ' - OUTLIERS HISTOGRAM')\n",
    "        vis.plot_hist(bin_size=10, feature_column=header)\n",
    "    \n",
    "    # Plotting Scatter Plots of data distribution\n",
    "    for header in rep_hist_snapshot_headers:\n",
    "        print('REP_HIST_SNAPSHOT - ' + header + ' - OUTLIERS SCATTER')\n",
    "        vis.plot_scatter(feature_column=header)\n",
    "    \n",
    "    # Plotting Box Plots of data distribution\n",
    "    whisker_boxes_per_plot = 3\n",
    "    for i in range(whisker_boxes_per_plot, len(rep_hist_snapshot_headers), whisker_boxes_per_plot):\n",
    "        print('REP_HIST_SNAPSHOT - ' + header + ' - OUTLIERS WHISKER')\n",
    "        vis.plot_boxplot(feature_columns=rep_hist_snapshot_headers[i-whisker_boxes_per_plot:i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Handling\n",
    "\n",
    "https://machinelearningmastery.com/how-to-identify-outliers-in-your-data/\n",
    "\n",
    "As can be appreciated from the previous plots, data is heavily skewed on particular (smallest) bins. This skew in the plotted histograms is a result of data point outliers - these need to be evaluated and removed if neccessary.\n",
    "\n",
    "Following the 3 Standard Deviation Rule, we can categorize our dataset into subsets consisting of the following ranges:\n",
    "* 0     - 68.27%\n",
    "* 68.28 - 95.45%\n",
    "* 95.46 - 99.73%\n",
    "* 99.74 - 100%\n",
    "\n",
    "It should be mentioned, that given the time series nature of the dataset, it is not a safe assumption to ignore outliers. By training respective models on outlier insensitive dataset, we would invite a potential problem, which risks blinding any models we train to future predicted spikes of activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8033 - 367.0 - SQL_ID - 367.0\n",
      "8225 - 368.0 - SQL_ID - 368.0\n",
      "9006 - 369.0 - SQL_ID - 369.0\n",
      "9046 - 370.0 - SQL_ID - 370.0\n",
      "9062 - 371.0 - SQL_ID - 371.0\n",
      "9105 - 372.0 - SQL_ID - 372.0\n",
      "9141 - 373.0 - SQL_ID - 373.0\n",
      "9299 - 374.0 - SQL_ID - 374.0\n",
      "9469 - 375.0 - SQL_ID - 375.0\n",
      "9673 - 376.0 - SQL_ID - 376.0\n",
      "2 - 0.0 - SQL_ID - 0.0\n",
      "979 - 0.0 - SQL_ID - 0.0\n",
      "1983 - 0.0 - SQL_ID - 0.0\n",
      "3018 - 0.0 - SQL_ID - 0.0\n",
      "4026 - 0.0 - SQL_ID - 0.0\n",
      "4993 - 0.0 - SQL_ID - 0.0\n",
      "6093 - 0.0 - SQL_ID - 0.0\n",
      "7098 - 0.0 - SQL_ID - 0.0\n",
      "8117 - 0.0 - SQL_ID - 0.0\n",
      "9113 - 0.0 - SQL_ID - 0.0\n",
      "55 - 49.0 - PLAN_HASH_VALUE - 4289615928.0\n",
      "1025 - 49.0 - PLAN_HASH_VALUE - 4289615928.0\n",
      "2030 - 49.0 - PLAN_HASH_VALUE - 4289615928.0\n",
      "3050 - 49.0 - PLAN_HASH_VALUE - 4289615928.0\n",
      "4079 - 49.0 - PLAN_HASH_VALUE - 4289615928.0\n",
      "5040 - 49.0 - PLAN_HASH_VALUE - 4289615928.0\n",
      "6131 - 49.0 - PLAN_HASH_VALUE - 4289615928.0\n",
      "7124 - 49.0 - PLAN_HASH_VALUE - 4289615928.0\n",
      "8162 - 49.0 - PLAN_HASH_VALUE - 4289615928.0\n",
      "9161 - 49.0 - PLAN_HASH_VALUE - 4289615928.0\n",
      "546 - 232.0 - OPTIMIZER_MODE - 3.0\n",
      "7942 - 39.0 - SHARABLE_MEM - 226372136.0\n",
      "8028 - 39.0 - SHARABLE_MEM - 226372176.0\n",
      "8504 - 39.0 - SHARABLE_MEM - 226372176.0\n",
      "8654 - 39.0 - SHARABLE_MEM - 223672320.0\n",
      "8737 - 39.0 - SHARABLE_MEM - 223672320.0\n",
      "8840 - 39.0 - SHARABLE_MEM - 223672320.0\n",
      "8931 - 39.0 - SHARABLE_MEM - 223672320.0\n",
      "9024 - 39.0 - SHARABLE_MEM - 223672320.0\n",
      "9088 - 39.0 - SHARABLE_MEM - 223672320.0\n",
      "4939 - 167.0 - LOADED_VERSIONS - 79.0\n",
      "5593 - 167.0 - LOADED_VERSIONS - 80.0\n",
      "6039 - 167.0 - LOADED_VERSIONS - 81.0\n",
      "6600 - 167.0 - LOADED_VERSIONS - 82.0\n",
      "7041 - 167.0 - LOADED_VERSIONS - 83.0\n",
      "7586 - 167.0 - LOADED_VERSIONS - 84.0\n",
      "7998 - 167.0 - LOADED_VERSIONS - 85.0\n",
      "8629 - 167.0 - LOADED_VERSIONS - 86.0\n",
      "9060 - 167.0 - LOADED_VERSIONS - 87.0\n",
      "9668 - 167.0 - LOADED_VERSIONS - 87.0\n",
      "4561 - 335.0 - ACTION - 4.0\n",
      "7065 - 357.0 - PARSING_SCHEMA_NAME - 5.0\n",
      "9160 - 48.0 - FETCHES_TOTAL - 72932136.0\n",
      "9234 - 48.0 - FETCHES_TOTAL - 72935451.0\n",
      "9328 - 48.0 - FETCHES_TOTAL - 72948915.0\n",
      "9423 - 48.0 - FETCHES_TOTAL - 72989149.0\n",
      "9523 - 48.0 - FETCHES_TOTAL - 73031682.0\n",
      "9627 - 48.0 - FETCHES_TOTAL - 73044738.0\n",
      "9709 - 48.0 - FETCHES_TOTAL - 73047645.0\n",
      "9787 - 48.0 - FETCHES_TOTAL - 73064623.0\n",
      "9888 - 48.0 - FETCHES_TOTAL - 73102661.0\n",
      "9988 - 48.0 - FETCHES_TOTAL - 73143000.0\n",
      "1278 - 48.0 - FETCHES_DELTA - 41199.0\n",
      "1373 - 48.0 - FETCHES_DELTA - 42992.0\n",
      "1804 - 48.0 - FETCHES_DELTA - 42735.0\n",
      "2276 - 48.0 - FETCHES_DELTA - 41506.0\n",
      "2374 - 48.0 - FETCHES_DELTA - 41198.0\n",
      "5459 - 48.0 - FETCHES_DELTA - 42635.0\n",
      "6361 - 48.0 - FETCHES_DELTA - 41712.0\n",
      "8515 - 48.0 - FETCHES_DELTA - 43243.0\n",
      "8942 - 48.0 - FETCHES_DELTA - 42420.0\n",
      "9048 - 116.0 - SORTS_TOTAL - 2837975.0\n",
      "9107 - 116.0 - SORTS_TOTAL - 2838085.0\n",
      "9260 - 116.0 - SORTS_TOTAL - 2838267.0\n",
      "9353 - 116.0 - SORTS_TOTAL - 2838794.0\n",
      "9448 - 116.0 - SORTS_TOTAL - 2840372.0\n",
      "9547 - 116.0 - SORTS_TOTAL - 2842040.0\n",
      "9651 - 116.0 - SORTS_TOTAL - 2842552.0\n",
      "9719 - 116.0 - SORTS_TOTAL - 2842666.0\n",
      "9816 - 116.0 - SORTS_TOTAL - 2843332.0\n",
      "9913 - 116.0 - SORTS_TOTAL - 2844824.0\n",
      "1305 - 116.0 - SORTS_DELTA - 1616.0\n",
      "1398 - 116.0 - SORTS_DELTA - 1686.0\n",
      "1827 - 116.0 - SORTS_DELTA - 1676.0\n",
      "2302 - 116.0 - SORTS_DELTA - 1628.0\n",
      "2400 - 116.0 - SORTS_DELTA - 1618.0\n",
      "5485 - 116.0 - SORTS_DELTA - 1672.0\n",
      "6386 - 116.0 - SORTS_DELTA - 1636.0\n",
      "8539 - 116.0 - SORTS_DELTA - 1696.0\n",
      "8965 - 116.0 - SORTS_DELTA - 1664.0\n",
      "10 - 8.0 - PX_SERVERS_EXECS_TOTAL - 15914.0\n",
      "987 - 8.0 - PX_SERVERS_EXECS_TOTAL - 16034.0\n",
      "1990 - 8.0 - PX_SERVERS_EXECS_TOTAL - 16153.0\n",
      "3023 - 8.0 - PX_SERVERS_EXECS_TOTAL - 16272.0\n",
      "4034 - 8.0 - PX_SERVERS_EXECS_TOTAL - 16391.0\n",
      "5000 - 8.0 - PX_SERVERS_EXECS_TOTAL - 16510.0\n",
      "6100 - 8.0 - PX_SERVERS_EXECS_TOTAL - 16630.0\n",
      "7102 - 8.0 - PX_SERVERS_EXECS_TOTAL - 16750.0\n",
      "8125 - 8.0 - PX_SERVERS_EXECS_TOTAL - 16867.0\n",
      "9119 - 8.0 - PX_SERVERS_EXECS_TOTAL - 16987.0\n",
      "491 - 199.0 - LOADS_TOTAL - 33692.0\n",
      "902 - 199.0 - LOADS_TOTAL - 33806.0\n",
      "1469 - 199.0 - LOADS_TOTAL - 33951.0\n",
      "1901 - 199.0 - LOADS_TOTAL - 34081.0\n",
      "2481 - 199.0 - LOADS_TOTAL - 34228.0\n",
      "2926 - 199.0 - LOADS_TOTAL - 34375.0\n",
      "3456 - 199.0 - LOADS_TOTAL - 34522.0\n",
      "3865 - 199.0 - LOADS_TOTAL - 34669.0\n",
      "9017 - 155.0 - LOADS_TOTAL - 33616.0\n",
      "9611 - 155.0 - LOADS_TOTAL - 33736.0\n",
      "852 - 165.0 - LOADS_DELTA - 491.0\n",
      "4413 - 136.0 - LOADS_DELTA - 191.0\n",
      "6355 - 136.0 - LOADS_DELTA - 191.0\n",
      "6498 - 165.0 - LOADS_DELTA - 491.0\n",
      "6893 - 136.0 - LOADS_DELTA - 191.0\n",
      "7038 - 165.0 - LOADS_DELTA - 491.0\n",
      "9565 - 165.0 - LOADS_DELTA - 491.0\n",
      "9881 - 136.0 - LOADS_DELTA - 191.0\n",
      "498 - 204.0 - INVALIDATIONS_TOTAL - 524.0\n",
      "908 - 204.0 - INVALIDATIONS_TOTAL - 525.0\n",
      "4514 - 204.0 - INVALIDATIONS_TOTAL - 532.0\n",
      "4929 - 204.0 - INVALIDATIONS_TOTAL - 533.0\n",
      "7678 - 231.0 - INVALIDATIONS_TOTAL - 520.0\n",
      "8089 - 231.0 - INVALIDATIONS_TOTAL - 521.0\n",
      "8633 - 216.0 - INVALIDATIONS_TOTAL - 516.0\n",
      "8987 - 173.0 - INVALIDATIONS_TOTAL - 516.0\n",
      "9066 - 216.0 - INVALIDATIONS_TOTAL - 517.0\n",
      "9672 - 216.0 - INVALIDATIONS_TOTAL - 518.0\n",
      "8797 - 69.0 - DISK_READS_TOTAL - 757890278.0\n",
      "8886 - 69.0 - DISK_READS_TOTAL - 761147709.0\n",
      "9185 - 69.0 - DISK_READS_TOTAL - 761148149.0\n",
      "9279 - 69.0 - DISK_READS_TOTAL - 761242544.0\n",
      "9372 - 69.0 - DISK_READS_TOTAL - 762058786.0\n",
      "9468 - 69.0 - DISK_READS_TOTAL - 762935138.0\n",
      "9571 - 69.0 - DISK_READS_TOTAL - 763077128.0\n",
      "9735 - 69.0 - DISK_READS_TOTAL - 764220032.0\n",
      "9837 - 69.0 - DISK_READS_TOTAL - 767059846.0\n",
      "9932 - 69.0 - DISK_READS_TOTAL - 770168694.0\n",
      "670 - 69.0 - DISK_READS_DELTA - 4384408.0\n",
      "1659 - 69.0 - DISK_READS_DELTA - 3754383.0\n",
      "2682 - 84.0 - DISK_READS_DELTA - 3754392.0\n",
      "3630 - 84.0 - DISK_READS_DELTA - 3637205.0\n",
      "3713 - 69.0 - DISK_READS_DELTA - 3978906.0\n",
      "4693 - 69.0 - DISK_READS_DELTA - 3754359.0\n",
      "5753 - 69.0 - DISK_READS_DELTA - 3754390.0\n",
      "6766 - 84.0 - DISK_READS_DELTA - 3972443.0\n",
      "7807 - 69.0 - DISK_READS_DELTA - 4171509.0\n",
      "7738 - 94.0 - BUFFER_GETS_TOTAL - 1570056263.0\n",
      "7832 - 94.0 - BUFFER_GETS_TOTAL - 1574831402.0\n",
      "7923 - 94.0 - BUFFER_GETS_TOTAL - 1575134500.0\n",
      "8211 - 94.0 - BUFFER_GETS_TOTAL - 1575655694.0\n",
      "8302 - 94.0 - BUFFER_GETS_TOTAL - 1577584206.0\n",
      "8395 - 94.0 - BUFFER_GETS_TOTAL - 1584667172.0\n",
      "8487 - 94.0 - BUFFER_GETS_TOTAL - 1586659141.0\n",
      "8718 - 94.0 - BUFFER_GETS_TOTAL - 1588847364.0\n",
      "8821 - 94.0 - BUFFER_GETS_TOTAL - 1595861872.0\n",
      "8913 - 94.0 - BUFFER_GETS_TOTAL - 1597763572.0\n",
      "2239 - 86.0 - BUFFER_GETS_DELTA - 8197859.0\n",
      "2683 - 86.0 - BUFFER_GETS_DELTA - 8533454.0\n",
      "2692 - 94.0 - BUFFER_GETS_DELTA - 7921821.0\n",
      "6324 - 86.0 - BUFFER_GETS_DELTA - 8096591.0\n",
      "6767 - 86.0 - BUFFER_GETS_DELTA - 8259426.0\n",
      "6776 - 94.0 - BUFFER_GETS_DELTA - 7913834.0\n",
      "9385 - 86.0 - BUFFER_GETS_DELTA - 8664031.0\n",
      "9395 - 94.0 - BUFFER_GETS_DELTA - 8016405.0\n",
      "9850 - 86.0 - BUFFER_GETS_DELTA - 7976191.0\n",
      "9859 - 94.0 - BUFFER_GETS_DELTA - 8135898.0\n",
      "8172 - 118.0 - CPU_TIME_TOTAL - 37510853563.0\n",
      "8258 - 118.0 - CPU_TIME_TOTAL - 37511609437.0\n",
      "8350 - 118.0 - CPU_TIME_TOTAL - 37514064888.0\n",
      "8621 - 118.0 - CPU_TIME_TOTAL - 37529396268.0\n",
      "8678 - 118.0 - CPU_TIME_TOTAL - 37533926043.0\n",
      "9263 - 118.0 - CPU_TIME_TOTAL - 37537418382.0\n",
      "9355 - 118.0 - CPU_TIME_TOTAL - 37539911150.0\n",
      "9654 - 118.0 - CPU_TIME_TOTAL - 37549326946.0\n",
      "9723 - 118.0 - CPU_TIME_TOTAL - 37552597319.0\n",
      "9818 - 118.0 - CPU_TIME_TOTAL - 37557273076.0\n",
      "263 - 74.0 - CPU_TIME_DELTA - 216607435.0\n",
      "676 - 74.0 - CPU_TIME_DELTA - 212708495.0\n",
      "1232 - 74.0 - CPU_TIME_DELTA - 202158042.0\n",
      "1665 - 74.0 - CPU_TIME_DELTA - 200874679.0\n",
      "4287 - 74.0 - CPU_TIME_DELTA - 220877084.0\n",
      "4698 - 74.0 - CPU_TIME_DELTA - 216729965.0\n",
      "5759 - 74.0 - CPU_TIME_DELTA - 201365631.0\n",
      "7401 - 74.0 - CPU_TIME_DELTA - 212207717.0\n",
      "8374 - 74.0 - CPU_TIME_DELTA - 209043821.0\n",
      "8803 - 74.0 - CPU_TIME_DELTA - 202986032.0\n",
      "7680 - 101.0 - IOWAIT_TOTAL - 4101204818.0\n",
      "8030 - 101.0 - IOWAIT_TOTAL - 4102047272.0\n",
      "8091 - 101.0 - IOWAIT_TOTAL - 4102166004.0\n",
      "8224 - 101.0 - IOWAIT_TOTAL - 4102369763.0\n",
      "8601 - 101.0 - IOWAIT_TOTAL - 4104131164.0\n",
      "8656 - 101.0 - IOWAIT_TOTAL - 4104279898.0\n",
      "9025 - 101.0 - IOWAIT_TOTAL - 4105937228.0\n",
      "9090 - 101.0 - IOWAIT_TOTAL - 4106099991.0\n",
      "9226 - 101.0 - IOWAIT_TOTAL - 4106575659.0\n",
      "9699 - 101.0 - IOWAIT_TOTAL - 4107974441.0\n",
      "589 - 86.0 - IOWAIT_DELTA - 6827021.0\n",
      "5766 - 86.0 - IOWAIT_DELTA - 7077528.0\n",
      "7727 - 86.0 - IOWAIT_DELTA - 8057358.0\n",
      "8739 - 136.0 - APWAIT_TOTAL - 7200920.0\n",
      "8843 - 136.0 - APWAIT_TOTAL - 7220403.0\n",
      "8935 - 136.0 - APWAIT_TOTAL - 7239884.0\n",
      "9321 - 136.0 - APWAIT_TOTAL - 7241680.0\n",
      "9417 - 136.0 - APWAIT_TOTAL - 7260330.0\n",
      "9516 - 136.0 - APWAIT_TOTAL - 7272652.0\n",
      "9619 - 136.0 - APWAIT_TOTAL - 7290890.0\n",
      "9778 - 136.0 - APWAIT_TOTAL - 7293678.0\n",
      "9982 - 136.0 - APWAIT_TOTAL - 7332826.0\n",
      "299 - 136.0 - APWAIT_DELTA - 28167.0\n",
      "715 - 136.0 - APWAIT_DELTA - 31824.0\n",
      "1366 - 136.0 - APWAIT_DELTA - 28784.0\n",
      "2810 - 136.0 - APWAIT_DELTA - 26028.0\n",
      "4325 - 136.0 - APWAIT_DELTA - 24318.0\n",
      "4736 - 136.0 - APWAIT_DELTA - 23623.0\n",
      "5893 - 136.0 - APWAIT_DELTA - 23739.0\n",
      "7851 - 136.0 - APWAIT_DELTA - 24905.0\n",
      "8417 - 136.0 - APWAIT_DELTA - 24483.0\n",
      "8507 - 136.0 - APWAIT_DELTA - 29482.0\n",
      "24 - 22.0 - CCWAIT_DELTA - 2114339.0\n",
      "29 - 27.0 - CCWAIT_DELTA - 2863946.0\n",
      "989 - 256.0 - CCWAIT_DELTA - 1817169.0\n",
      "2000 - 15.0 - CCWAIT_DELTA - 1848799.0\n",
      "3070 - 257.0 - CCWAIT_DELTA - 1822330.0\n",
      "3086 - 29.0 - CCWAIT_DELTA - 1827997.0\n",
      "5048 - 61.0 - CCWAIT_DELTA - 1992059.0\n",
      "7186 - 359.0 - CCWAIT_DELTA - 1785616.0\n",
      "8124 - 7.0 - CCWAIT_DELTA - 1887401.0\n",
      "8717 - 92.0 - DIRECT_WRITES_TOTAL - 40613051.0\n",
      "8818 - 92.0 - DIRECT_WRITES_TOTAL - 40700273.0\n",
      "8910 - 92.0 - DIRECT_WRITES_TOTAL - 40874717.0\n",
      "9208 - 92.0 - DIRECT_WRITES_TOTAL - 40889254.0\n",
      "9302 - 92.0 - DIRECT_WRITES_TOTAL - 40932865.0\n",
      "9394 - 92.0 - DIRECT_WRITES_TOTAL - 40976476.0\n",
      "9494 - 92.0 - DIRECT_WRITES_TOTAL - 41155783.0\n",
      "9597 - 92.0 - DIRECT_WRITES_TOTAL - 41194531.0\n",
      "9758 - 92.0 - DIRECT_WRITES_TOTAL - 41238142.0\n",
      "9959 - 92.0 - DIRECT_WRITES_TOTAL - 41456197.0\n",
      "1774 - 92.0 - DIRECT_WRITES_DELTA - 174444.0\n",
      "2346 - 92.0 - DIRECT_WRITES_DELTA - 174444.0\n",
      "2790 - 92.0 - DIRECT_WRITES_DELTA - 174444.0\n",
      "4393 - 92.0 - DIRECT_WRITES_DELTA - 168557.0\n",
      "4803 - 92.0 - DIRECT_WRITES_DELTA - 174444.0\n",
      "6873 - 92.0 - DIRECT_WRITES_DELTA - 174444.0\n",
      "8485 - 92.0 - DIRECT_WRITES_DELTA - 174444.0\n",
      "70 - 56.0 - PLSEXEC_TIME_DELTA - 1704060.0\n",
      "1029 - 56.0 - PLSEXEC_TIME_DELTA - 1919589.0\n",
      "2038 - 56.0 - PLSEXEC_TIME_DELTA - 1903551.0\n",
      "3124 - 56.0 - PLSEXEC_TIME_DELTA - 1302233.0\n",
      "4092 - 56.0 - PLSEXEC_TIME_DELTA - 1895005.0\n",
      "5045 - 56.0 - PLSEXEC_TIME_DELTA - 1978839.0\n",
      "6138 - 56.0 - PLSEXEC_TIME_DELTA - 1683023.0\n",
      "7208 - 56.0 - PLSEXEC_TIME_DELTA - 1483787.0\n",
      "8169 - 56.0 - PLSEXEC_TIME_DELTA - 1916205.0\n",
      "9168 - 56.0 - PLSEXEC_TIME_DELTA - 1899658.0\n",
      "588 - 84.0 - IO_INTERCONNECT_BYTES_DELTA - 23609892864.0\n",
      "1671 - 84.0 - IO_INTERCONNECT_BYTES_DELTA - 22247636992.0\n",
      "4703 - 84.0 - IO_INTERCONNECT_BYTES_DELTA - 18453381120.0\n",
      "5765 - 84.0 - IO_INTERCONNECT_BYTES_DELTA - 24604786688.0\n",
      "7726 - 84.0 - IO_INTERCONNECT_BYTES_DELTA - 26329964544.0\n",
      "8808 - 84.0 - IO_INTERCONNECT_BYTES_DELTA - 22554353664.0\n",
      "9849 - 84.0 - IO_INTERCONNECT_BYTES_DELTA - 28705259520.0\n",
      "176 - 86.0 - PHYSICAL_READ_REQUESTS_DELTA - 569837.0\n",
      "270 - 86.0 - PHYSICAL_READ_REQUESTS_DELTA - 586834.0\n",
      "686 - 86.0 - PHYSICAL_READ_REQUESTS_DELTA - 1151657.0\n",
      "1240 - 86.0 - PHYSICAL_READ_REQUESTS_DELTA - 685362.0\n",
      "1575 - 86.0 - PHYSICAL_READ_REQUESTS_DELTA - 636465.0\n",
      "1672 - 86.0 - PHYSICAL_READ_REQUESTS_DELTA - 1295281.0\n",
      "4726 - 98.0 - PHYSICAL_READ_REQUESTS_DELTA - 470705.0\n",
      "8832 - 98.0 - PHYSICAL_READ_REQUESTS_DELTA - 457590.0\n",
      "9869 - 98.0 - PHYSICAL_READ_REQUESTS_DELTA - 468856.0\n",
      "2720 - 106.0 - PHYSICAL_WRITE_REQUESTS_DELTA - 320.0\n",
      "2816 - 106.0 - PHYSICAL_WRITE_REQUESTS_DELTA - 440.0\n",
      "3260 - 106.0 - PHYSICAL_WRITE_REQUESTS_DELTA - 280.0\n",
      "3353 - 106.0 - PHYSICAL_WRITE_REQUESTS_DELTA - 240.0\n",
      "3448 - 106.0 - PHYSICAL_WRITE_REQUESTS_DELTA - 320.0\n",
      "3670 - 106.0 - PHYSICAL_WRITE_REQUESTS_DELTA - 280.0\n",
      "3765 - 106.0 - PHYSICAL_WRITE_REQUESTS_DELTA - 280.0\n",
      "3858 - 106.0 - PHYSICAL_WRITE_REQUESTS_DELTA - 280.0\n",
      "3034 - 24.0 - IO_OFFLOAD_RETURN_BYTES_DELTA - 524288.0\n",
      "3075 - 19.0 - IO_OFFLOAD_RETURN_BYTES_DELTA - 376832.0\n",
      "5011 - 259.0 - IO_OFFLOAD_RETURN_BYTES_DELTA - 8192.0\n",
      "6157 - 23.0 - IO_OFFLOAD_RETURN_BYTES_DELTA - 311296.0\n",
      "7155 - 259.0 - IO_OFFLOAD_RETURN_BYTES_DELTA - 385024.0\n",
      "9663 - 163.0 - BIND_DATA - 219.0\n",
      "9682 - 178.0 - BIND_DATA - 220.0\n",
      "9696 - 283.0 - BIND_DATA - 221.0\n",
      "9700 - 284.0 - BIND_DATA - 222.0\n",
      "9741 - 217.0 - BIND_DATA - 223.0\n",
      "9743 - 222.0 - BIND_DATA - 224.0\n",
      "9827 - 163.0 - BIND_DATA - 219.0\n",
      "9883 - 104.0 - BIND_DATA - 225.0\n",
      "9915 - 123.0 - BIND_DATA - 226.0\n",
      "9984 - 104.0 - BIND_DATA - 225.0\n",
      "\n",
      "\n",
      "DATAFRAMES WITH OUTLIERS\n",
      "(10000, 70)\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "OUTLIERS\n",
      "294\n",
      "----------------------------\n",
      "\n",
      "\n",
      "DATAFRAMES WITHOUT OUTLIERS\n",
      "(9706, 70)\n",
      "\n",
      "\n",
      "First 20 record sample before outliers:\n",
      "0      0.0\n",
      "1      1.0\n",
      "2      2.0\n",
      "3      3.0\n",
      "4      4.0\n",
      "5      5.0\n",
      "6      6.0\n",
      "7      7.0\n",
      "8      8.0\n",
      "9      9.0\n",
      "10    10.0\n",
      "11    11.0\n",
      "12    12.0\n",
      "13    13.0\n",
      "14    14.0\n",
      "15    15.0\n",
      "16    16.0\n",
      "17    17.0\n",
      "18    18.0\n",
      "19    19.0\n",
      "Name: SQL_ID, dtype: float64\n",
      "---------------------------------------\n",
      "First 20 record sample after outliers:\n",
      "1      1.0\n",
      "2      2.0\n",
      "3      3.0\n",
      "4      4.0\n",
      "5      5.0\n",
      "6      6.0\n",
      "7      7.0\n",
      "9      9.0\n",
      "10    10.0\n",
      "11    11.0\n",
      "12    12.0\n",
      "13    13.0\n",
      "14    14.0\n",
      "15    15.0\n",
      "16    16.0\n",
      "17    17.0\n",
      "18    18.0\n",
      "19    19.0\n",
      "20    20.0\n",
      "21    21.0\n",
      "Name: SQL_ID, dtype: float64\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class OutlierHandling:\n",
    "    \"\"\"\n",
    "    This class handles outlier detection and removal methods.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, low_quartile_limit=.01,upper_quartile_limit=.99):\n",
    "        \"\"\"\n",
    "        Constructor method.\n",
    "        :param df:                   (Pandas) Dataframe consisting of input features to be pruned of outliers.\n",
    "        :param low_quartile_limit:   (Float) Lower percentage threshold for removal of outliers.\n",
    "        :param upper_quartile_limit: (Float) Upper percentage threshold for removal of outliers.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.__df = df\n",
    "        self.__low_quartile_limit = low_quartile_limit\n",
    "        self.__upper_quartile_limit = upper_quartile_limit\n",
    "        self.__headers= df.columns\n",
    "        \n",
    "    def get_outliers(self):\n",
    "        \"\"\"\n",
    "        Detect and return which rows are considered outliers within the dataset, determined by :quartile_limit (99%)\n",
    "        :return: (List) A list denoting row positions of detected outliers.\n",
    "        \"\"\"\n",
    "        outlier_rows = [] # This list of lists consists of elements of the following notation [column,rowid]\n",
    "        df = self.__df\n",
    "        for header in self.__headers:\n",
    "            try:\n",
    "                df[header] = df[header].astype(float)\n",
    "                q = df[header].quantile(self.__upper_quartile_limit)\n",
    "                series_row = (df[df[header] > q].index)\n",
    "                for id in list(np.array(series_row)):\n",
    "                    outlier_rows.append([header,id])\n",
    "                q = df[header].quantile(self.__low_quartile_limit)\n",
    "                series_row = (df[df[header] < q].index)\n",
    "                for id in list(np.array(series_row)):\n",
    "                    outlier_rows.append([header,id])\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "\n",
    "        unique_ids = []\n",
    "        unique_outlier_rows = []\n",
    "\n",
    "        for col, rowid in outlier_rows:\n",
    "            if rowid not in unique_ids:\n",
    "                unique_outlier_rows.append([col,rowid])\n",
    "                unique_ids.append(rowid)\n",
    "        return unique_outlier_rows\n",
    "\n",
    "    def remove_outliers(self):\n",
    "        \"\"\"\n",
    "        Remove rows which are considered outliers within the dataset, determined by :quartile_limit (99%).\n",
    "        :return: (Pandas) Dataframe with pruned outliers.\n",
    "        \"\"\"\n",
    "        df = self.__df\n",
    "        length_before = len(df)\n",
    "        outliers_index = []\n",
    "        for header in self.__headers:\n",
    "            try:\n",
    "                df[header] = df[header].astype(float)\n",
    "                q = df[header].quantile(self.__upper_quartile_limit)\n",
    "                outliers_index.append(list(np.array(df[df[header] > q].index)))\n",
    "                q = df[header].quantile(self.__low_quartile_limit)\n",
    "                outliers_index.append(list(np.array(df[df[header] < q].index)))\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "        #flat_outliers_index = [item for sublist in l for item in outliers_index]\n",
    "        flat_outliers_index = [item for sublist in outliers_index for item in sublist]\n",
    "        outliers_index = list(set(flat_outliers_index))\n",
    "        df = df.drop(outliers_index)\n",
    "        return df\n",
    "\n",
    "# Defining which columns will be exposed to outliers\n",
    "rep_hist_snapshot_header_outliers = ['OPTIMIZER_COST',\n",
    "                                    'SHARABLE_MEM',\n",
    "                                    'FETCHES_TOTAL',\n",
    "                                    'FETCHES_DELTA',\n",
    "                                    'END_OF_FETCH_COUNT_TOTAL',\n",
    "                                    'END_OF_FETCH_COUNT_DELTA',\n",
    "                                    'SORTS_TOTAL',\n",
    "                                    'SORTS_DELTA',\n",
    "                                    'EXECUTIONS_TOTAL',\n",
    "                                    'EXECUTIONS_DELTA',\n",
    "                                    'PX_SERVERS_EXECS_TOTAL',\n",
    "                                    'PX_SERVERS_EXECS_DELTA',\n",
    "                                    'LOADS_TOTAL',\n",
    "                                    'LOADS_DELTA',\n",
    "                                    'INVALIDATIONS_TOTAL',\n",
    "                                    'INVALIDATIONS_DELTA',\n",
    "                                    'PARSE_CALLS_TOTAL',\n",
    "                                    'PARSE_CALLS_DELTA',\n",
    "                                    'DISK_READS_TOTAL',\n",
    "                                    'DISK_READS_DELTA',\n",
    "                                    'BUFFER_GETS_TOTAL',\n",
    "                                    'BUFFER_GETS_DELTA',\n",
    "                                    'ROWS_PROCESSED_TOTAL',\n",
    "                                    'ROWS_PROCESSED_DELTA',\n",
    "                                    'CPU_TIME_TOTAL',\n",
    "                                    'CPU_TIME_DELTA',\n",
    "                                    'ELAPSED_TIME_TOTAL',\n",
    "                                    'ELAPSED_TIME_DELTA',\n",
    "                                    'IOWAIT_TOTAL',\n",
    "                                    'IOWAIT_DELTA',\n",
    "                                    'CLWAIT_TOTAL',\n",
    "                                    'CLWAIT_DELTA',\n",
    "                                    'APWAIT_TOTAL',\n",
    "                                    'APWAIT_DELTA',\n",
    "                                    'CCWAIT_TOTAL',\n",
    "                                    'CCWAIT_DELTA',\n",
    "                                    'DIRECT_WRITES_TOTAL',\n",
    "                                    'DIRECT_WRITES_DELTA',\n",
    "                                    'PLSEXEC_TIME_TOTAL',\n",
    "                                    'PLSEXEC_TIME_DELTA',\n",
    "                                    'JAVEXEC_TIME_TOTAL',\n",
    "                                    'JAVEXEC_TIME_DELTA',\n",
    "                                    'IO_OFFLOAD_ELIG_BYTES_TOTAL',\n",
    "                                    'IO_OFFLOAD_ELIG_BYTES_DELTA',\n",
    "                                    'IO_INTERCONNECT_BYTES_TOTAL',\n",
    "                                    'IO_INTERCONNECT_BYTES_DELTA',\n",
    "                                    'PHYSICAL_READ_REQUESTS_TOTAL',\n",
    "                                    'PHYSICAL_READ_REQUESTS_DELTA',\n",
    "                                    'PHYSICAL_READ_BYTES_TOTAL',\n",
    "                                    'PHYSICAL_READ_BYTES_DELTA',\n",
    "                                    'PHYSICAL_WRITE_REQUESTS_TOTAL',\n",
    "                                    'PHYSICAL_WRITE_REQUESTS_DELTA',\n",
    "                                    'PHYSICAL_WRITE_BYTES_TOTAL',\n",
    "                                    'PHYSICAL_WRITE_BYTES_DELTA',\n",
    "                                    'OPTIMIZED_PHYSICAL_READS_TOTAL',\n",
    "                                    'OPTIMIZED_PHYSICAL_READS_DELTA',\n",
    "                                    'CELL_UNCOMPRESSED_BYTES_TOTAL',\n",
    "                                    'CELL_UNCOMPRESSED_BYTES_DELTA',\n",
    "                                    'IO_OFFLOAD_RETURN_BYTES_TOTAL',\n",
    "                                    'IO_OFFLOAD_RETURN_BYTES_DELTA']\n",
    "\n",
    "#Printing outliers to screen\n",
    "oh = OutlierHandling(df=rep_hist_snapshot_df,\n",
    "                     upper_quartile_limit=upper_quartile_limit,\n",
    "                     low_quartile_limit=low_quartile_limit)\n",
    "outliers = oh.get_outliers()\n",
    "for header, loc in outliers:\n",
    "    print(str(loc+2) + \" - \" + str(rep_hist_snapshot_df.iloc[loc]['SQL_ID']) + \" - \" + str(header) + \" - \" + str(rep_hist_snapshot_df.iloc[loc][header]))\n",
    "\n",
    "# Printing dataframe before adjustments\n",
    "print('\\n\\nDATAFRAMES WITH OUTLIERS')\n",
    "print(rep_hist_snapshot_df.shape)\n",
    "print('----------------------------')\n",
    "\n",
    "#Printing outlier length to screen\n",
    "rep_hist_snapshot_df_outliers = oh.get_outliers()\n",
    "print('\\n\\nOUTLIERS')\n",
    "print(len(rep_hist_snapshot_df_outliers))\n",
    "print('----------------------------')\n",
    "\n",
    "# Dropping Outliers\n",
    "rep_hist_snapshot_df_pruned = oh.remove_outliers()\n",
    "print('\\n\\nDATAFRAMES WITHOUT OUTLIERS')\n",
    "print(rep_hist_snapshot_df_pruned.shape)\n",
    "\n",
    "print('\\n\\nFirst 20 record sample before outliers:')\n",
    "print(rep_hist_snapshot_df.iloc[0:20]['SQL_ID'])\n",
    "print('---------------------------------------')\n",
    "print('First 20 record sample after outliers:')\n",
    "print(rep_hist_snapshot_df_pruned.iloc[0:20]['SQL_ID'])\n",
    "print('---------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting data distribution without outliers\n",
    "\n",
    "Plotting metrics against SNAP_ID, without outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if debug_mode is False:\n",
    "    \n",
    "    # Plotting Histograms without Outliers\n",
    "    for header in rep_hist_snapshot_df.columns:\n",
    "        print('REP_HIST_SNAPSHOT - ' + header + ' - STRIPPED HISTOGRAM')\n",
    "        plot_hist(df=rep_hist_snapshot_df_pruned, tpc_type=tpcds, table='rep_hist_snapshot', feature_column=header, bin_size=10)\n",
    "    \n",
    "    # Plotting Scatter Plots without Outliers\n",
    "    for header in rep_hist_snapshot_df.columns:\n",
    "        print('REP_HIST_SNAPSHOT - ' + header + ' - STRIPPED SCATTER')\n",
    "        plot_scatter(df=rep_hist_snapshot_df_pruned, tpc_type=tpcds,table='rep_hist_snapshot',feature_column=header)\n",
    "    \n",
    "    # Plotting Box Plots without Outliers\n",
    "    whisker_boxes_per_plot = 3\n",
    "    for i in range(whisker_boxes_per_plot, len(rep_hist_snapshot_header_outliers), whisker_boxes_per_plot):\n",
    "        print('REP_HIST_SNAPSHOT - ' + header + ' - STRIPPED WHISKER')\n",
    "        plot_boxplot(df=rep_hist_snapshot_df, tpc_type=tpcds,table='rep_hist_snapshot',feature_columns=rep_hist_snapshot_df.columns[i-whisker_boxes_per_plot:i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Redundant Columns\n",
    "\n",
    "Dropping redundant columns which are not detrimental to the task at hand (NB: This is only the first steps towards feature selection. This step ensures that specific columns which are SURELY not useful are dropped ahead of time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "http://benalexkeen.com/feature-scaling-with-scikit-learn/\n",
    "\n",
    "Based on the above plots, one can argue that the data distribution is uneven, and does not correlate to any particular pattern. A normalization approach (MinMaxScaling and/or RobustScaling) to the presented dataset is a more likely candidate than standardizing of the presented dataset. \n",
    "\n",
    "Reasons behind normalizing the dataset rather than standardizing, is due to the vast standard deviations from the mean for several feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Before----------\n",
      "Index(['SNAP_ID', 'SQL_ID', 'PLAN_HASH_VALUE', 'OPTIMIZER_COST',\n",
      "       'OPTIMIZER_MODE', 'OPTIMIZER_ENV_HASH_VALUE', 'SHARABLE_MEM',\n",
      "       'LOADED_VERSIONS', 'VERSION_COUNT', 'MODULE', 'ACTION',\n",
      "       'FORCE_MATCHING_SIGNATURE', 'PARSING_SCHEMA_ID', 'PARSING_SCHEMA_NAME',\n",
      "       'PARSING_USER_ID', 'FETCHES_TOTAL', 'FETCHES_DELTA',\n",
      "       'END_OF_FETCH_COUNT_TOTAL', 'END_OF_FETCH_COUNT_DELTA', 'SORTS_TOTAL',\n",
      "       'SORTS_DELTA', 'EXECUTIONS_TOTAL', 'EXECUTIONS_DELTA',\n",
      "       'PX_SERVERS_EXECS_TOTAL', 'PX_SERVERS_EXECS_DELTA', 'LOADS_TOTAL',\n",
      "       'LOADS_DELTA', 'INVALIDATIONS_TOTAL', 'INVALIDATIONS_DELTA',\n",
      "       'PARSE_CALLS_TOTAL', 'PARSE_CALLS_DELTA', 'DISK_READS_TOTAL',\n",
      "       'DISK_READS_DELTA', 'BUFFER_GETS_TOTAL', 'BUFFER_GETS_DELTA',\n",
      "       'ROWS_PROCESSED_TOTAL', 'ROWS_PROCESSED_DELTA', 'CPU_TIME_TOTAL',\n",
      "       'CPU_TIME_DELTA', 'ELAPSED_TIME_TOTAL', 'ELAPSED_TIME_DELTA',\n",
      "       'IOWAIT_TOTAL', 'IOWAIT_DELTA', 'APWAIT_TOTAL', 'APWAIT_DELTA',\n",
      "       'CCWAIT_TOTAL', 'CCWAIT_DELTA', 'DIRECT_WRITES_TOTAL',\n",
      "       'DIRECT_WRITES_DELTA', 'PLSEXEC_TIME_TOTAL', 'PLSEXEC_TIME_DELTA',\n",
      "       'IO_INTERCONNECT_BYTES_TOTAL', 'IO_INTERCONNECT_BYTES_DELTA',\n",
      "       'PHYSICAL_READ_REQUESTS_TOTAL', 'PHYSICAL_READ_REQUESTS_DELTA',\n",
      "       'PHYSICAL_READ_BYTES_TOTAL', 'PHYSICAL_READ_BYTES_DELTA',\n",
      "       'PHYSICAL_WRITE_REQUESTS_TOTAL', 'PHYSICAL_WRITE_REQUESTS_DELTA',\n",
      "       'PHYSICAL_WRITE_BYTES_TOTAL', 'PHYSICAL_WRITE_BYTES_DELTA',\n",
      "       'IO_OFFLOAD_RETURN_BYTES_TOTAL', 'IO_OFFLOAD_RETURN_BYTES_DELTA',\n",
      "       'BIND_DATA', 'FLAG', 'SQL_TEXT', 'COMMAND_TYPE', 'BEGIN_INTERVAL_TIME',\n",
      "       'END_INTERVAL_TIME', 'FLUSH_ELAPSED'],\n",
      "      dtype='object')\n",
      "----------After----------\n",
      "Index(['SNAP_ID', 'SQL_ID', 'PLAN_HASH_VALUE', 'OPTIMIZER_COST',\n",
      "       'OPTIMIZER_MODE', 'OPTIMIZER_ENV_HASH_VALUE', 'SHARABLE_MEM',\n",
      "       'LOADED_VERSIONS', 'VERSION_COUNT', 'MODULE', 'ACTION',\n",
      "       'FORCE_MATCHING_SIGNATURE', 'PARSING_SCHEMA_ID', 'PARSING_SCHEMA_NAME',\n",
      "       'PARSING_USER_ID', 'FETCHES_TOTAL', 'FETCHES_DELTA',\n",
      "       'END_OF_FETCH_COUNT_TOTAL', 'END_OF_FETCH_COUNT_DELTA', 'SORTS_TOTAL',\n",
      "       'SORTS_DELTA', 'EXECUTIONS_TOTAL', 'EXECUTIONS_DELTA',\n",
      "       'PX_SERVERS_EXECS_TOTAL', 'PX_SERVERS_EXECS_DELTA', 'LOADS_TOTAL',\n",
      "       'LOADS_DELTA', 'INVALIDATIONS_TOTAL', 'INVALIDATIONS_DELTA',\n",
      "       'PARSE_CALLS_TOTAL', 'PARSE_CALLS_DELTA', 'DISK_READS_TOTAL',\n",
      "       'DISK_READS_DELTA', 'BUFFER_GETS_TOTAL', 'BUFFER_GETS_DELTA',\n",
      "       'ROWS_PROCESSED_TOTAL', 'ROWS_PROCESSED_DELTA', 'CPU_TIME_TOTAL',\n",
      "       'CPU_TIME_DELTA', 'ELAPSED_TIME_TOTAL', 'ELAPSED_TIME_DELTA',\n",
      "       'IOWAIT_TOTAL', 'IOWAIT_DELTA', 'APWAIT_TOTAL', 'APWAIT_DELTA',\n",
      "       'CCWAIT_TOTAL', 'CCWAIT_DELTA', 'DIRECT_WRITES_TOTAL',\n",
      "       'DIRECT_WRITES_DELTA', 'PLSEXEC_TIME_TOTAL', 'PLSEXEC_TIME_DELTA',\n",
      "       'IO_INTERCONNECT_BYTES_TOTAL', 'IO_INTERCONNECT_BYTES_DELTA',\n",
      "       'PHYSICAL_READ_REQUESTS_TOTAL', 'PHYSICAL_READ_REQUESTS_DELTA',\n",
      "       'PHYSICAL_READ_BYTES_TOTAL', 'PHYSICAL_READ_BYTES_DELTA',\n",
      "       'PHYSICAL_WRITE_REQUESTS_TOTAL', 'PHYSICAL_WRITE_REQUESTS_DELTA',\n",
      "       'PHYSICAL_WRITE_BYTES_TOTAL', 'PHYSICAL_WRITE_BYTES_DELTA',\n",
      "       'IO_OFFLOAD_RETURN_BYTES_TOTAL', 'IO_OFFLOAD_RETURN_BYTES_DELTA',\n",
      "       'BIND_DATA', 'FLAG', 'SQL_TEXT', 'COMMAND_TYPE', 'BEGIN_INTERVAL_TIME',\n",
      "       'END_INTERVAL_TIME', 'FLUSH_ELAPSED'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "class NonNumericStrip:\n",
    "    \"\"\"\n",
    "    This class contains a method dedicated to feature removing if they contain non-numeric data\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def remove_non_numeric_columns(df):\n",
    "        \"\"\"\n",
    "        Accepts data matrix, and returns another matrix with stripped columns containing non-numeric data.\n",
    "        :param df: (Pandas) Data matrix\n",
    "        :return: (Pandas) Data matrix\n",
    "        \"\"\"\n",
    "        print('-'*10 + 'Before' + '-'*10)\n",
    "        print(df.columns)\n",
    "        col_list = []\n",
    "        for col in df.columns:\n",
    "            try:\n",
    "                df[col] = df[col].astype(float)\n",
    "                col_list.append(col)\n",
    "            except ValueError:\n",
    "                print('Column ' + str(col) + ' contains non numeric data')\n",
    "        df = df[col_list]\n",
    "        print('-'*10 + 'After' + '-'*10)\n",
    "        print(df.columns)\n",
    "        return df\n",
    "rep_hist_snapshot_df = NonNumericStrip.remove_non_numeric_columns(df=rep_hist_snapshot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Consolidation\n",
    "\n",
    "Grouping datasets on SNAP_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REP_HIST_SNAPSHOT shape before transformation: (9706, 70)\n",
      "REP_HIST_SNAPSHOT shape after transformation: (121, 70)\n"
     ]
    }
   ],
   "source": [
    "print(\"REP_HIST_SNAPSHOT shape before transformation: \" + str(rep_hist_snapshot_df_pruned.shape))\n",
    "rep_hist_snapshot_df_pruned = rep_hist_snapshot_df_pruned[rep_hist_snapshot_df_pruned['SNAP_ID'] > 0]\n",
    "\n",
    "# Group By Values by SNAP_ID , sum all metrics (for table REP_HIST_SNAPSHOT)\n",
    "rep_hist_snapshot_df_pruned = rep_hist_snapshot_df_pruned.groupby(['SNAP_ID']).sum()\n",
    "rep_hist_snapshot_df_pruned.reset_index(inplace=True)\n",
    "\n",
    "print(\"REP_HIST_SNAPSHOT shape after transformation: \" + str(rep_hist_snapshot_df_pruned.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "Relavent Sources:\n",
    "\n",
    "* http://jmlr.csail.mit.edu/papers/volume3/guyon03a/guyon03a.pdf\n",
    "* https://machinelearningmastery.com/rescaling-data-for-machine-learning-in-python-with-scikit-learn/\n",
    "\n",
    "https://machinelearningmastery.com/normalize-standardize-time-series-data-python/ recommends a normalization preprocessing technique for data distribution that can closely approximate minimum and maximum observable values per column:\n",
    "\n",
    "<i>\"Normalization requires that you know or are able to accurately estimate the minimum and maximum observable values. You may be able to estimate these values from your available data. If your time series is trending up or down, estimating these expected values may be difficult and normalization may not be the best method to use on your problem.\"</i>\n",
    "\n",
    "Normalization formula is stated as follows: $$y=(x-min)/(max-min)$$\n",
    "\n",
    "### Standardization\n",
    "\n",
    "https://machinelearningmastery.com/normalize-standardize-time-series-data-python/ recommends a standardization preprocessing technique for data distributions that observe a Gaussian spread, with a mean of 0 and a standard deviation of 1 (approximately close to these values):\n",
    "\n",
    "<i>\"Standardization assumes that your observations fit a Gaussian distribution (bell curve) with a well behaved mean and standard deviation. You can still standardize your time series data if this expectation is not met, but you may not get reliable results.\"</i>\n",
    "\n",
    "Standardization formula is stated as follows: $$y=(x-mean)/StandardDeviation$$\n",
    "Mean defined as: $$mean=sum(x)/count(x)$$\n",
    "Standard Deviation defined as: $$StandardDeviation=sqrt(sum((x-mean)^2)/count(x))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------BEFORE------------------\n",
      "------------------REP_HIST_SNAPSHOT------------------\n",
      "(121, 70)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------------AFTER------------------\n",
      "------------------REP_HIST_SNAPSHOT------------------\n",
      "(121, 70)\n",
      "\n",
      "\n",
      "\n",
      "REP_HIST_SNAPSHOT\n",
      "        SNAP_ID        SQL_ID  PLAN_HASH_VALUE  OPTIMIZER_COST  \\\n",
      "0  1.701353e-08  1.097685e-09         0.067526    6.655944e-08   \n",
      "1  1.646239e-09  2.602738e-10         0.005290    1.437212e-01   \n",
      "2  1.265592e-09  2.302004e-10         0.005895    1.104871e-01   \n",
      "3  1.433093e-09  2.590440e-10         0.006120    1.251072e-01   \n",
      "4  1.314871e-09  2.928464e-10         0.006796    1.147839e-01   \n",
      "\n",
      "   OPTIMIZER_MODE  OPTIMIZER_ENV_HASH_VALUE  SHARABLE_MEM  LOADED_VERSIONS  \\\n",
      "0    1.567561e-12                  0.048058      0.000095     1.136482e-10   \n",
      "1    9.100482e-13                  0.007965      0.000009     8.380027e-12   \n",
      "2    4.664058e-13                  0.008096      0.000008     1.122289e-11   \n",
      "3    4.621071e-13                  0.008824      0.000009     1.184975e-11   \n",
      "4    8.479522e-13                  0.009438      0.000009     1.541456e-11   \n",
      "\n",
      "   VERSION_COUNT        MODULE      ...        PHYSICAL_WRITE_BYTES_DELTA  \\\n",
      "0   5.717680e-10  1.645939e-11      ...                      0.000000e+00   \n",
      "1   4.246891e-11  4.739834e-12      ...                      2.547164e-08   \n",
      "2   5.658085e-11  3.556344e-12      ...                      2.387997e-08   \n",
      "3   5.720225e-11  3.993925e-12      ...                      6.759966e-08   \n",
      "4   7.113713e-11  4.239761e-12      ...                      4.341515e-08   \n",
      "\n",
      "   IO_OFFLOAD_RETURN_BYTES_TOTAL  IO_OFFLOAD_RETURN_BYTES_DELTA     BIND_DATA  \\\n",
      "0                  -3.467195e-07                            0.0  4.702684e-12   \n",
      "1                  -2.046615e-05                            0.0  3.336843e-12   \n",
      "2                   2.239703e-06                            0.0  2.069676e-12   \n",
      "3                  -1.465615e-05                            0.0  2.574597e-12   \n",
      "4                   2.326804e-06                            0.0  6.632198e-12   \n",
      "\n",
      "           FLAG      SQL_TEXT  COMMAND_TYPE  BEGIN_INTERVAL_TIME  \\\n",
      "0  2.351342e-12  1.097685e-09  9.131045e-11         0.000000e+00   \n",
      "1  2.275120e-13  2.602738e-10  1.486412e-11         2.805982e-12   \n",
      "2  1.749022e-13  2.302004e-10  1.043583e-11         5.247065e-12   \n",
      "3  1.980459e-13  2.590440e-10  1.148666e-11         8.614996e-12   \n",
      "4  1.817040e-13  2.928464e-10  1.226502e-11         1.223474e-11   \n",
      "\n",
      "   END_INTERVAL_TIME  FLUSH_ELAPSED  \n",
      "0       0.000000e+00   0.000000e+00  \n",
      "1       2.805982e-12   2.805982e-12  \n",
      "2       5.247065e-12   5.247065e-12  \n",
      "3       8.614996e-12   2.871665e-12  \n",
      "4       1.223474e-11   0.000000e+00  \n",
      "\n",
      "[5 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "class Normalizer:\n",
    "\n",
    "    @staticmethod\n",
    "    def robust_scaler(dataframe):\n",
    "        \"\"\"\n",
    "        Normalize df using interquartile ranges as min-max, this way outliers do not play a heavy emphasis on the\n",
    "        normalization of values.\n",
    "        :param dataframe: (Pandas) Pandas data matrix\n",
    "        :return: (Pandas) Normalized data matrix\n",
    "        \"\"\"\n",
    "        headers = dataframe.columns\n",
    "        X = preprocessing.robust_scale(dataframe.values)\n",
    "        return pd.DataFrame(X, columns=headers)\n",
    "\n",
    "    @staticmethod\n",
    "    def minmax_scaler(dataframe):\n",
    "        \"\"\"\n",
    "        Normalize df using min-max ranges for normalization method\n",
    "        :param dataframe: (Pandas) Pandas data matrix\n",
    "        :return: (Pandas) Normalized data matrix\n",
    "        \"\"\"\n",
    "        headers = dataframe.columns\n",
    "        X = preprocessing.minmax_scale(dataframe.values)\n",
    "        return pd.DataFrame(X, columns=headers)\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(dataframe):\n",
    "        \"\"\"\n",
    "        The normalizer scales each value by dividing each value by its magnitude in n-dimensional space for n number of features.\n",
    "        :param dataframe: (Pandas) Pandas data matrix\n",
    "        :return: (Pandas) Normalized data matrix\n",
    "        \"\"\"\n",
    "        headers = dataframe.columns\n",
    "        X = preprocessing.normalize(dataframe.values)\n",
    "        return pd.DataFrame(X, columns=headers)\n",
    "\n",
    "print('------------------BEFORE------------------')\n",
    "print('------------------REP_HIST_SNAPSHOT------------------')\n",
    "print(rep_hist_snapshot_df_pruned.shape)\n",
    "print('\\n')\n",
    "#print(rep_hist_snapshot_df_pruned.head())\n",
    "\n",
    "# ROBUST SCALER\n",
    "# rep_hist_snapshot_df_pruned_norm = Normalizer.robust_scaler(dataframe=rep_hist_snapshot_df_pruned\n",
    "\n",
    "# MINMAX SCALER\n",
    "#rep_hist_snapshot_df_pruned_norm = Normalizer.minmax_scaler(dataframe=rep_hist_snapshot_df_pruned)\n",
    "\n",
    "# NORMALIZER\n",
    "rep_hist_snapshot_df_pruned_norm = Normalizer.normalize(dataframe=rep_hist_snapshot_df_pruned)\n",
    "\n",
    "print('\\n\\n------------------AFTER------------------')\n",
    "print('------------------REP_HIST_SNAPSHOT------------------')\n",
    "print(rep_hist_snapshot_df_pruned_norm.shape)\n",
    "print('\\n\\n')\n",
    "print('REP_HIST_SNAPSHOT')\n",
    "print(rep_hist_snapshot_df_pruned_norm.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Methods\n",
    "\n",
    "* https://machinelearningmastery.com/feature-selection-machine-learning-python/\n",
    "* https://towardsdatascience.com/running-random-forests-inspect-the-feature-importances-with-this-code-2b00dd72b92e\n",
    "\n",
    "Filter methods allow for the univariate analysis of features. Particularly, the following statistical methods have been considered and dismissed as explained below:\n",
    "\n",
    "* Information Gain - Data at hand is continous by nature, whilst MI is usually applicable against discrete values / binned labels.\n",
    "* Pearson Correlation Coefficient - Applicable to data with linear distributions, which is not the case for the majority of the presented features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureImportance:\n",
    "    \"\"\"\n",
    "    This class is dedicated to containing methods related to feature ranking. Features are ranked exclusively, or mutually with\n",
    "    repsect to other features.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def chi2_test(top_n_features=30, X_df=None, y_df=None, table=None):\n",
    "        \"\"\"\n",
    "        Carries out a chi squared test on passed X,y dataframes, selecting top N features ranked by highest scoring.\n",
    "        :param top_n_features: (Integer) Denotes number of top features to plot.\n",
    "        :param x_df:           (Pandas) Pandas feature matrix.\n",
    "        :param y_df:           (Pandas) Pandas label matrix.\n",
    "        :param table:          (String) Denotes which table is being operated on.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        headers = X_df.columns\n",
    "        X_df = X_df.values\n",
    "        y_df = y_df.values\n",
    "        chi2_selector = SelectKBest(score_func=chi2, k=top_n_features)\n",
    "        X_kbest = chi2_selector.fit_transform(X_df, y_df)\n",
    "        print('\\n\\nTable [' + table.upper() + ']')\n",
    "        print('Original number of features: ' + str(X_df.shape[1]))\n",
    "        print('Reduced number of features: ' + str(X_kbest.shape[1]) + \"\\n\")\n",
    "        outcome = chi2_selector.get_support()\n",
    "\n",
    "        scoring_sheet = []\n",
    "        for i in range(0,len(headers)-1):\n",
    "            if outcome[i]:\n",
    "                scoring_sheet.append([headers[i],chi2_selector.scores_[i]])\n",
    "\n",
    "        scoring_sheet = sorted(scoring_sheet, key=itemgetter(1), reverse=True)\n",
    "        [print('Feature [' + str(row) + '] with score [' + str(score) + ']') for row, score in scoring_sheet[:top_n_features]]\n",
    "\n",
    "        scoring_sheet = pd.Series((v[1] for v in scoring_sheet[:top_n_features]) )\n",
    "        scoring_sheet[:top_n_features].plot.bar()\n",
    "        \n",
    "        FeatureImportance.__plot_metrics(ylabel='CHI2 RANKING',\n",
    "                                         xlabel='FEATURES',\n",
    "                                         title='Features Ranked By Chi2 Scoring')\n",
    "      \n",
    "    @staticmethod\n",
    "    def rfr_ranking(X_df=None, y_df=None, top_n_features=30, parallel_degree=1):\n",
    "        \"\"\"\n",
    "        Ranks features using a filter RFR method, and plots them in descending order (ranked by importance)\n",
    "        :param x_df:           (Pandas) Pandas feature matrix.\n",
    "        :param y_df:           (Pandas) Pandas label matrix.\n",
    "        :param top_n_features: (Integer) Denotes number of top features to plot.\n",
    "        :param parallel_degree:(Integer) Denotes model training parallel degree.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        headers = X_df.columns\n",
    "        X_df = X_df.values\n",
    "        y_df = y_df.values\n",
    "        rfr = RandomForestRegressor(n_estimators=1000,\n",
    "                                    n_jobs=parallel_degree)\n",
    "        rfr.fit(X_df, y_df)\n",
    "        importances = pd.DataFrame({'feature':headers,\n",
    "                                    'importance':np.round(rfr.feature_importances_,3)})\n",
    "        importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "        print(importances[:top_n_features])\n",
    "        importances[:top_n_features].plot.bar()\n",
    "        \n",
    "        FeatureImportance.__plot_metrics(ylabel='RANDOM FOREST RANKING',\n",
    "                                         xlabel='FEATURES',\n",
    "                                         title='Features Ranked By Random Forest Scoring')\n",
    "        \n",
    "    @staticmethod\n",
    "    def __plot_metrics(ylabel, xlabel, title):\n",
    "        \"\"\"\n",
    "        Private method used to plot metrics for statistical feature evaluation\n",
    "        :param ylabel: (String) ylabel title name.\n",
    "        :param xlabel: (String) xlabel title name.\n",
    "        :param title:  (String) plot title name.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.title(title)\n",
    "        plt.rcParams['figure.figsize'] = [20, 15]\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi2\n",
    "\n",
    "Therefore, a likely candidate for a first univariate, filter test is a chi2 measure, between X labels 'SNAP_ID', and other output 'y' labels. NB: Due to chi2 requiring non-nagative values, a data normalization strategy was opted for (Refer to above cell).\n",
    "\n",
    "The following cell computes the chi2 value for each feature pertaining in the following tables, in relation to the SNAP_ID feature:\n",
    "* REP_HIST_SNAPSHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rep_hist_snapshot_df_pruned_scaled = Normalizer.minmax_scaler(dataframe=rep_hist_snapshot_df_pruned)\n",
    "# FeatureImportance.chi2_test(top_n_features=top_n_features, \n",
    "#                             X_df=rep_hist_snapshot_df_pruned_scaled, \n",
    "#                             y_df=rep_hist_snapshot_df_pruned_scaled['SNAP_ID'], \n",
    "#                             table='REP_HIST_SNAPSHOT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Feature Importance\n",
    "\n",
    "Calculating MI (Mutual Information) scoring between data matrix X (feature vectors) and target column y ('SNAP_ID') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               importance\n",
      "feature                                  \n",
      "SNAP_ID                               0.0\n",
      "APWAIT_DELTA                          0.0\n",
      "PLSEXEC_TIME_DELTA                    0.0\n",
      "PLSEXEC_TIME_TOTAL                    0.0\n",
      "DIRECT_WRITES_DELTA                   0.0\n",
      "DIRECT_WRITES_TOTAL                   0.0\n",
      "CCWAIT_DELTA                          0.0\n",
      "CCWAIT_TOTAL                          0.0\n",
      "APWAIT_TOTAL                          0.0\n",
      "IO_INTERCONNECT_BYTES_DELTA           0.0\n",
      "IOWAIT_DELTA                          0.0\n",
      "IOWAIT_TOTAL                          0.0\n",
      "ELAPSED_TIME_DELTA                    0.0\n",
      "ELAPSED_TIME_TOTAL                    0.0\n",
      "CPU_TIME_DELTA                        0.0\n",
      "CPU_TIME_TOTAL                        0.0\n",
      "IO_INTERCONNECT_BYTES_TOTAL           0.0\n",
      "PHYSICAL_READ_REQUESTS_TOTAL          0.0\n",
      "SQL_ID                                0.0\n",
      "IO_OFFLOAD_RETURN_BYTES_DELTA         0.0\n",
      "END_INTERVAL_TIME                     0.0\n",
      "BEGIN_INTERVAL_TIME                   0.0\n",
      "COMMAND_TYPE                          0.0\n",
      "SQL_TEXT                              0.0\n",
      "FLAG                                  0.0\n",
      "BIND_DATA                             0.0\n",
      "IO_OFFLOAD_RETURN_BYTES_TOTAL         0.0\n",
      "PHYSICAL_READ_REQUESTS_DELTA          0.0\n",
      "PHYSICAL_WRITE_BYTES_DELTA            0.0\n",
      "PHYSICAL_WRITE_BYTES_TOTAL            0.0\n",
      "PHYSICAL_WRITE_REQUESTS_DELTA         0.0\n",
      "PHYSICAL_WRITE_REQUESTS_TOTAL         0.0\n",
      "PHYSICAL_READ_BYTES_DELTA             0.0\n",
      "PHYSICAL_READ_BYTES_TOTAL             0.0\n",
      "ROWS_PROCESSED_DELTA                  0.0\n",
      "ROWS_PROCESSED_TOTAL                  0.0\n",
      "BUFFER_GETS_DELTA                     0.0\n",
      "MODULE                                0.0\n",
      "FETCHES_TOTAL                         0.0\n",
      "PARSING_USER_ID                       0.0\n",
      "PARSING_SCHEMA_NAME                   0.0\n",
      "PARSING_SCHEMA_ID                     0.0\n",
      "FORCE_MATCHING_SIGNATURE              0.0\n",
      "ACTION                                0.0\n",
      "VERSION_COUNT                         0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "FeatureImportance.rfr_ranking(top_n_features=top_n_features,\n",
    "                              X_df=rep_hist_snapshot_df_pruned_norm, \n",
    "                              y_df=rep_hist_snapshot_df_pruned_norm['SNAP_ID'],\n",
    "                              parallel_degree=parallel_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper Methods\n",
    "\n",
    "Use a number of machine learning models to evaluate features together and rank by highest. The following machine learning models will be opted for:\n",
    "\n",
    "* Random Forest Classifier\n",
    "* Gradient Boosting\n",
    "\n",
    "In a 'Brute-Fore' approach, these machine learning heuristics will strip away 1 feature at a time in a method referred to as 'Recursive Feature Elimination', and compare accuracy with every variable elimination. This allows the respective classifier to establish an optimum feature configuration with the highest accuracy score.\n",
    "\n",
    "https://www.fabienplisson.com/choosing-right-features/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleWrappers:\n",
    "    \"\"\"\n",
    "    This class contains wrapper methods, which utilize ensemble methods to gauge feature pairings. Features are combined together\n",
    "    and then stripped one at a time. Each feature combination is evaluated per feature count, so as to establish the optimum\n",
    "    feature count cut off.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def rfr_wrapper(X_df=None, y_df=None, test_split=.4, table_name=None, top_n_features=10, parallel_degree=1):\n",
    "        \"\"\"\n",
    "        Random Forest Regressor - Takes data matrix and target vector, and evaluates best combination of features \n",
    "        using an RFR model.\n",
    "        :param x_df:           (Pandas) Pandas feature matrix.\n",
    "        :param y_df:           (Pandas) Pandas label matrix.\n",
    "        :param test_split:     (Float) Denotes training/testing data split.\n",
    "        :param table_name:     (String) Denotes which table is being operated on.\n",
    "        :param top_n_features: (Integer) Denotes number of top features to plot.\n",
    "        :param parallel_degree:(Integer) Denotes model training parallel degree.\n",
    "        :return: Model Scoring, for best feature combination count\n",
    "        :return: Recommended feature count, as per best achieved score\n",
    "        \"\"\"\n",
    "        X_df = X_df.values\n",
    "        y_df = y_df.values\n",
    "        val_op, optimum_features = 0, 0\n",
    "        val_op = 0\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=test_split)\n",
    "        model = RandomForestRegressor(n_estimators=1000, \n",
    "                                      n_jobs=parallel_degree)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # make predictions for test data and evaluate\n",
    "        pred_y = model.predict(X_test)\n",
    "        predictions = [round(value) for value in pred_y]\n",
    "        r2s = r2_score(y_test, predictions)\n",
    "        print(\"Table [\" + table_name + \"] RFR R2 Score: \" + str(r2s))\n",
    "\n",
    "        # fit model using each importance as a threshold\n",
    "        print('Feature Importance\\n' + str('-'*60))\n",
    "        print(model.feature_importances_)\n",
    "        print(str('-'*60))\n",
    "        thresholds = np.sort(model.feature_importances_)\n",
    "        feature_counts, feature_score = [],[]\n",
    "        for thresh in thresholds:\n",
    "            # selecting features using threshold\n",
    "            selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "            select_train_x = selection.transform(X_train)\n",
    "\n",
    "            # training model\n",
    "            selection_model = RandomForestRegressor(n_estimators=1000,\n",
    "                                                    n_jobs=parallel_degree)\n",
    "            selection_model.fit(select_train_x, y_train)\n",
    "\n",
    "            # evaluating model\n",
    "            select_test_x = selection.transform(X_test)\n",
    "            pred_y = selection_model.predict(select_test_x)\n",
    "            predictions = [round(value) for value in pred_y]\n",
    "            r2s = r2_score(y_test, predictions)\n",
    "            print(\"Thresh=\" + str(thresh) + \", n=\" + str(select_train_x.shape[1]) + \", R2 Score: \" + str(r2s))\n",
    "            if(r2s > val_op):\n",
    "                val_op = r2s\n",
    "                optimum_features = select_train_x.shape[1]\n",
    "\n",
    "            # Add/Keep track of '[no of features','r2 score']\n",
    "            feature_counts.append(select_train_x.shape[1])\n",
    "            feature_score.append(r2s)\n",
    "\n",
    "        # Plot feature count performance\n",
    "        EnsembleWrappers.__plot_metrics(feature_counts=feature_counts,\n",
    "                                        feature_score=feature_score,\n",
    "                                        xlabel='Featuers',\n",
    "                                        ylabel='R2 Score',\n",
    "                                        title='Feature Pairing Performance')\n",
    "\n",
    "        return val_op, optimum_features\n",
    "\n",
    "    @staticmethod\n",
    "    def gradient_boosting_wrapper(X_df=None, y_df=None, test_split=.4, table_name=None, top_n_features=10):\n",
    "        \"\"\"\n",
    "        Gradient Boosting Regressor - Takes data matrix and target vector, and evaluates best combination of features \n",
    "        using a GBR model.\n",
    "        :param x_df:           (Pandas) Pandas feature matrix.\n",
    "        :param y_df:           (Pandas) Pandas label matrix.\n",
    "        :param test_split:     (Float) Denotes training/testing data split.\n",
    "        :param table_name:     (String) Denotes which table is being operated on.\n",
    "        :param top_n_features: (Integer) Denotes number of top features to plot.\n",
    "        :return: Model Scoring, for best feature combination count\n",
    "        :return: Recommended feature count, as per best achieved score\n",
    "        \"\"\"\n",
    "        X_df = X_df.values\n",
    "        y_df = y_df.values\n",
    "        val_op, optimum_features = 0, 0\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=test_split)\n",
    "        model = GradientBoostingRegressor(n_estimators=1000)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # make predictions for test data and evaluate\n",
    "        pred_y = model.predict(X_test)\n",
    "        predictions = [round(value) for value in pred_y]\n",
    "        r2s = r2_score(y_test, predictions)\n",
    "        print(\"Table [\" + table_name + \"] RFR R2 Score: \" + str(r2s))\n",
    "        #\n",
    "        # fit model using each importance as a threshold\n",
    "        print('Feature Importance\\n' + str('-'*60))\n",
    "        print(model.feature_importances_)\n",
    "        print(str('-'*60))\n",
    "        thresholds = np.sort(model.feature_importances_)\n",
    "        feature_counts, feature_score = [],[]\n",
    "        for thresh in thresholds:\n",
    "            # selecting features using threshold\n",
    "            selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "            select_train_x = selection.transform(X_train)\n",
    "\n",
    "            # training model\n",
    "            selection_model = GradientBoostingRegressor(n_estimators=1000)\n",
    "            selection_model.fit(select_train_x, y_train)\n",
    "\n",
    "            # evaluating model\n",
    "            select_test_x = selection.transform(X_test)\n",
    "            pred_y = selection_model.predict(select_test_x)\n",
    "            predictions = [round(value) for value in pred_y]\n",
    "            r2s = r2_score(y_test, predictions)\n",
    "            print(\"Thresh=\" + str(thresh) + \", n=\" + str(select_train_x.shape[1]) + \", R2 Score: \" + str(r2s))\n",
    "            if(r2s > val_op):\n",
    "                val_op = r2s\n",
    "                optimum_features = select_train_x.shape[1]\n",
    "\n",
    "            # Add/Keep track of '[no of features','r2 score']\n",
    "            feature_counts.append(select_train_x.shape[1])\n",
    "            feature_score.append(r2s)\n",
    "\n",
    "        # Plot feature count performance\n",
    "        EnsembleWrappers.__plot_metrics(feature_counts=feature_counts,\n",
    "                                        feature_score=feature_score,\n",
    "                                        xlabel='Featuers',\n",
    "                                        ylabel='R2 Score',\n",
    "                                        title='Feature Pairing Performance')\n",
    "\n",
    "        return val_op, optimum_features\n",
    "    \n",
    "    @staticmethod\n",
    "    def __plot_metrics(feature_counts, feature_score, ylabel, xlabel, title):\n",
    "        \"\"\"\n",
    "        Private method used to plot metrics for statistical feature evaluation\n",
    "        :param feature_counts: (List) List of feature combination counts per achieved score.\n",
    "        :param feature_score:  (List) List of feature scores per combination.\n",
    "        :param ylabel:         (String) ylabel title name.\n",
    "        :param xlabel:         (String) xlabel title name.\n",
    "        :param title:          (String) plot title name.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.title(title)\n",
    "        plt.rcParams['figure.figsize'] = [20, 15]\n",
    "        plt.plot(feature_counts, feature_score)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Wrapper (Feature Combination)  (Regression)\n",
    "\n",
    "Utilizes an ensemble Random Forest method to gauge different feature combination/counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table [REP_HIST_SNAPSHOT] RFR R2 Score: 0.45296643526015923\n",
      "Feature Importance\n",
      "------------------------------------------------------------\n",
      "[1.33628985e-04 0.00000000e+00 1.41906046e-02 3.86138745e-02\n",
      " 0.00000000e+00 1.87630897e-02 5.27164994e-02 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.08525780e-02\n",
      " 0.00000000e+00 7.20612804e-03 0.00000000e+00 5.97969574e-03\n",
      " 0.00000000e+00 1.37384573e-02 0.00000000e+00 9.16243310e-04\n",
      " 0.00000000e+00 4.37577092e-04 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 8.68187703e-03 0.00000000e+00 1.41280796e-02\n",
      " 1.57866836e-03 2.98615736e-02 2.10308495e-02 1.44541050e-02\n",
      " 1.89938672e-03 1.77576659e-02 9.63347754e-03 1.36309475e-02\n",
      " 1.09540694e-02 2.19711064e-02 7.43327694e-02 5.00745321e-03\n",
      " 0.00000000e+00 1.34028176e-02 4.38212432e-03 2.79541860e-02\n",
      " 0.00000000e+00 2.13988957e-02 1.26995056e-03 8.44860344e-02\n",
      " 2.00771882e-02 9.03612653e-02 8.42612160e-06 2.38790601e-02\n",
      " 2.35385709e-02 1.23402597e-03 0.00000000e+00 8.66252835e-02\n",
      " 6.79606176e-02 1.14951148e-01 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n",
      "------------------------------------------------------------\n",
      "Thresh=0.0, n=70, R2 Score: 0.4582068429425772\n",
      "Thresh=0.0, n=70, R2 Score: 0.47689356801166427\n",
      "Thresh=0.0, n=70, R2 Score: 0.4414294136957664\n",
      "Thresh=0.0, n=70, R2 Score: 0.46531592313190373\n",
      "Thresh=0.0, n=70, R2 Score: 0.46133483822588084\n",
      "Thresh=0.0, n=70, R2 Score: 0.4590802442229801\n",
      "Thresh=0.0, n=70, R2 Score: 0.452316462214278\n",
      "Thresh=0.0, n=70, R2 Score: 0.46622994772767434\n",
      "Thresh=0.0, n=70, R2 Score: 0.46129421491051326\n",
      "Thresh=0.0, n=70, R2 Score: 0.45081339954567745\n",
      "Thresh=0.0, n=70, R2 Score: 0.46740802387333413\n",
      "Thresh=0.0, n=70, R2 Score: 0.4623097977947028\n",
      "Thresh=0.0, n=70, R2 Score: 0.47088131733726235\n",
      "Thresh=0.0, n=70, R2 Score: 0.45063059462652333\n",
      "Thresh=0.0, n=70, R2 Score: 0.4572725066891228\n",
      "Thresh=0.0, n=70, R2 Score: 0.46180200635260804\n",
      "Thresh=0.0, n=70, R2 Score: 0.46363005554414916\n",
      "Thresh=0.0, n=70, R2 Score: 0.4493509601924446\n",
      "Thresh=0.0, n=70, R2 Score: 0.46174107137955667\n",
      "Thresh=0.0, n=70, R2 Score: 0.4649706249512794\n",
      "Thresh=0.0, n=70, R2 Score: 0.44709636618954385\n",
      "Thresh=0.0, n=70, R2 Score: 0.458125596311842\n",
      "Thresh=0.0, n=70, R2 Score: 0.4647268850590739\n",
      "Thresh=0.0, n=70, R2 Score: 0.4607864234684186\n",
      "Thresh=0.0, n=70, R2 Score: 0.4731359113401631\n",
      "Thresh=0.0, n=70, R2 Score: 0.4674689588463855\n",
      "Thresh=0.0, n=70, R2 Score: 0.44918846693097425\n",
      "Thresh=0.0, n=70, R2 Score: 0.45944585406128835\n",
      "Thresh=0.0, n=70, R2 Score: 0.4530476818908944\n",
      "Thresh=0.0, n=70, R2 Score: 0.46570184462789577\n",
      "Thresh=8.426121595139412e-06, n=40, R2 Score: 0.4658643378893661\n",
      "Thresh=0.0001336289847146721, n=39, R2 Score: 0.4550991593169572\n",
      "Thresh=0.0004375770922799541, n=38, R2 Score: 0.45195085237596977\n",
      "Thresh=0.0009162433100033345, n=37, R2 Score: 0.46592527286241747\n",
      "Thresh=0.0012340259712059656, n=36, R2 Score: 0.4637113021748843\n",
      "Thresh=0.001269950559284345, n=35, R2 Score: 0.446690133035868\n",
      "Thresh=0.0015786683562256398, n=34, R2 Score: 0.4518899174029184\n",
      "Thresh=0.0018993867235148525, n=33, R2 Score: 0.4621269928755487\n",
      "Thresh=0.004382124321238483, n=32, R2 Score: 0.45008217986906107\n",
      "Thresh=0.00500745321330295, n=31, R2 Score: 0.4563178587779847\n",
      "Thresh=0.005979695744030591, n=30, R2 Score: 0.45453043290181117\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-4ca7a3236b23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                                                         \u001b[0mtable_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'REP_HIST_SNAPSHOT'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                                                         \u001b[0mtop_n_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtop_n_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                                                                                         parallel_degree=parallel_degree)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-6b119160fa4e>\u001b[0m in \u001b[0;36mrfr_wrapper\u001b[1;34m(X_df, y_df, test_split, table_name, top_n_features, parallel_degree)\u001b[0m\n\u001b[0;32m     48\u001b[0m             selection_model = RandomForestRegressor(n_estimators=1000,\n\u001b[0;32m     49\u001b[0m                                                     n_jobs=parallel_degree)\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0mselection_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselect_train_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;31m# evaluating model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[1;32m--> 321\u001b[1;33m                                             random_state=random_state)\n\u001b[0m\u001b[0;32m    322\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[1;34m(self, append, random_state)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0msub\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \"\"\"\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m         estimator.set_params(**dict((p, getattr(self, p))\n\u001b[0;32m    128\u001b[0m                                     for p in self.estimator_params))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mparams_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m# quick sanity check of the parameters of the clone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mget_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \"\"\"\n\u001b[0;32m    180\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_params'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0minit_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         parameters = [p for p in init_signature.parameters.values()\n\u001b[0m\u001b[0;32m    154\u001b[0m                       if p.name != 'self' and p.kind != p.VAR_KEYWORD]\n\u001b[0;32m    155\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n\u001b[1;32m--> 154\u001b[1;33m                       if p.name != 'self' and p.kind != p.VAR_KEYWORD]\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVAR_POSITIONAL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rfr_rep_hist_snapshot_score, rfr_rep_hist_snapshot_count = EnsembleWrappers.rfr_wrapper(X_df=rep_hist_snapshot_df_pruned_norm,\n",
    "                                                                                        y_df=rep_hist_snapshot_df_pruned['SNAP_ID'],\n",
    "                                                                                        test_split=test_split,\n",
    "                                                                                        table_name='REP_HIST_SNAPSHOT',\n",
    "                                                                                        top_n_features=top_n_features,\n",
    "                                                                                        parallel_degree=parallel_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Wrapper (Feature Combination)  (Regression)\n",
    "\n",
    "Utilizes an ensemble Gradient Boosting method to gauge different feature combination/counts.\n",
    "\n",
    "https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbw_rep_hist_snapshot_score, gbw_rep_hist_snapshot_count = EnsembleWrappers.gradient_boosting_wrapper(X_df=rep_hist_snapshot_df_pruned_norm,\n",
    "                                                                                                      y_df=rep_hist_snapshot_df_pruned['SNAP_ID'],\n",
    "                                                                                                      test_split=test_split,\n",
    "                                                                                                      table_name='REP_HIST_SNAPSHOT',\n",
    "                                                                                                      top_n_features=top_n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination (Regression)\n",
    "\n",
    "Implements a recursive solution, where in features are eliminated based on an ensemble evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEliminator:\n",
    "    \"\"\"\n",
    "    This class is dedicated to housing logic pertaining to feature selection - retaining only labels which are considered\n",
    "    important.\n",
    "    \"\"\"\n",
    "    def __init__(self, X_df, y_df):\n",
    "        \"\"\"\n",
    "        Class constructor.\n",
    "        :param X_df: (Pandas) Pandas feature matrix.\n",
    "        :param y_df: (Pandas) Pandas label matrix.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.__X_df = X_df\n",
    "        self.__y_df = y_df\n",
    "    \n",
    "    def rfe_selector(self, test_split=.4, optimum_feature_count=0, model=None, parallel_degree=1):\n",
    "        \"\"\"\n",
    "        Recursive Feature Elimination Function. Isolates and eliminated features one by one, up till the desired amount, starting\n",
    "        by features which are considered less important.\n",
    "        :param test_split:            (Float) Denotes training/testing data split.\n",
    "        :param optimum_feature_count: (Integer) Denotes the best estimated number of features to retain before a performance drop\n",
    "                                                is estimated.\n",
    "        :param parallel_degree:       (Integer) Denotes model training parallel degree.\n",
    "        :return: (List) This list is composed of boolean values, which correspond to the input feature column headers. True List \n",
    "                        values denote columns which have been retained. False values denote eliminated feature headers.\n",
    "        :return: (List) This list denotes feature rankings, which correspond to the input feature column headers. Values of '1',\n",
    "                        denote that features have been retained.\n",
    "        \"\"\"\n",
    "        X_df = self.__X_df.values\n",
    "        y_df = self.__y_df.values\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=test_split)\n",
    "        if model == 0:\n",
    "            model = RandomForestRegressor(n_estimators=1000,\n",
    "                                          n_jobs=parallel_degree)\n",
    "        elif model == 1:\n",
    "            model = GradientBoostingRegressor(n_estimators=1000)\n",
    "\n",
    "        # create the RFE model and select N attributes\n",
    "        rfe_model = RFE(model, optimum_feature_count, step=1)\n",
    "        rfe_model = rfe_model.fit(X_train, y_train)\n",
    "\n",
    "        # summarize the selection of the attributes\n",
    "        print(rfe_model.support_)\n",
    "        print(rfe_model.ranking_)\n",
    "\n",
    "        # evaluate the model on testing set\n",
    "        pred_y = rfe_model.predict(X_test)\n",
    "        predictions = [round(value) for value in pred_y]\n",
    "        r2s = r2_score(y_test, predictions)\n",
    "        \n",
    "        return rfe_model.support_, rfe_model.ranking_\n",
    "    \n",
    "    def get_selected_features(self, column_mask):\n",
    "        \"\"\"\n",
    "        Retrieves features which have not been eliminated from the RFE function.\n",
    "        :param column_mask: (List) This list is composed of boolean values, which correspond to the input feature column headers. \n",
    "                                   True list values denote columns which have been retained. False values denote eliminated \n",
    "                                   feature headers. \n",
    "        :return: (Pandas) Pandas data matrix.\n",
    "        \"\"\"\n",
    "        recommended_columns = []\n",
    "        for i in range(len(self.__X_df.columns)):\n",
    "            if (column_mask[i]):\n",
    "                recommended_columns.append(self.__X_df.columns[i])\n",
    "                \n",
    "        return self.__X_df[recommended_columns]\n",
    "    \n",
    "if rfr_rep_hist_snapshot_score > gbw_rep_hist_snapshot_score:\n",
    "    rep_hist_snapshot_op = rfr_rep_hist_snapshot_count\n",
    "    rep_hist_snapshot_model = 0\n",
    "else:\n",
    "    rep_hist_snapshot_op = gbw_rep_hist_snapshot_count\n",
    "    rep_hist_snapshot_model = 1\n",
    "\n",
    "fe = FeatureEliminator(X_df=rep_hist_snapshot_df_pruned_norm,\n",
    "                       y_df=rep_hist_snapshot_df_pruned_norm['SNAP_ID'])\n",
    "\n",
    "print('Recommended Feature Drop [' + str(rep_hist_snapshot_op) + '] using model [' + str(rep_hist_snapshot_model) + ']')\n",
    "column_mask, column_rankings = fe.rfe_selector(test_split=test_split,\n",
    "                                               optimum_feature_count=rep_hist_snapshot_op,\n",
    "                                               model = rep_hist_snapshot_model,\n",
    "                                               parallel_degree=parallel_degree)\n",
    "print(rep_hist_snapshot_df_pruned_norm.columns)\n",
    "rep_hist_snapshot_df_pruned_norm = fe.get_selected_features(column_mask=column_mask)\n",
    "print(rep_hist_snapshot_df_pruned_norm.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Decomposition\n",
    "\n",
    "Principal component analysis: Factor model in which the factors are based on summarizing the total variance. With PCA, unities are used in the diagonal of the correlation matrix computationally implying that all the variance is common or shared.\n",
    "\n",
    "https://towardsdatascience.com/an-approach-to-choosing-the-number-of-components-in-a-principal-component-analysis-pca-3b9f3d6e73fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrincipalComponentAnalysisClass:\n",
    "    \"\"\"\n",
    "    This class handles logic related to PCA data transformations.\n",
    "    https://towardsdatascience.com/an-approach-to-choosing-the-number-of-components-in-a-principal-component-analysis-pca-3b9f3d6e73fe\n",
    "    \"\"\"\n",
    "    def __init__(self, X_df):\n",
    "        \"\"\"\n",
    "        Cosntructor method.\n",
    "        :param X_df: (Pandas) Dataframe consisting of input features, which will be subject to PCA.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.__X_df = X_df\n",
    "        \n",
    "    def get_default_component_variances(self):\n",
    "        \"\"\"\n",
    "        Fitting the PCA algorithm with our Data.\n",
    "        :return: (Numpy array) Array of feature variances.\n",
    "        \"\"\"\n",
    "        pca = PCA().fit(self.__X_df.values)\n",
    "        return np.cumsum(pca.explained_variance_ratio_)\n",
    "        \n",
    "    def get_default_component_count(self, threshold=.99):\n",
    "        \"\"\"\n",
    "        Retrieves the recommended number of component decomposition, above which very little variance \n",
    "        gain is achieved. This treshold will be set at a 0.999 variance threshold.\n",
    "        :param threshold: (Float) Threshold value between 0 and 1. Stops immediately as soon the number\n",
    "                                  of required components exceeds the threshold value.\n",
    "        :return: (Integer) Returns the number of recommended components.\n",
    "        \"\"\"\n",
    "        variance_ratios = self.get_default_component_variances()\n",
    "        n = 0\n",
    "        for val in variance_ratios:\n",
    "            if val < threshold:\n",
    "                n += 1\n",
    "        return n\n",
    "    \n",
    "    def plot_variance_per_reduction(self):\n",
    "        \"\"\"\n",
    "        This method subjects the feature matrix to a PCA decomposition. The number of components is plot\n",
    "        vs the amount of retained variance.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        variance_ratios = self.get_default_component_variances()\n",
    "        \n",
    "        #Plotting the Cumulative Summation of the Explained Variance\n",
    "        plt.figure()\n",
    "        plt.plot(variance_ratios)\n",
    "        plt.xlabel('Number of Components')\n",
    "        plt.ylabel('Variance (%)') #for each component\n",
    "        plt.title(tpcds + ' Dataset Explained Variance')\n",
    "        plt.show()\n",
    "        \n",
    "    def apply_PCA(self, n_components):\n",
    "        \"\"\"\n",
    "        Applies Principle Component Analysis on the constructor passed data matrix, on a number of components.\n",
    "        A new pandas data matrix is returned, with renamed 'Principal Component' headers.\n",
    "        :param n_components: (Integer) Denotes number of component breakdown.\n",
    "        :return: (Pandas) Dataframe consisting of new decomposed components.\n",
    "        \"\"\"\n",
    "        pca = PCA(n_components=n_components)\n",
    "        dataset = pca.fit_transform(self.__X_df.values)\n",
    "        header_list = []\n",
    "        for i in range(dataset.shape[1]):\n",
    "            header_list.append('Component_' + str(i))\n",
    "        return pd.DataFrame(data=dataset, columns=header_list)\n",
    "\n",
    "print(rep_hist_snapshot_df_pruned_norm.head())\n",
    "print(rep_hist_snapshot_df_pruned_norm.shape)\n",
    "\n",
    "pcac = PrincipalComponentAnalysisClass(X_df=rep_hist_snapshot_df_pruned_norm)\n",
    "pcac.plot_variance_per_reduction()\n",
    "component_count = pcac.get_default_component_count()\n",
    "rep_hist_snapshot_df_pruned_norm = pcac.apply_PCA(n_components=component_count)\n",
    "\n",
    "print('-'*30)\n",
    "print(rep_hist_snapshot_df_pruned_norm.head())\n",
    "print(rep_hist_snapshot_df_pruned_norm.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
