{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schedule TPC-DS 1 Descriptor\n",
    "\n",
    "This notebook contains work pertatining to pattern learning / identification for a database workload schedule. It contains descriptors of the available data through plot visualizations, so as to better understand which resource play a part into reflecting underlying workloads.\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "### Module Installation and Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Cell\n",
    "\n",
    "Tweak parametric changes from this cell to influence outcome of experiment. \n",
    "NB: This experiment demonstrates at time  step = 1 (1 minute in advance). Further down in experiment, other timestep results are also featured and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpcds='TPCDS1'\n",
    "# dtype={'COST':'int64',\n",
    "#        'CARDINALITY':'int64',\n",
    "#        'BYTES':'int64',\n",
    "#        'CPU_COST':'int64',\n",
    "#        'IO_COST':'int64',\n",
    "#        'TEMP_SPACE':'int64',\n",
    "#        'TIME':'int64'}\n",
    "nrows=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from file into Pandas Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7bbf27a939ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Replace original headers with a prettified version of the same column list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mrep_vsql_plan_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrep_vsql_plan_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrep_vsql_plan_headers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mrep_vsql_plan_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrep_vsql_plan_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1034\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m     \"\"\"\n\u001b[0;32m    813\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Root path\n",
    "root_dir = 'C:/Users/gabriel.sammut/University/Data_ICS5200/Schedule/' + tpcds\n",
    "#root_dir = 'D:/Projects/Datagenerated_ICS5200/Schedule/' + tpcds\n",
    "\n",
    "# Open Data\n",
    "rep_vsql_plan_path = root_dir + '/rep_vsql_plan.csv'\n",
    "\n",
    "rep_vsql_plan_df = pd.read_csv(rep_vsql_plan_path,nrows=nrows)\n",
    "\n",
    "def prettify_header(headers):\n",
    "    \"\"\"\n",
    "    Cleans header list from unwated character strings\n",
    "    \"\"\"\n",
    "    header_list = []\n",
    "    [header_list.append(header.replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"\").replace(\",\",\"\")) for header in headers]\n",
    "    return header_list\n",
    "\n",
    "rep_vsql_plan_headers = prettify_header(rep_vsql_plan_df.columns.values)\n",
    "\n",
    "# Replace original headers with a prettified version of the same column list\n",
    "rep_vsql_plan_df = pd.read_csv(rep_vsql_plan_path, names=rep_vsql_plan_headers)\n",
    "\n",
    "rep_vsql_plan_df.drop(rep_vsql_plan_df.index[0],inplace=True)\n",
    "\n",
    "print(\"---------------------------------------------------------------------------------\")\n",
    "print(rep_vsql_plan_df.head())\n",
    "print(\"---------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "\n",
    "All data sources are retrieved from Oracle defined tables/views. These sources have been specifically chosen because they accurately portray a database system under load, across a period of time. Such data sources were polled at regular intervals (60 seconds), and recorded into intermediatery tables for future data mining potential. Each statistic set corresponds to a 'SNAP_ID', which quantifies a particular resource usage at a point in time. 'SNAP_ID' delta equates to 60 seconds. In addition, relavent SQL access plans taken during the workloads execution were also captured.\n",
    "\n",
    "Statistical calculations:\n",
    "* Column Names\n",
    "* Dataframe Row Counts\n",
    "* Mean (were applicable)\n",
    "* Standard Dev (were applicable)\n",
    "* Quartile Percentile\n",
    "* Min / Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-----------------------------------------------------------')\n",
    "print('Dataframe Row Count: VSQL_PLAN - ' + str(len(rep_vsql_plan_df)))\n",
    "print('-----------------------------------------------------------\\n')\n",
    "\n",
    "print('\\n\\nVSQL_PLAN:')\n",
    "print(rep_vsql_plan_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Extraction\n",
    "\n",
    "The above datasets were extracted from the following user defined tables:\n",
    "* REP_VSQL_PLAN\n",
    "\n",
    "Each table corresponds to an Oracle defined table, whose sole function is to offload data from Oracle defined tables (which tend to have a retention period) into a user defined table. Table REP_HIST_SNAPSHOT, REP_HIST_SYSMETRIC_SUMMARY and REP_HIST_SYSSTAT can be joined through the 'SNAP_ID' column. Table REP_VSQL_PLAN can be joined to REP_HIST_SNAPSHOT through the 'SQL_ID' column.\n",
    "\n",
    "\n",
    "For table REP_VSQL_PLAN, the Oracle view (https://docs.oracle.com/database/121/REFRN/GUID-893C1D35-70C8-46F1-A355-D5858233CC7E.htm#REFRN23443) was opted for. This Oracle view mantains a history of past execution plans per child cursor in the workload repository. This view captures information from V$SQL_PLAN and is used with the DBA_HIST_SQLSTAT. The specific query used can be found further below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` sql\n",
    "/*REP_VSQL_PLAN*/\n",
    "select *\n",
    "from v$sql_plan vsp\n",
    "where vsp.sql_id in (\n",
    "\tselect dhsql.sql_id\n",
    "\tfrom dba_hist_sqlstat dhsql,\n",
    "\t     dba_hist_snapshot dhsnap\n",
    "\twhere dhsql.snap_id = dhsnap.snap_id\n",
    "\tand dhsql.dbid = dhsnap.dbid\n",
    "\tand dhsql.instance_number = dhsnap.instance_number\n",
    "\tand dhsnap.snap_id between '544' and '545'\n",
    ")\n",
    "and vsp.timestamp = (\n",
    "  select max(timestamp)\n",
    "  from v$sql_plan\n",
    "  where sql_id = vsp.sql_id\n",
    ")\n",
    "order by sql_id, id;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "\n",
    "The following section visualizes each dataset through a number of pictorial graphs, so as to better visualize the underlying load distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_snapshot_distribution(table=None, column=None, tpc_type=None):\n",
    "    \"\"\"\n",
    "    Plots line graph.\n",
    "    \"\"\"\n",
    "    if column is None or tpc_type is None:\n",
    "        raise ValueError('Parameters were declared incorrectly!')\n",
    "    tpc_type = tpc_type.upper()\n",
    "    table=table.lower()\n",
    "    #\n",
    "    if table == 'rep_hist_snapshot':\n",
    "        df = rep_hist_snapshot_df\n",
    "    elif table == 'rep_hist_sysmetric_summary':\n",
    "        df = rep_hist_sysmetric_summary_df\n",
    "    elif table == 'rep_hist_sysstat':\n",
    "        df = rep_hist_sysstat_df\n",
    "    else:\n",
    "        raise ValueError('Table Name not supported!')\n",
    "    #\n",
    "    # Convert to float\n",
    "    df['SNAP_ID'] = df['SNAP_ID'].astype(float)\n",
    "    df[column]=df[column].astype(float)\n",
    "    start_snap, end_snap = int(df['SNAP_ID'].min()), int(df['SNAP_ID'].max())\n",
    "    #\n",
    "    # Sort by order of execute time\n",
    "    df = df.sort_values(by=['SNAP_ID'])\n",
    "    #\n",
    "    # Group by SNAP_ID\n",
    "    df = df.groupby(['SNAP_ID'])[column].sum()\n",
    "    #\n",
    "    fig, ax = plt.subplots()\n",
    "    df.plot(kind='line', x='SNAP_ID', y=column, ax=ax)\n",
    "    plt.ylabel(column)\n",
    "    plt.xlabel('SNAP ID')\n",
    "    plt.title(tpc_type + ' ' + str(column) + \" between \" + str(start_snap) + \" - \" + str(end_snap))\n",
    "    plt.rcParams['figure.figsize'] = [20, 15]\n",
    "    plt.show()\n",
    "#\n",
    "def plot_snapshot_ratios(table=None, column=None, tpc_type=None):\n",
    "    \"\"\"\n",
    "    Plots Pie Chart\n",
    "    \"\"\"\n",
    "    if column is None or tpc_type is None:\n",
    "        raise ValueError('Parameters were declared incorrectly!')\n",
    "    tpc_type = tpc_type.upper()\n",
    "    table=table.lower()\n",
    "    #\n",
    "    if table == 'rep_hist_snapshot':\n",
    "        df = rep_hist_snapshot_df\n",
    "    elif table == 'rep_hist_sysmetric_summary':\n",
    "        df = rep_hist_sysmetric_summary_df\n",
    "    elif table == 'rep_hist_sysstat':\n",
    "        df = rep_hist_sysstat_df\n",
    "    elif table == 'rep_vsql_plan':\n",
    "        df = rep_vsql_plan_df\n",
    "    else:\n",
    "        raise ValueError('Table Name not supported!')\n",
    "    #\n",
    "    df = df.groupby([column])[column].count()\n",
    "    #\n",
    "    # Sort by operation counts\n",
    "    series = pd.Series(df.values, index=df.index, name='series')\n",
    "    series.plot.pie(figsize=(6, 6))\n",
    "    #plt.xticks([])\n",
    "    plt.ylabel(column)\n",
    "    plt.title(tpc_type + ' ' + str(column) + ' Ratio')\n",
    "    plt.rcParams['figure.figsize'] = [40, 30]\n",
    "    plt.legend(bbox_to_anchor=(0.95,0.95))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View V$SQL_PLAN\n",
    "\n",
    "Plotting metrics from table REP_VSQL_PLAN (v$sql_plan).\n",
    "\n",
    "``` sql\n",
    "/*REP_VSQL_PLAN*/\n",
    "select *\n",
    "from v$sql_plan vsp\n",
    "where vsp.sql_id in (\n",
    "\tselect dhsql.sql_id\n",
    "\tfrom dba_hist_sqlstat dhsql,\n",
    "\t     dba_hist_snapshot dhsnap\n",
    "\twhere dhsql.snap_id = dhsnap.snap_id\n",
    "\tand dhsql.dbid = dhsnap.dbid\n",
    "\tand dhsql.instance_number = dhsnap.instance_number\n",
    "\tand dhsnap.snap_id between '544' and '545'\n",
    ")\n",
    "and vsp.timestamp = (\n",
    "  select max(timestamp)\n",
    "  from v$sql_plan\n",
    "  where sql_id = vsp.sql_id\n",
    ")\n",
    "order by sql_id, id;\n",
    "```\n",
    "\n",
    "### SQL_ID\n",
    "\n",
    "SQL identifier of the parent cursor in the library cache\n",
    "\n",
    "This field uniquely identifies an sql statement inside of a database environment. In the case of view v$sql_plan, a number of sql operations pertain to a single SQL_ID (grouped by 'TIME_STAMP'). These denote what and how many instruction operations were opted for by the optimizer for a single 'SQL_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_snapshot_ratios(table=\"rep_vsql_plan\", column=\"SQL_ID\", tpc_type=tpcds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operation\n",
    "\n",
    "Name of the internal operation performed in this step (for example, TABLE ACCESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_snapshot_ratios(table=\"rep_vsql_plan\", column=\"OPERATION\", tpc_type=tpcds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options\n",
    "\n",
    "A variation on the operation described in the OPERATION column (for example, FULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_snapshot_ratios(table=\"rep_vsql_plan\", column=\"OPTIONS\", tpc_type=tpcds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Owner\n",
    "\n",
    "Name of the user who owns the schema containing the table or index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_snapshot_ratios(table=\"rep_vsql_plan\", column=\"OBJECT_OWNER\", tpc_type=tpcds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPC-DS Query Variants\n",
    "\n",
    "Amongst the established workload, a number of TPC-DS query variants are generated at random during a schedule's execution. Variants are copies of each respective query number, with Oracle Optimizer hints injected in respective SQLs so as to influence the access plan opted for at runtime. This achieves the goal of creating outliers within the established schedule.\n",
    "\n",
    "The following queries were used to establish SQL variants:\n",
    "* 5\n",
    "* 10\n",
    "* 14\n",
    "* 18\n",
    "* 22\n",
    "* 27\n",
    "* 35\n",
    "* 36\n",
    "* 51\n",
    "* 67\n",
    "* 70\n",
    "* 77\n",
    "* 80\n",
    "* 86\n",
    "\n",
    "Of noticable mention for hints which were used, includes:\n",
    "* FULL optimizer hint - https://docs.oracle.com/cd/E11882_01/server.112/e41084/sql_elements006.htm#SQLRF50401\n",
    "* USE_NL optimizer hint - https://docs.oracle.com/cd/E11882_01/server.112/e41084/sql_elements006.htm#BABDDFHC\n",
    "\n",
    "In addition, variants were modified to retrieve a 10,000 rows (instead of the standard 100).\n",
    "\n",
    "### Query 5 \t  \t  \n",
    "``` sql\n",
    "with ssr as\n",
    " (select /*+full(salesreturns)*/ s_store_id,\n",
    "        sum(sales_price) as sales,\n",
    "        sum(profit) as profit,\n",
    "        sum(return_amt) as returns,\n",
    "        sum(net_loss) as profit_loss\n",
    " from\n",
    "  ( select  ss_store_sk as store_sk,\n",
    "            ss_sold_date_sk  as date_sk,\n",
    "            ss_ext_sales_price as sales_price,\n",
    "            ss_net_profit as profit,\n",
    "            cast(0 as decimal(7,2)) as return_amt,\n",
    "            cast(0 as decimal(7,2)) as net_loss\n",
    "    from store_sales\n",
    "    union all\n",
    "    select sr_store_sk as store_sk,\n",
    "           sr_returned_date_sk as date_sk,\n",
    "           cast(0 as decimal(7,2)) as sales_price,\n",
    "           cast(0 as decimal(7,2)) as profit,\n",
    "           sr_return_amt as return_amt,\n",
    "           sr_net_loss as net_loss\n",
    "    from store_returns\n",
    "   ) salesreturns,\n",
    "     date_dim,\n",
    "     store\n",
    " where date_sk = d_date_sk\n",
    "       and d_date between to_char(to_date('2000-08-19','yyyy/mm/dd'),'yyyy-mm-dd')\n",
    "                  and (to_char(to_date('2000-08-19','yyyy/mm/dd') +  14,'yyyy-mm-dd'))\n",
    "       and store_sk = s_store_sk\n",
    " group by s_store_id)\n",
    " ,\n",
    " csr as\n",
    " (select cp_catalog_page_id,\n",
    "        sum(sales_price) as sales,\n",
    "        sum(profit) as profit,\n",
    "        sum(return_amt) as returns,\n",
    "        sum(net_loss) as profit_loss\n",
    " from\n",
    "  ( select  cs_catalog_page_sk as page_sk,\n",
    "            cs_sold_date_sk  as date_sk,\n",
    "            cs_ext_sales_price as sales_price,\n",
    "            cs_net_profit as profit,\n",
    "            cast(0 as decimal(7,2)) as return_amt,\n",
    "            cast(0 as decimal(7,2)) as net_loss\n",
    "    from catalog_sales\n",
    "    union all\n",
    "    select cr_catalog_page_sk as page_sk,\n",
    "           cr_returned_date_sk as date_sk,\n",
    "           cast(0 as decimal(7,2)) as sales_price,\n",
    "           cast(0 as decimal(7,2)) as profit,\n",
    "           cr_return_amount as return_amt,\n",
    "           cr_net_loss as net_loss\n",
    "    from catalog_returns\n",
    "   ) salesreturns,\n",
    "     date_dim,\n",
    "     catalog_page\n",
    " where date_sk = d_date_sk\n",
    "       and d_date between to_char(to_date('2000-08-19','yyyy/mm/dd'),'yyyy-mm-dd')\n",
    "                  and (to_char(to_date('2000-08-19','yyyy/mm/dd') +  14,'yyyy-mm-dd'))\n",
    "       and page_sk = cp_catalog_page_sk\n",
    " group by cp_catalog_page_id)\n",
    " ,\n",
    " wsr as\n",
    " (select web_site_id,\n",
    "        sum(sales_price) as sales,\n",
    "        sum(profit) as profit,\n",
    "        sum(return_amt) as returns,\n",
    "        sum(net_loss) as profit_loss\n",
    " from\n",
    "  ( select  ws_web_site_sk as wsr_web_site_sk,\n",
    "            ws_sold_date_sk  as date_sk,\n",
    "            ws_ext_sales_price as sales_price,\n",
    "            ws_net_profit as profit,\n",
    "            cast(0 as decimal(7,2)) as return_amt,\n",
    "            cast(0 as decimal(7,2)) as net_loss\n",
    "    from web_sales\n",
    "    union all\n",
    "    select ws_web_site_sk as wsr_web_site_sk,\n",
    "           wr_returned_date_sk as date_sk,\n",
    "           cast(0 as decimal(7,2)) as sales_price,\n",
    "           cast(0 as decimal(7,2)) as profit,\n",
    "           wr_return_amt as return_amt,\n",
    "           wr_net_loss as net_loss\n",
    "    from web_returns left outer join web_sales on\n",
    "         ( wr_item_sk = ws_item_sk\n",
    "           and wr_order_number = ws_order_number)\n",
    "   ) salesreturns,\n",
    "     date_dim,\n",
    "     web_site\n",
    " where date_sk = d_date_sk\n",
    "       and d_date between to_char(to_date('2000-08-19','yyyy/mm/dd'),'yyyy-mm-dd')\n",
    "                  and (to_char(to_date('2000-08-19','yyyy/mm/dd') +  14,'yyyy-mm-dd'))\n",
    "       and wsr_web_site_sk = web_site_sk\n",
    " group by web_site_id)\n",
    " select * from ( select  channel\n",
    "        , id\n",
    "        , sum(sales) as sales\n",
    "        , sum(returns) as returns\n",
    "        , sum(profit) as profit\n",
    " from \n",
    " (select 'store channel' as channel\n",
    "        , 'store' || s_store_id as id\n",
    "        , sales\n",
    "        , returns\n",
    "        , (profit - profit_loss) as profit\n",
    " from   ssr\n",
    " union all\n",
    " select 'catalog channel' as channel\n",
    "        , 'catalog_page' || cp_catalog_page_id as id\n",
    "        , sales\n",
    "        , returns\n",
    "        , (profit - profit_loss) as profit\n",
    " from  csr\n",
    " union all\n",
    " select 'web channel' as channel\n",
    "        , 'web_site' || web_site_id as id\n",
    "        , sales\n",
    "        , returns\n",
    "        , (profit - profit_loss) as profit\n",
    " from   wsr\n",
    " ) x\n",
    " group by rollup (channel, id)\n",
    " order by channel\n",
    "         ,id\n",
    "  ) where rownum <= 10000;\n",
    "```\n",
    "\n",
    "### Query 10\n",
    "``` sql\n",
    "select * from (select\n",
    "  cd_gender,\n",
    "  cd_marital_status,\n",
    "  cd_education_status,\n",
    "  count(*) cnt1,\n",
    "  cd_purchase_estimate,\n",
    "  count(*) cnt2,\n",
    "  cd_credit_rating,\n",
    "  count(*) cnt3,\n",
    "  cd_dep_count,\n",
    "  count(*) cnt4,\n",
    "  cd_dep_employed_count,\n",
    "  count(*) cnt5,\n",
    "  cd_dep_college_count,\n",
    "  count(*) cnt6\n",
    " from\n",
    "  customer c,customer_address ca,customer_demographics\n",
    " where\n",
    "  c.c_current_addr_sk = ca.ca_address_sk and\n",
    "  ca_county in ('Fairfield County','Campbell County','Washtenaw County','Escambia County','Cleburne County') and\n",
    "  cd_demo_sk = c.c_current_cdemo_sk and\n",
    "  exists (select /*+full(date_dim) full(STORE_SALES)*/ *\n",
    "          from store_sales,date_dim\n",
    "          where c.c_customer_sk = ss_customer_sk and\n",
    "                ss_sold_date_sk = d_date_sk and\n",
    "                d_year = 2001 and\n",
    "                d_moy between 3 and 3+3) and\n",
    "   (exists (select *\n",
    "            from web_sales,date_dim\n",
    "            where c.c_customer_sk = ws_bill_customer_sk and\n",
    "                  ws_sold_date_sk = d_date_sk and\n",
    "                  d_year = 2001 and\n",
    "                  d_moy between 3 ANd 3+3) or\n",
    "    exists (select /*+full(catalog_sales)*/ *\n",
    "            from catalog_sales,date_dim\n",
    "            where c.c_customer_sk = cs_ship_customer_sk and\n",
    "                  cs_sold_date_sk = d_date_sk and\n",
    "                  d_year = 2001 and\n",
    "                  d_moy between 3 and 3+3))\n",
    " group by cd_gender,\n",
    "          cd_marital_status,\n",
    "          cd_education_status,\n",
    "          cd_purchase_estimate,\n",
    "          cd_credit_rating,\n",
    "          cd_dep_count,\n",
    "          cd_dep_employed_count,\n",
    "          cd_dep_college_count\n",
    " order by cd_gender,\n",
    "          cd_marital_status,\n",
    "          cd_education_status,\n",
    "          cd_purchase_estimate,\n",
    "          cd_credit_rating,\n",
    "          cd_dep_count,\n",
    "          cd_dep_employed_count,\n",
    "          cd_dep_college_count\n",
    " ) where rownum <= 10000;\n",
    " ```\n",
    "\n",
    "### Query 14\n",
    "``` sql\n",
    "select * from (select  /*+full(catalog_sales)*/ i_item_id,\n",
    "        ca_country,\n",
    "        ca_state,\n",
    "        ca_county,\n",
    "        avg( cast(cs_quantity as decimal(12,2))) agg1,\n",
    "        avg( cast(cs_list_price as decimal(12,2))) agg2,\n",
    "        avg( cast(cs_coupon_amt as decimal(12,2))) agg3,\n",
    "        avg( cast(cs_sales_price as decimal(12,2))) agg4,\n",
    "        avg( cast(cs_net_profit as decimal(12,2))) agg5,\n",
    "        avg( cast(c_birth_year as decimal(12,2))) agg6,\n",
    "        avg( cast(cd1.cd_dep_count as decimal(12,2))) agg7\n",
    " from catalog_sales, customer_demographics cd1,\n",
    "      customer_demographics cd2, customer, customer_address, date_dim, item\n",
    " where cs_sold_date_sk = d_date_sk and\n",
    "       cs_item_sk = i_item_sk and\n",
    "       cs_bill_cdemo_sk = cd1.cd_demo_sk and\n",
    "       cs_bill_customer_sk = c_customer_sk and\n",
    "       cd1.cd_gender = 'F' and\n",
    "       cd1.cd_education_status = 'Primary' and\n",
    "       c_current_cdemo_sk = cd2.cd_demo_sk and\n",
    "       c_current_addr_sk = ca_address_sk and\n",
    "       c_birth_month in (1,3,7,11,10,4) and\n",
    "       d_year = 2001 and\n",
    "       ca_state in ('AL','MO','TN'\n",
    "                   ,'GA','MT','IN','CA')\n",
    " group by rollup (i_item_id, ca_country, ca_state, ca_county)\n",
    " order by ca_country,\n",
    "        ca_state,\n",
    "        ca_county,\n",
    "\ti_item_id\n",
    "  ) where rownum <= 10000;\n",
    "```\n",
    "\n",
    "### Query 18\n",
    "``` sql\n",
    "select * from (select  /*+full(catalog_sales)*/ i_item_id,\n",
    "        ca_country,\n",
    "        ca_state,\n",
    "        ca_county,\n",
    "        avg( cast(cs_quantity as decimal(12,2))) agg1,\n",
    "        avg( cast(cs_list_price as decimal(12,2))) agg2,\n",
    "        avg( cast(cs_coupon_amt as decimal(12,2))) agg3,\n",
    "        avg( cast(cs_sales_price as decimal(12,2))) agg4,\n",
    "        avg( cast(cs_net_profit as decimal(12,2))) agg5,\n",
    "        avg( cast(c_birth_year as decimal(12,2))) agg6,\n",
    "        avg( cast(cd1.cd_dep_count as decimal(12,2))) agg7\n",
    " from catalog_sales, customer_demographics cd1,\n",
    "      customer_demographics cd2, customer, customer_address, date_dim, item\n",
    " where cs_sold_date_sk = d_date_sk and\n",
    "       cs_item_sk = i_item_sk and\n",
    "       cs_bill_cdemo_sk = cd1.cd_demo_sk and\n",
    "       cs_bill_customer_sk = c_customer_sk and\n",
    "       cd1.cd_gender = 'F' and\n",
    "       cd1.cd_education_status = 'Primary' and\n",
    "       c_current_cdemo_sk = cd2.cd_demo_sk and\n",
    "       c_current_addr_sk = ca_address_sk and\n",
    "       c_birth_month in (1,3,7,11,10,4) and\n",
    "       d_year = 2001 and\n",
    "       ca_state in ('AL','MO','TN'\n",
    "                   ,'GA','MT','IN','CA')\n",
    " group by rollup (i_item_id, ca_country, ca_state, ca_county)\n",
    " order by ca_country,\n",
    "        ca_state,\n",
    "        ca_county,\n",
    "\ti_item_id\n",
    "  ) where rownum <= 10000;\n",
    "```\n",
    "\n",
    "### Query 22\n",
    "```sql\n",
    "select * from (select  /*+use_nl(date_dim,item)*/ i_product_name\n",
    "             ,i_brand\n",
    "             ,i_class\n",
    "             ,i_category\n",
    "             ,avg(inv_quantity_on_hand) qoh\n",
    "       from inventory\n",
    "           ,date_dim\n",
    "           ,item\n",
    "       where inv_date_sk=d_date_sk\n",
    "              and inv_item_sk=i_item_sk\n",
    "              and d_month_seq between 1200 and 1200 + 11\n",
    "       group by rollup(i_product_name\n",
    "                       ,i_brand\n",
    "                       ,i_class\n",
    "                       ,i_category)\n",
    "order by qoh, i_product_name, i_brand, i_class, i_category\n",
    " ) where rownum <= 10000;\n",
    "```\n",
    "\n",
    "### Query 27\n",
    "``` sql\n",
    "select * from (select /*+full(store_sales)*/ i_item_id,\n",
    "        s_state, grouping(s_state) g_state,\n",
    "        avg(ss_quantity) agg1,\n",
    "        avg(ss_list_price) agg2,\n",
    "        avg(ss_coupon_amt) agg3,\n",
    "        avg(ss_sales_price) agg4\n",
    " from store_sales, customer_demographics, date_dim, store, item\n",
    " where ss_sold_date_sk = d_date_sk and\n",
    "       ss_item_sk = i_item_sk and\n",
    "       ss_store_sk = s_store_sk and\n",
    "       ss_cdemo_sk = cd_demo_sk and\n",
    "       cd_gender = 'M' and\n",
    "       cd_marital_status = 'W' and\n",
    "       cd_education_status = 'Secondary' and\n",
    "       d_year = 1999 and\n",
    "       s_state in ('TN','TN', 'TN', 'TN', 'TN', 'TN')\n",
    " group by rollup (i_item_id, s_state)\n",
    " order by i_item_id\n",
    "         ,s_state\n",
    "  ) where rownum <= 10000;\n",
    "```\n",
    "\n",
    "### Query 35\n",
    "``` sql\n",
    "select * from (select\n",
    "  ca_state,\n",
    "  cd_gender,\n",
    "  cd_marital_status,\n",
    "  cd_dep_count,\n",
    "  count(*) cnt1,\n",
    "  avg(cd_dep_count),\n",
    "  stddev_samp(cd_dep_count),\n",
    "  sum(cd_dep_count),\n",
    "  cd_dep_employed_count,\n",
    "  count(*) cnt2,\n",
    "  avg(cd_dep_employed_count),\n",
    "  stddev_samp(cd_dep_employed_count),\n",
    "  sum(cd_dep_employed_count),\n",
    "  cd_dep_college_count,\n",
    "  count(*) cnt3,\n",
    "  avg(cd_dep_college_count),\n",
    "  stddev_samp(cd_dep_college_count),\n",
    "  sum(cd_dep_college_count)\n",
    " from\n",
    "  customer c,customer_address ca,customer_demographics\n",
    " where\n",
    "  c.c_current_addr_sk = ca.ca_address_sk and\n",
    "  cd_demo_sk = c.c_current_cdemo_sk and\n",
    "  exists (select *\n",
    "          from store_sales,date_dim\n",
    "          where c.c_customer_sk = ss_customer_sk and\n",
    "                ss_sold_date_sk = d_date_sk and\n",
    "                d_year = 1999 and\n",
    "                d_qoy < 4) and\n",
    "   (exists (select *\n",
    "            from web_sales,date_dim\n",
    "            where c.c_customer_sk = ws_bill_customer_sk and\n",
    "                  ws_sold_date_sk = d_date_sk and\n",
    "                  d_year = 1999 and\n",
    "                  d_qoy < 4) or\n",
    "    exists (select /*+full(CATALOG_SALES)*/ *\n",
    "            from catalog_sales,date_dim\n",
    "            where c.c_customer_sk = cs_ship_customer_sk and\n",
    "                  cs_sold_date_sk = d_date_sk and\n",
    "                  d_year = 1999 and\n",
    "                  d_qoy < 4))\n",
    " group by ca_state,\n",
    "          cd_gender,\n",
    "          cd_marital_status,\n",
    "          cd_dep_count,\n",
    "          cd_dep_employed_count,\n",
    "          cd_dep_college_count\n",
    " order by ca_state,\n",
    "          cd_gender,\n",
    "          cd_marital_status,\n",
    "          cd_dep_count,\n",
    "          cd_dep_employed_count,\n",
    "          cd_dep_college_count\n",
    "  ) where rownum <= 10000;\n",
    "```\n",
    "\n",
    "### Query 36\n",
    "``` sql\n",
    "select * from (select /*+full(STORE_SALES)*/\n",
    "    sum(ss_net_profit)/sum(ss_ext_sales_price) as gross_margin\n",
    "   ,i_category\n",
    "   ,i_class\n",
    "   ,grouping(i_category)+grouping(i_class) as lochierarchy\n",
    "   ,rank() over (\n",
    " \tpartition by grouping(i_category)+grouping(i_class),\n",
    " \tcase when grouping(i_class) = 0 then i_category end\n",
    " \torder by sum(ss_net_profit)/sum(ss_ext_sales_price) asc) as rank_within_parent\n",
    " from\n",
    "    store_sales\n",
    "   ,date_dim       d1\n",
    "   ,item\n",
    "   ,store\n",
    " where\n",
    "    d1.d_year = 2000\n",
    " and d1.d_date_sk = ss_sold_date_sk\n",
    " and i_item_sk  = ss_item_sk\n",
    " and s_store_sk  = ss_store_sk\n",
    " and s_state in ('TN','TN','TN','TN',\n",
    "                 'TN','TN','TN','TN')\n",
    " group by rollup(i_category,i_class)\n",
    " order by\n",
    "   lochierarchy desc\n",
    "  ,case when lochierarchy = 0 then i_category end\n",
    "  ,rank_within_parent\n",
    "   ) where rownum <= 10000;\n",
    "```\n",
    "\n",
    "### Query 51\n",
    "``` sql\n",
    "WITH web_v1 as (\n",
    "select\n",
    "  ws_item_sk item_sk, d_date,\n",
    "  sum(sum(ws_sales_price))\n",
    "      over (partition by ws_item_sk order by d_date rows between unbounded preceding and current row) cume_sales\n",
    "from web_sales\n",
    "    ,date_dim\n",
    "where ws_sold_date_sk=d_date_sk\n",
    "  and d_month_seq between 1208 and 1208+11\n",
    "  and ws_item_sk is not NULL\n",
    "group by ws_item_sk, d_date),\n",
    "store_v1 as (\n",
    "select /*+full(STORE_SALES)*/\n",
    "  ss_item_sk item_sk, d_date,\n",
    "  sum(sum(ss_sales_price))\n",
    "      over (partition by ss_item_sk order by d_date rows between unbounded preceding and current row) cume_sales\n",
    "from store_sales\n",
    "    ,date_dim\n",
    "where ss_sold_date_sk=d_date_sk\n",
    "  and d_month_seq between 1208 and 1208+11\n",
    "  and ss_item_sk is not NULL\n",
    "group by ss_item_sk, d_date)\n",
    "select * from ( select  *\n",
    "from (select item_sk\n",
    "     ,d_date\n",
    "     ,web_sales\n",
    "     ,store_sales\n",
    "     ,max(web_sales)\n",
    "         over (partition by item_sk order by d_date rows between unbounded preceding and current row) web_cumulative\n",
    "     ,max(store_sales)\n",
    "         over (partition by item_sk order by d_date rows between unbounded preceding and current row) store_cumulative\n",
    "     from (select case when web.item_sk is not null then web.item_sk else store.item_sk end item_sk\n",
    "                 ,case when web.d_date is not null then web.d_date else store.d_date end d_date\n",
    "                 ,web.cume_sales web_sales\n",
    "                 ,store.cume_sales store_sales\n",
    "           from web_v1 web full outer join store_v1 store on (web.item_sk = store.item_sk\n",
    "                                                          and web.d_date = store.d_date)\n",
    "          )x )y\n",
    "where web_cumulative > store_cumulative\n",
    "order by item_sk\n",
    "        ,d_date\n",
    " ) where rownum <= 10000;\n",
    "```\n",
    "\n",
    "### Query 67\n",
    "``` sql\n",
    "select * from (select  *\n",
    "from (select i_category\n",
    "            ,i_class\n",
    "            ,i_brand\n",
    "            ,i_product_name\n",
    "            ,d_year\n",
    "            ,d_qoy\n",
    "            ,d_moy\n",
    "            ,s_store_id\n",
    "            ,sumsales\n",
    "            ,rank() over (partition by i_category order by sumsales desc) rk\n",
    "      from (select /*+full(store_sales)*/ i_category\n",
    "                  ,i_class\n",
    "                  ,i_brand\n",
    "                  ,i_product_name\n",
    "                  ,d_year\n",
    "                  ,d_qoy\n",
    "                  ,d_moy\n",
    "                  ,s_store_id\n",
    "                  ,sum(coalesce(ss_sales_price*ss_quantity,0)) sumsales\n",
    "            from store_sales\n",
    "                ,date_dim\n",
    "                ,store\n",
    "                ,item\n",
    "       where  ss_sold_date_sk=d_date_sk\n",
    "          and ss_item_sk=i_item_sk\n",
    "          and ss_store_sk = s_store_sk\n",
    "          and d_month_seq between 1219 and 1219+11\n",
    "       group by  rollup(i_category, i_class, i_brand, i_product_name, d_year, d_qoy, d_moy,s_store_id))dw1) dw2\n",
    "where rk <= 100\n",
    "order by i_category\n",
    "        ,i_class\n",
    "        ,i_brand\n",
    "        ,i_product_name\n",
    "        ,d_year\n",
    "        ,d_qoy\n",
    "        ,d_moy\n",
    "        ,s_store_id\n",
    "        ,sumsales\n",
    "        ,rk\n",
    " ) where rownum <= 10000;\n",
    "```\n",
    "\n",
    "### Query 70\n",
    "``` sql\n",
    "select  * from (select /*+full(STORE_SALES)*/\n",
    "    sum(ss_net_profit) as total_sum\n",
    "   ,s_state\n",
    "   ,s_county\n",
    "   ,grouping(s_state)+grouping(s_county) as lochierarchy\n",
    "   ,rank() over (\n",
    " \tpartition by grouping(s_state)+grouping(s_county),\n",
    " \tcase when grouping(s_county) = 0 then s_state end\n",
    " \torder by sum(ss_net_profit) desc) as rank_within_parent\n",
    " from\n",
    "    store_sales\n",
    "   ,date_dim       d1\n",
    "   ,store\n",
    " where\n",
    "    d1.d_month_seq between 1195 and 1195+11\n",
    " and d1.d_date_sk = ss_sold_date_sk\n",
    " and s_store_sk  = ss_store_sk\n",
    " and s_state in\n",
    "             ( select s_state\n",
    "               from  (select s_state as s_state,\n",
    " \t\t\t    rank() over ( partition by s_state order by sum(ss_net_profit) desc) as ranking\n",
    "                      from   store_sales, store, date_dim\n",
    "                      where  d_month_seq between 1195 and 1195+11\n",
    " \t\t\t    and d_date_sk = ss_sold_date_sk\n",
    " \t\t\t    and s_store_sk  = ss_store_sk\n",
    "                      group by s_state\n",
    "                     ) tmp1\n",
    "               where ranking <= 5\n",
    "             )\n",
    " group by rollup(s_state,s_county)\n",
    " order by\n",
    "   lochierarchy desc\n",
    "  ,case when lochierarchy = 0 then s_state end\n",
    "  ,rank_within_parent\n",
    "  ) where rownum <= 10000;\n",
    "```\n",
    "\n",
    "### Query 77\n",
    "``` sql\n",
    "with ss as\n",
    " (select s_store_sk,\n",
    "         sum(ss_ext_sales_price) as sales,\n",
    "         sum(ss_net_profit) as profit\n",
    " from store_sales,\n",
    "      date_dim,\n",
    "      store\n",
    " where ss_sold_date_sk = d_date_sk\n",
    "       and d_date between to_char(to_date('2000-08-16','yyyy/mm/dd'),'yyyy-mm-dd')\n",
    "                  and (to_char(to_date('2000-08-16','yyyy/mm/dd') +  30,'yyyy-mm-dd'))\n",
    "       and ss_store_sk = s_store_sk\n",
    " group by s_store_sk)\n",
    " ,\n",
    " sr as\n",
    " (select /*+full(STORE_RETURNS)*/ s_store_sk,\n",
    "         sum(sr_return_amt) as returns,\n",
    "         sum(sr_net_loss) as profit_loss\n",
    " from store_returns,\n",
    "      date_dim,\n",
    "      store\n",
    " where sr_returned_date_sk = d_date_sk\n",
    "       and d_date between to_char(to_date('2000-08-16','yyyy/mm/dd'),'yyyy-mm-dd')\n",
    "                  and (to_char(to_date('2000-08-16','yyyy/mm/dd') +  30,'yyyy-mm-dd'))\n",
    "       and sr_store_sk = s_store_sk\n",
    " group by s_store_sk),\n",
    " cs as\n",
    " (select /*+full(CATALOG_SALES)*/ cs_call_center_sk,\n",
    "        sum(cs_ext_sales_price) as sales,\n",
    "        sum(cs_net_profit) as profit\n",
    " from catalog_sales,\n",
    "      date_dim\n",
    " where cs_sold_date_sk = d_date_sk\n",
    "       and d_date between to_char(to_date('2000-08-16','yyyy/mm/dd'),'yyyy-mm-dd')\n",
    "                  and (to_char(to_date('2000-08-16','yyyy/mm/dd') +  30,'yyyy-mm-dd'))\n",
    " group by cs_call_center_sk\n",
    " ),\n",
    " cr as\n",
    " (select cr_call_center_sk,\n",
    "         sum(cr_return_amount) as returns,\n",
    "         sum(cr_net_loss) as profit_loss\n",
    " from catalog_returns,\n",
    "      date_dim\n",
    " where cr_returned_date_sk = d_date_sk\n",
    "       and d_date between to_char(to_date('2000-08-16','yyyy/mm/dd'),'yyyy-mm-dd')\n",
    "                  and (to_char(to_date('2000-08-16','yyyy/mm/dd') +  30,'yyyy-mm-dd'))\n",
    " group by cr_call_center_sk\n",
    " ),\n",
    " ws as\n",
    " ( select wp_web_page_sk,\n",
    "        sum(ws_ext_sales_price) as sales,\n",
    "        sum(ws_net_profit) as profit\n",
    " from web_sales,\n",
    "      date_dim,\n",
    "      web_page\n",
    " where ws_sold_date_sk = d_date_sk\n",
    "       and d_date between to_char(to_date('2000-08-16','yyyy-mm-dd'),'yyyy-mm-dd')\n",
    "                  and (to_char(to_date('2000-08-16','yyyy-mm-dd') +  30,'yyyy-mm-dd'))\n",
    "       and ws_web_page_sk = wp_web_page_sk\n",
    " group by wp_web_page_sk),\n",
    " wr as\n",
    " (select wp_web_page_sk,\n",
    "        sum(wr_return_amt) as returns,\n",
    "        sum(wr_net_loss) as profit_loss\n",
    " from web_returns,\n",
    "      date_dim,\n",
    "      web_page\n",
    " where wr_returned_date_sk = d_date_sk\n",
    "       and d_date between to_char(to_date('2000-08-16','yyyy/mm/dd'),'yyyy-mm-dd')\n",
    "                  and (to_char(to_date('2000-08-16','yyyy/mm/dd') +  30,'yyyy-mm-dd'))\n",
    "       and wr_web_page_sk = wp_web_page_sk\n",
    " group by wp_web_page_sk)\n",
    " select * from ( select  channel\n",
    "        , id\n",
    "        , sum(sales) as sales\n",
    "        , sum(returns) as returns\n",
    "        , sum(profit) as profit\n",
    " from\n",
    " (select 'store channel' as channel\n",
    "        , ss.s_store_sk as id\n",
    "        , sales\n",
    "        , coalesce(returns, 0) as returns\n",
    "        , (profit - coalesce(profit_loss,0)) as profit\n",
    " from   ss left join sr\n",
    "        on  ss.s_store_sk = sr.s_store_sk\n",
    " union all\n",
    " select 'catalog channel' as channel\n",
    "        , cs_call_center_sk as id\n",
    "        , sales\n",
    "        , returns\n",
    "        , (profit - profit_loss) as profit\n",
    " from  cs\n",
    "       , cr\n",
    " union all\n",
    " select 'web channel' as channel\n",
    "        , ws.wp_web_page_sk as id\n",
    "        , sales\n",
    "        , coalesce(returns, 0) returns\n",
    "        , (profit - coalesce(profit_loss,0)) as profit\n",
    " from   ws left join wr\n",
    "        on  ws.wp_web_page_sk = wr.wp_web_page_sk\n",
    " ) x\n",
    " group by rollup (channel, id)\n",
    " order by channel\n",
    "         ,id\n",
    "  ) where rownum <= 10000;\n",
    "```\n",
    "\n",
    "### Query 80\n",
    "``` sql\n",
    "with ssr as\n",
    " (select  /*+use_nl(date_dim,store)*/\n",
    "          s_store_id as store_id,\n",
    "          sum(ss_ext_sales_price) as sales,\n",
    "          sum(coalesce(sr_return_amt, 0)) as returns,\n",
    "          sum(ss_net_profit - coalesce(sr_net_loss, 0)) as profit\n",
    "  from store_sales left outer join store_returns on\n",
    "         (ss_item_sk = sr_item_sk and ss_ticket_number = sr_ticket_number),\n",
    "     date_dim,\n",
    "     store,\n",
    "     item,\n",
    "     promotion\n",
    " where ss_sold_date_sk = d_date_sk\n",
    "       and d_date between to_char(to_date('2000-08-20','yyyy/mm/dd'),'yyyy-mm-dd')\n",
    "                  and (to_char(to_date('2000-08-20','yyyy/mm/dd') +  30,'yyyy-mm-dd'))\n",
    "       and ss_store_sk = s_store_sk\n",
    "       and ss_item_sk = i_item_sk\n",
    "       and i_current_price > 50\n",
    "       and ss_promo_sk = p_promo_sk\n",
    "       and p_channel_tv = 'N'\n",
    " group by s_store_id)\n",
    " ,\n",
    " csr as\n",
    " (select  /*+use_nl(date_dim,store)*/\n",
    "          cp_catalog_page_id as catalog_page_id,\n",
    "          sum(cs_ext_sales_price) as sales,\n",
    "          sum(coalesce(cr_return_amount, 0)) as returns,\n",
    "          sum(cs_net_profit - coalesce(cr_net_loss, 0)) as profit\n",
    "  from catalog_sales left outer join catalog_returns on\n",
    "         (cs_item_sk = cr_item_sk and cs_order_number = cr_order_number),\n",
    "     date_dim,\n",
    "     catalog_page,\n",
    "     item,\n",
    "     promotion\n",
    " where cs_sold_date_sk = d_date_sk\n",
    "       and d_date between to_char(to_date('2000-08-20','yyyy/mm/dd'),'yyyy-mm-dd')\n",
    "                  and (to_char(to_date('2000-08-20','yyyy/mm/dd') +  30,'yyyy-mm-dd'))\n",
    "        and cs_catalog_page_sk = cp_catalog_page_sk\n",
    "       and cs_item_sk = i_item_sk\n",
    "       and i_current_price > 50\n",
    "       and cs_promo_sk = p_promo_sk\n",
    "       and p_channel_tv = 'N'\n",
    "group by cp_catalog_page_id)\n",
    " ,\n",
    " wsr as\n",
    " (select /*+use_nl(date_dim,store)*/\n",
    "          web_site_id,\n",
    "          sum(ws_ext_sales_price) as sales,\n",
    "          sum(coalesce(wr_return_amt, 0)) as returns,\n",
    "          sum(ws_net_profit - coalesce(wr_net_loss, 0)) as profit\n",
    "  from web_sales left outer join web_returns on\n",
    "         (ws_item_sk = wr_item_sk and ws_order_number = wr_order_number),\n",
    "     date_dim,\n",
    "     web_site,\n",
    "     item,\n",
    "     promotion\n",
    " where ws_sold_date_sk = d_date_sk\n",
    "       and d_date between to_char(to_date('2000-08-20','yyyy/mm/dd'),'yyyy-mm-dd')\n",
    "                  and (to_char(to_date('2000-08-20','yyyy/mm/dd') +  30,'yyyy-mm-dd'))\n",
    "        and ws_web_site_sk = web_site_sk\n",
    "       and ws_item_sk = i_item_sk\n",
    "       and i_current_price > 50\n",
    "       and ws_promo_sk = p_promo_sk\n",
    "       and p_channel_tv = 'N'\n",
    "group by web_site_id)\n",
    " select * from ( select  channel\n",
    "        , id\n",
    "        , sum(sales) as sales\n",
    "        , sum(returns) as returns\n",
    "        , sum(profit) as profit\n",
    " from\n",
    " (select 'store channel' as channel\n",
    "        , 'store' || store_id as id\n",
    "        , sales\n",
    "        , returns\n",
    "        , profit\n",
    " from   ssr\n",
    " union all\n",
    " select 'catalog channel' as channel\n",
    "        , 'catalog_page' || catalog_page_id as id\n",
    "        , sales\n",
    "        , returns\n",
    "        , profit\n",
    " from  csr\n",
    " union all\n",
    " select 'web channel' as channel\n",
    "        , 'web_site' || web_site_id as id\n",
    "        , sales\n",
    "        , returns\n",
    "        , profit\n",
    " from   wsr\n",
    " ) x\n",
    " group by rollup (channel, id)\n",
    " order by channel\n",
    "         ,id\n",
    "  ) where rownum <= 10000;\n",
    "```\n",
    "\n",
    "### Query 86\n",
    "``` sql\n",
    "select * from (select  /*+full(WEB_SALES)*/\n",
    "    sum(ws_net_paid) as total_sum\n",
    "   ,i_category\n",
    "   ,i_class\n",
    "   ,grouping(i_category)+grouping(i_class) as lochierarchy\n",
    "   ,rank() over (\n",
    " \tpartition by grouping(i_category)+grouping(i_class),\n",
    " \tcase when grouping(i_class) = 0 then i_category end\n",
    " \torder by sum(ws_net_paid) desc) as rank_within_parent\n",
    " from\n",
    "    web_sales\n",
    "   ,date_dim       d1\n",
    "   ,item\n",
    " where\n",
    "    d1.d_month_seq between 1194 and 1194+11\n",
    " and d1.d_date_sk = ws_sold_date_sk\n",
    " and i_item_sk  = ws_item_sk\n",
    " group by rollup(i_category,i_class)\n",
    " order by\n",
    "   lochierarchy desc,\n",
    "   case when lochierarchy = 0 then i_category end,\n",
    "   rank_within_parent\n",
    "  ) where rownum <= 10000;\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
