{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schedule Access Plan Recommendation\n",
    "\n",
    "This notebook is dedicated to model fitting in terms of database access plans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 0.23.4\n",
      "numpy: 1.15.2\n",
      "sklearn: 0.20.0\n"
     ]
    }
   ],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "print('pandas: %s' % pd.__version__)\n",
    "# numpy\n",
    "import numpy as np\n",
    "print('numpy: %s' % np.__version__)\n",
    "# sklearn\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "print('sklearn: %s' % sk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Experiment Config\n",
    "tpcds='TPCDS1' # Schema upon which to operate test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from file into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3018: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3018: DtypeWarning: Columns (6,19,20,21,23,24,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Index(['SNAP_ID', 'DBID', 'INSTANCE_NUMBER', 'SQL_ID', 'PLAN_HASH_VALUE',\n",
      "       'OPTIMIZER_COST', 'OPTIMIZER_MODE', 'OPTIMIZER_ENV_HASH_VALUE',\n",
      "       'SHARABLE_MEM', 'LOADED_VERSIONS', 'VERSION_COUNT', 'MODULE', 'ACTION',\n",
      "       'SQL_PROFILE', 'FORCE_MATCHING_SIGNATURE', 'PARSING_SCHEMA_ID',\n",
      "       'PARSING_SCHEMA_NAME', 'PARSING_USER_ID', 'FETCHES_TOTAL',\n",
      "       'FETCHES_DELTA', 'END_OF_FETCH_COUNT_TOTAL', 'END_OF_FETCH_COUNT_DELTA',\n",
      "       'SORTS_TOTAL', 'SORTS_DELTA', 'EXECUTIONS_TOTAL', 'EXECUTIONS_DELTA',\n",
      "       'PX_SERVERS_EXECS_TOTAL', 'PX_SERVERS_EXECS_DELTA', 'LOADS_TOTAL',\n",
      "       'LOADS_DELTA', 'INVALIDATIONS_TOTAL', 'INVALIDATIONS_DELTA',\n",
      "       'PARSE_CALLS_TOTAL', 'PARSE_CALLS_DELTA', 'DISK_READS_TOTAL',\n",
      "       'DISK_READS_DELTA', 'BUFFER_GETS_TOTAL', 'BUFFER_GETS_DELTA',\n",
      "       'ROWS_PROCESSED_TOTAL', 'ROWS_PROCESSED_DELTA', 'CPU_TIME_TOTAL',\n",
      "       'CPU_TIME_DELTA', 'ELAPSED_TIME_TOTAL', 'ELAPSED_TIME_DELTA',\n",
      "       'IOWAIT_TOTAL', 'IOWAIT_DELTA', 'CLWAIT_TOTAL', 'CLWAIT_DELTA',\n",
      "       'APWAIT_TOTAL', 'APWAIT_DELTA', 'CCWAIT_TOTAL', 'CCWAIT_DELTA',\n",
      "       'DIRECT_WRITES_TOTAL', 'DIRECT_WRITES_DELTA', 'PLSEXEC_TIME_TOTAL',\n",
      "       'PLSEXEC_TIME_DELTA', 'JAVEXEC_TIME_TOTAL', 'JAVEXEC_TIME_DELTA',\n",
      "       'IO_OFFLOAD_ELIG_BYTES_TOTAL', 'IO_OFFLOAD_ELIG_BYTES_DELTA',\n",
      "       'IO_INTERCONNECT_BYTES_TOTAL', 'IO_INTERCONNECT_BYTES_DELTA',\n",
      "       'PHYSICAL_READ_REQUESTS_TOTAL', 'PHYSICAL_READ_REQUESTS_DELTA',\n",
      "       'PHYSICAL_READ_BYTES_TOTAL', 'PHYSICAL_READ_BYTES_DELTA',\n",
      "       'PHYSICAL_WRITE_REQUESTS_TOTAL', 'PHYSICAL_WRITE_REQUESTS_DELTA',\n",
      "       'PHYSICAL_WRITE_BYTES_TOTAL', 'PHYSICAL_WRITE_BYTES_DELTA',\n",
      "       'OPTIMIZED_PHYSICAL_READS_TOTAL', 'OPTIMIZED_PHYSICAL_READS_DELTA',\n",
      "       'CELL_UNCOMPRESSED_BYTES_TOTAL', 'CELL_UNCOMPRESSED_BYTES_DELTA',\n",
      "       'IO_OFFLOAD_RETURN_BYTES_TOTAL', 'IO_OFFLOAD_RETURN_BYTES_DELTA',\n",
      "       'BIND_DATA', 'FLAG', 'CON_DBID', 'CON_ID', 'SQL_TEXT', 'COMMAND_TYPE',\n",
      "       'STARTUP_TIME', 'BEGIN_INTERVAL_TIME', 'END_INTERVAL_TIME',\n",
      "       'FLUSH_ELAPSED', 'SNAP_LEVEL', 'ERROR_COUNT', 'SNAP_FLAG',\n",
      "       'SNAP_TIMEZONE'],\n",
      "      dtype='object')\n",
      "Index(['DBID', 'SQL_ID', 'PLAN_HASH_VALUE', 'ID', 'OPERATION', 'OPTIONS',\n",
      "       'OBJECT_NODE', 'OBJECT#', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS',\n",
      "       'OBJECT_TYPE', 'OPTIMIZER', 'PARENT_ID', 'DEPTH', 'POSITION',\n",
      "       'SEARCH_COLUMNS', 'COST', 'CARDINALITY', 'BYTES', 'OTHER_TAG',\n",
      "       'PARTITION_START', 'PARTITION_STOP', 'PARTITION_ID', 'OTHER',\n",
      "       'DISTRIBUTION', 'CPU_COST', 'IO_COST', 'TEMP_SPACE',\n",
      "       'ACCESS_PREDICATES', 'FILTER_PREDICATES', 'PROJECTION', 'TIME',\n",
      "       'QBLOCK_NAME', 'REMARKS', 'TIMESTAMP', 'OTHER_XML', 'CON_DBID',\n",
      "       'CON_ID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# rep_vsql_plan_path = 'C:/Users/gabriel.sammut/University/Data_ICS5200/Schedule/' + tpcds + '/v2/rep_vsql_plan.csv'\n",
    "rep_vsql_plan_path = 'D:/Projects/Datagenerated_ICS5200/Schedule/' + tpcds + '/v2/rep_vsql_plan.csv'\n",
    "#\n",
    "rep_vsql_plan_df = pd.read_csv(rep_vsql_plan_path)\n",
    "#\n",
    "def prettify_header(headers):\n",
    "    \"\"\"\n",
    "    Cleans header list from unwated character strings\n",
    "    \"\"\"\n",
    "    header_list = []\n",
    "    [header_list.append(header.replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"\").replace(\",\",\"\")) for header in headers]\n",
    "    return header_list\n",
    "#\n",
    "rep_vsql_plan_df.columns = prettify_header(rep_vsql_plan_df.columns.values)\n",
    "print('------------------------------------------')\n",
    "print(rep_vsql_plan_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N/A Columns\n",
      "\n",
      "\n",
      "REP_HIST_SNAPSHOT Features 90: ['OPTIMIZER_COST', 'OPTIMIZER_MODE', 'OPTIMIZER_ENV_HASH_VALUE', 'LOADED_VERSIONS', 'MODULE', 'ACTION', 'SQL_PROFILE', 'PARSING_SCHEMA_ID', 'PARSING_SCHEMA_NAME', 'PARSING_USER_ID', 'FETCHES_TOTAL', 'FETCHES_DELTA', 'END_OF_FETCH_COUNT_TOTAL', 'END_OF_FETCH_COUNT_DELTA', 'SORTS_TOTAL', 'SORTS_DELTA', 'EXECUTIONS_TOTAL', 'EXECUTIONS_DELTA', 'PX_SERVERS_EXECS_TOTAL', 'PX_SERVERS_EXECS_DELTA', 'LOADS_TOTAL', 'LOADS_DELTA', 'INVALIDATIONS_TOTAL', 'INVALIDATIONS_DELTA', 'PARSE_CALLS_TOTAL', 'DISK_READS_TOTAL', 'DISK_READS_DELTA', 'BUFFER_GETS_TOTAL', 'BUFFER_GETS_DELTA', 'ROWS_PROCESSED_TOTAL', 'ROWS_PROCESSED_DELTA', 'CPU_TIME_TOTAL', 'ELAPSED_TIME_TOTAL', 'IOWAIT_TOTAL', 'IOWAIT_DELTA', 'CLWAIT_TOTAL', 'CLWAIT_DELTA', 'APWAIT_TOTAL', 'APWAIT_DELTA', 'CCWAIT_TOTAL', 'CCWAIT_DELTA', 'DIRECT_WRITES_TOTAL', 'DIRECT_WRITES_DELTA', 'PLSEXEC_TIME_TOTAL', 'PLSEXEC_TIME_DELTA', 'JAVEXEC_TIME_TOTAL', 'JAVEXEC_TIME_DELTA', 'IO_OFFLOAD_ELIG_BYTES_TOTAL', 'IO_OFFLOAD_ELIG_BYTES_DELTA', 'IO_INTERCONNECT_BYTES_TOTAL', 'IO_INTERCONNECT_BYTES_DELTA', 'PHYSICAL_READ_REQUESTS_TOTAL', 'PHYSICAL_READ_REQUESTS_DELTA', 'PHYSICAL_READ_BYTES_TOTAL', 'PHYSICAL_READ_BYTES_DELTA', 'PHYSICAL_WRITE_REQUESTS_TOTAL', 'PHYSICAL_WRITE_REQUESTS_DELTA', 'PHYSICAL_WRITE_BYTES_TOTAL', 'PHYSICAL_WRITE_BYTES_DELTA', 'OPTIMIZED_PHYSICAL_READS_TOTAL', 'OPTIMIZED_PHYSICAL_READS_DELTA', 'CELL_UNCOMPRESSED_BYTES_TOTAL', 'CELL_UNCOMPRESSED_BYTES_DELTA', 'IO_OFFLOAD_RETURN_BYTES_TOTAL', 'IO_OFFLOAD_RETURN_BYTES_DELTA', 'BIND_DATA', 'FLAG']\n",
      "\n",
      "\n",
      "REP_VSQL_PLAN Features 39: ['OPTIONS', 'OBJECT_NODE', 'OBJECT#', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS', 'OBJECT_TYPE', 'OPTIMIZER', 'PARENT_ID', 'COST', 'CARDINALITY', 'BYTES', 'OTHER_TAG', 'PARTITION_START', 'PARTITION_STOP', 'PARTITION_ID', 'OTHER', 'DISTRIBUTION', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'ACCESS_PREDICATES', 'FILTER_PREDICATES', 'PROJECTION', 'QBLOCK_NAME', 'REMARKS', 'TIMESTAMP', 'OTHER_XML', 'CON_DBID', 'CON_ID']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_na_columns(df, headers):\n",
    "    \"\"\"\n",
    "    Return columns which consist of NAN values\n",
    "    \"\"\"\n",
    "    na_list = []\n",
    "    for head in headers:\n",
    "        if df[head].isnull().values.any():\n",
    "            na_list.append(head)\n",
    "    return na_list\n",
    "#\n",
    "print('N/A Columns\\n')\n",
    "print('\\nREP_HIST_SNAPSHOT Features ' + str(len(rep_hist_snapshot_df.columns)) + ': ' + str(get_na_columns(df=rep_hist_snapshot_df,headers=rep_hist_snapshot_df.columns)) + \"\\n\")\n",
    "print('\\nREP_VSQL_PLAN Features ' + str(len(rep_vsql_plan_df.columns)) + ': ' + str(get_na_columns(df=rep_vsql_plan_df,headers=rep_vsql_plan_df.columns)) + \"\\n\")\n",
    "#\n",
    "def fill_na(df):\n",
    "    \"\"\"\n",
    "    Replaces NA columns with 0s\n",
    "    \"\"\"\n",
    "    return df.fillna(0)\n",
    "#\n",
    "# Populating NaN values with amount '0'\n",
    "df = fill_na(df=rep_vsql_plan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPC-DS Filtering & Merging\n",
    "\n",
    "Exclude all queries but those pertaining to TPC-DS.\n",
    "This part also merges the field 'SQL_TEXT' from data matrix REP_HIST_SNAPSHOT with data matrix 'REP_VSQL_PLAN'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64912, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415, 2)\n",
      "Plan table shape: (3252487, 39)\n",
      "Merged matrix shape: (260, 40)\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "\n",
      "          SQL_ID                                           SQL_TEXT  \\\n",
      "0  4gg1xchywmt7x  select /*+  no_parallel(t) no_parallel_index(t...   \n",
      "1  4gg1xchywmt7x  select /*+  no_parallel(t) no_parallel_index(t...   \n",
      "2  4gg1xchywmt7x  select /*+  no_parallel(t) no_parallel_index(t...   \n",
      "3  4gg1xchywmt7x  select /*+  no_parallel(t) no_parallel_index(t...   \n",
      "4  g7ab83s8qgp1m  SELECT /* DS_SVC */ /*+ dynamic_sampling(0) no...   \n",
      "\n",
      "                                                DBID  PLAN_HASH_VALUE  ID  \\\n",
      "0  select /*+  no_parallel(t) no_parallel_index(t...        220038496   0   \n",
      "1  select /*+  no_parallel(t) no_parallel_index(t...        220038496   1   \n",
      "2  select /*+  no_parallel(t) no_parallel_index(t...        220038496   2   \n",
      "3  select /*+  no_parallel(t) no_parallel_index(t...        220038496   3   \n",
      "4  SELECT /* DS_SVC */ /*+ dynamic_sampling(0) no...        686381367   0   \n",
      "\n",
      "          OPERATION        OPTIONS OBJECT_NODE   OBJECT# OBJECT_OWNER   ...    \\\n",
      "0  SELECT STATEMENT              0           0       0.0            0   ...     \n",
      "1              SORT       ORDER BY           0       0.0            0   ...     \n",
      "2   INLIST ITERATOR              0           0       0.0            0   ...     \n",
      "3      TABLE ACCESS  BY USER ROWID           0  114576.0       TPCDS1   ...     \n",
      "4  SELECT STATEMENT              0           0       0.0            0   ...     \n",
      "\n",
      "  ACCESS_PREDICATES FILTER_PREDICATES PROJECTION                 TIME  \\\n",
      "0               0.0               0.0          0  2018-10-30 06:40:14   \n",
      "1               0.0               1.0      SEL$1  2018-10-30 06:40:14   \n",
      "2               0.0               0.0          0  2018-10-30 06:40:14   \n",
      "3               0.0               1.0      SEL$1  2018-10-30 06:40:14   \n",
      "4               0.0               0.0          0  2018-10-08 22:44:34   \n",
      "\n",
      "   QBLOCK_NAME  REMARKS  TIMESTAMP  OTHER_XML  CON_DBID  CON_ID  \n",
      "0          0.0      0.0        0.0        0.0       0.0     0.0  \n",
      "1          0.0      0.0        0.0        0.0       0.0     0.0  \n",
      "2          0.0      0.0        0.0        0.0       0.0     0.0  \n",
      "3          0.0      0.0        0.0        0.0       0.0     0.0  \n",
      "4          0.0      0.0        0.0        0.0       0.0     0.0  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "# #\n",
    "# # Creating a dataframe consisting of a mapping library, composed of SQL_IDs & SQL_TEXTs\n",
    "# sql_id_map = rep_hist_snapshot_df[['SQL_ID','SQL_TEXT']]\n",
    "# print(sql_id_map.shape)\n",
    "# #\n",
    "# # Drop duplicate combinations from map\n",
    "# sql_id_map.drop_duplicates(keep = False,\n",
    "#                            inplace = True)\n",
    "# print(sql_id_map.shape)\n",
    "# #\n",
    "# # Merge SQL_TEXT with Access Plan table\n",
    "# df = pd.merge(sql_id_map, rep_vsql_plan_df, how='inner', on=['SQL_ID'])\n",
    "# print('Plan table shape: ' + str(rep_vsql_plan_df.shape))\n",
    "# print(\"Merged matrix shape: \" + str(df.shape) + \"\\n\\n--------------------------------------------------------\\n\\n\")\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "In this step, redundant features are dropped. Features are considered redundant if exhibit a standard devaition of 0 (meaning no change in value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape before changes: [(260, 40)]\n",
      "Shape after changes: [(260, 28)]\n",
      "Dropped a total [12]\n",
      "\n",
      "After flatline column drop:\n",
      "(260, 28)\n",
      "Index(['SQL_ID', 'SQL_TEXT', 'DBID', 'PLAN_HASH_VALUE', 'ID', 'OPERATION',\n",
      "       'OPTIONS', 'OBJECT_NODE', 'OBJECT#', 'OBJECT_OWNER', 'OBJECT_NAME',\n",
      "       'OBJECT_ALIAS', 'OBJECT_TYPE', 'OPTIMIZER', 'PARENT_ID', 'DEPTH',\n",
      "       'POSITION', 'SEARCH_COLUMNS', 'COST', 'CARDINALITY', 'BYTES',\n",
      "       'PARTITION_ID', 'OTHER', 'DISTRIBUTION', 'CPU_COST',\n",
      "       'FILTER_PREDICATES', 'PROJECTION', 'TIME'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def drop_flatline_columns(df):\n",
    "    columns = df.columns\n",
    "    flatline_features = []\n",
    "    for i in range(len(columns)):\n",
    "        try:\n",
    "            std = df[columns[i]].std()\n",
    "            if std == 0:\n",
    "                flatline_features.append(columns[i])\n",
    "        except:\n",
    "            pass\n",
    "    #\n",
    "    #print('Features which are considered flatline:\\n')\n",
    "    #for col in flatline_features:\n",
    "    #    print(col)\n",
    "    print('\\nShape before changes: [' + str(df.shape) + ']')\n",
    "    df = df.drop(columns=flatline_features)\n",
    "    print('Shape after changes: [' + str(df.shape) + ']')\n",
    "    print('Dropped a total [' + str(len(flatline_features)) + ']')\n",
    "    return df\n",
    "#\n",
    "df = drop_flatline_columns(df=df)\n",
    "print('\\nAfter flatline column drop:')\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ordering\n",
    "\n",
    "Sorting of datasets in order of \n",
    "* SNAP_ID\n",
    "* SQL_ID\n",
    "* ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TIMESTAMP'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-263b509579ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TIMESTAMP'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'SQL_ID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36msort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position)\u001b[0m\n\u001b[0;32m   4409\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4410\u001b[0m                 k = self._get_label_or_level_values(x, axis=axis,\n\u001b[1;32m-> 4411\u001b[1;33m                                                     stacklevel=stacklevel)\n\u001b[0m\u001b[0;32m   4412\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4413\u001b[0m             indexer = lexsort_indexer(keys, orders=ascending,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis, stacklevel)\u001b[0m\n\u001b[0;32m   1380\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'TIMESTAMP'"
     ]
    }
   ],
   "source": [
    "df.sort_values(by=['TIMESTAMP','SQL_ID','ID'], ascending=True, inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding\n",
    "\n",
    "Converting labels/features into numerical representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df, encoded_labels):\n",
    "    for col in df.columns:\n",
    "        if col in encoded_labels:\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df\n",
    "#\n",
    "#print(rep_vsql_plan_df.head())\n",
    "encoded_labels = ['OPERATION','OPTIONS','OBJECT_OWNER','OBJECT_NAME','OBJECT_ALIAS','OBJECT_TYPE','OPTIMIZER','QBLOCK_NAME']\n",
    "df = encode(df=df, encoded_labels=encoded_labels)\n",
    "print('Encoded labels:\\n' + str(encoded_labels) + \"\\n\\n----------------------------------------------\\n\\n\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Plan Resource Aggregation\n",
    "\n",
    "This method attempts to tackle the problem of access plan anomolies by aggregating resources per explain plan. Notable resources which are being considered are as follows:\n",
    "\n",
    "* COST\n",
    "* CARDINALITY\n",
    "* BYTES\n",
    "* PARTITION_DELTA (Partition End - Partition Start)\n",
    "* CPU_COST\n",
    "* IO_COST\n",
    "* TEMP_SPACE\n",
    "* TIME\n",
    "\n",
    "The reasoning behind these fields in particular is mainly because these columns can be aggregated together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_aggregate = df.groupby(['SQL_TEXT','PLAN_HASH_VALUE']).sum()\n",
    "df_aggregate.reset_index(inplace=True)\n",
    "print(df_aggregate.columns)\n",
    "print(df_aggregate.shape)\n",
    "for index, row in df_aggregate.iterrows():\n",
    "    print(row['SQL_TEXT'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
