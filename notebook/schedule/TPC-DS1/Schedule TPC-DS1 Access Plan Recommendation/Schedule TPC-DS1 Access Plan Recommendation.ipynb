{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schedule Access Plan Recommendation\n",
    "\n",
    "This notebook is dedicated to model fitting in terms of database access plans. Access plans here are a representation for a particular query syntax, composed of underlying relational operators as to how data will be retrieved. This experiment deals with plan aggregation. Particularly, plans will be aggregated (summed) into a vector representation, which will then be gauged as an inlier or an outlier. Therefore the owrk contained within this experiment deals with flagging query access plans as eligable for further analysis - in our case, further analysis as to which optimizer statistics should be gathered.\n",
    "\n",
    "It should however be noted that this experiment poses a limitation. Access plans here are merely aggregated into a singular vector, representative of the underlying query cost. This aggregation does not indicate which sub-elements of the query are denoted as excessively expensive - this work is carried out in another experiment entirely.\n",
    "\n",
    "## Query to Access Plan Representation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each query undergoes a set of processing steps when executed against a database instance. Apart from syntax and semantic checks which are carried out on the input syntax, a number of access plans are generated. Only one plan is chosen, based on the Cost Based Optimizer's decision in an effort to choose the least expensive one.\n",
    "\n",
    "<div style=\"width:image width px; font-size:80%; text-align:center;\"><img src='Images/Query_translation.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"padding-bottom:0.5em;\" /><b>Query Translation Process</b></div>\n",
    "\n",
    "The query access plan is composed in a tree-like structure, where in each node of the tree acts as a row source. Each step of the access plan either retrieves rows from the database, or accepts rows from one or more row sources as input. The following example is extracted from - https://docs.oracle.com/database/121/TGSQL/tgsql_sqlproc.htm#TGSQL186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\"\"\"\n",
    "SELECT e.last_name, j.job_title, d.department_name \n",
    "FROM   hr.employees e, hr.departments d, hr.jobs j\n",
    "WHERE  e.department_id = d.department_id\n",
    "AND    e.job_id = j.job_id\n",
    "AND    e.last_name LIKE 'A%';\n",
    "Execution Plan\n",
    "Plan hash value: 975837011\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "| Id| Operation                     | Name        |Rows|Bytes|Cost(%CPU)|Time  |\n",
    "| 0 | SELECT STATEMENT              |             |  3 | 189 | 7(15)| 00:00:01 |\n",
    "|*1 |  HASH JOIN                    |             |  3 | 189 | 7(15)| 00:00:01 |\n",
    "|*2 |   HASH JOIN                   |             |  3 | 141 | 5(20)| 00:00:01 |\n",
    "| 3 |    TABLE ACCESS BY INDEX ROWID| EMPLOYEES   |  3 |  60 | 2 (0)| 00:00:01 |\n",
    "|*4 |     INDEX RANGE SCAN          | EMP_NAME_IX |  3 |     | 1 (0)| 00:00:01 |\n",
    "| 5 |    TABLE ACCESS FULL          | JOBS        | 19 | 513 | 2 (0)| 00:00:01 |\n",
    "| 6 |   TABLE ACCESS FULL           | DEPARTMENTS | 27 | 432 | 2 (0)| 00:00:01 |\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "Predicate Information (identified by operation id):\n",
    " \n",
    "   1 - access(\"E\".\"DEPARTMENT_ID\"=\"D\".\"DEPARTMENT_ID\")\n",
    "   2 - access(\"E\".\"JOB_ID\"=\"J\".\"JOB_ID\")\n",
    "   4 - access(\"E\".\"LAST_NAME\" LIKE 'A%')\n",
    "       filter(\"E\".\"LAST_NAME\" LIKE 'A%')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:80%; text-align:center;\"><img src='Images/Row_source_tree.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"padding-bottom:0.5em;\" /><b>Access Plan Row Source Tree Representation</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 0.23.4\n",
      "numpy: 1.15.2\n",
      "sklearn: 0.19.0\n"
     ]
    }
   ],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "print('pandas: %s' % pd.__version__)\n",
    "# numpy\n",
    "import numpy as np\n",
    "print('numpy: %s' % np.__version__)\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# sklearn\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "print('sklearn: %s' % sk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Experiment Config\n",
    "tpcds='TPCDS1' # Schema upon which to operate test\n",
    "test_split=.2\n",
    "y_labels = ['COST',\n",
    "            'CARDINALITY',\n",
    "            'BYTES',\n",
    "            'CPU_COST',\n",
    "            'IO_COST',\n",
    "            'TEMP_SPACE',\n",
    "            'TIME']\n",
    "nrows = 1000000\n",
    "#\n",
    "# Random Forest Config\n",
    "parallel_degree = 4\n",
    "n_estimators = 500\n",
    "max_depth = 7\n",
    "criterion='gini'\n",
    "#\n",
    "# Isolation Forest Config\n",
    "contamination = .05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from file into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (6,19,20,21,22,25,26,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ('DBID',)    ('SQL_ID',)  ('PLAN_HASH_VALUE',)  ('ID',)    ('OPERATION',)  \\\n",
      "0  2634225673  dxv968j0352kb             103598129        0  SELECT STATEMENT   \n",
      "1  2634225673  dxv968j0352kb             103598129        1              SORT   \n",
      "2  2634225673  dxv968j0352kb             103598129        2    PX COORDINATOR   \n",
      "3  2634225673  dxv968j0352kb             103598129        3           PX SEND   \n",
      "4  2634225673  dxv968j0352kb             103598129        4              SORT   \n",
      "\n",
      "  ('OPTIONS',) ('OBJECT_NODE',)  ('OBJECT#',) ('OBJECT_OWNER',)  \\\n",
      "0          NaN              NaN           NaN               NaN   \n",
      "1     GROUP BY              NaN           NaN               NaN   \n",
      "2          NaN              NaN           NaN               NaN   \n",
      "3  QC (RANDOM)           :Q1001           NaN               SYS   \n",
      "4     GROUP BY           :Q1001           NaN               NaN   \n",
      "\n",
      "  ('OBJECT_NAME',)     ...     ('ACCESS_PREDICATES',) ('FILTER_PREDICATES',)  \\\n",
      "0              NaN     ...                        NaN                    NaN   \n",
      "1              NaN     ...                        NaN                    NaN   \n",
      "2              NaN     ...                        NaN                    NaN   \n",
      "3         :TQ10001     ...                        NaN                    NaN   \n",
      "4              NaN     ...                        NaN                    NaN   \n",
      "\n",
      "  ('PROJECTION',)  ('TIME',)  ('QBLOCK_NAME',)  ('REMARKS',)  \\\n",
      "0             NaN        NaN               NaN           NaN   \n",
      "1             NaN        NaN             SEL$1           NaN   \n",
      "2             NaN        NaN               NaN           NaN   \n",
      "3             NaN        NaN               NaN           NaN   \n",
      "4             NaN        NaN               NaN           NaN   \n",
      "\n",
      "        ('TIMESTAMP',)                                     ('OTHER_XML',)  \\\n",
      "0  2018-10-07 15:52:33                                                NaN   \n",
      "1  2018-10-07 15:52:33  <other_xml><info type=\"db_version\">12.1.0.2</i...   \n",
      "2  2018-10-07 15:52:33                                                NaN   \n",
      "3  2018-10-07 15:52:33                                                NaN   \n",
      "4  2018-10-07 15:52:33                                                NaN   \n",
      "\n",
      "   ('CON_DBID',) ('CON_ID',)  \n",
      "0     2634225673           0  \n",
      "1     2634225673           0  \n",
      "2     2634225673           0  \n",
      "3     2634225673           0  \n",
      "4     2634225673           0  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "------------------------------------------\n",
      "Index(['DBID', 'SQL_ID', 'PLAN_HASH_VALUE', 'ID', 'OPERATION', 'OPTIONS',\n",
      "       'OBJECT_NODE', 'OBJECT#', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS',\n",
      "       'OBJECT_TYPE', 'OPTIMIZER', 'PARENT_ID', 'DEPTH', 'POSITION',\n",
      "       'SEARCH_COLUMNS', 'COST', 'CARDINALITY', 'BYTES', 'OTHER_TAG',\n",
      "       'PARTITION_START', 'PARTITION_STOP', 'PARTITION_ID', 'OTHER',\n",
      "       'DISTRIBUTION', 'CPU_COST', 'IO_COST', 'TEMP_SPACE',\n",
      "       'ACCESS_PREDICATES', 'FILTER_PREDICATES', 'PROJECTION', 'TIME',\n",
      "       'QBLOCK_NAME', 'REMARKS', 'TIMESTAMP', 'OTHER_XML', 'CON_DBID',\n",
      "       'CON_ID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "rep_vsql_plan_path = 'C:/Users/gabriel.sammut/University/Data_ICS5200/Schedule/' + tpcds + '/rep_vsql_plan.csv'\n",
    "#rep_vsql_plan_path = 'D:/Projects/Datagenerated_ICS5200/Schedule/' + tpcds + '/rep_vsql_plan.csv'\n",
    "#\n",
    "dtype={'COST':'int64',\n",
    "       'CARDINALITY':'int64',\n",
    "       'BYTES':'int64',\n",
    "       'CPU_COST':'int64',\n",
    "       'IO_COST':'int64',\n",
    "       'TEMP_SPACE':'int64',\n",
    "       'TIME':'int64'}\n",
    "rep_vsql_plan_df = pd.read_csv(rep_vsql_plan_path,nrows=nrows,dtype=dtype)\n",
    "print(rep_vsql_plan_df.head())\n",
    "#\n",
    "def prettify_header(headers):\n",
    "    \"\"\"\n",
    "    Cleans header list from unwated character strings\n",
    "    \"\"\"\n",
    "    header_list = []\n",
    "    [header_list.append(header.replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"\").replace(\",\",\"\")) for header in headers]\n",
    "    return header_list\n",
    "#\n",
    "rep_vsql_plan_df.columns = prettify_header(rep_vsql_plan_df.columns.values)\n",
    "print('------------------------------------------')\n",
    "print(rep_vsql_plan_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read outlier data from file into pandas dataframes and concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1456, 35)\n",
      "  PLAN_ID            TIMESTAMP REMARKS         OPERATION          OPTIONS  \\\n",
      "0   12354  11/20/2018 08:23:55     NaN  SELECT STATEMENT              NaN   \n",
      "1   12354  11/20/2018 08:23:55     NaN             COUNT          STOPKEY   \n",
      "2   12354  11/20/2018 08:23:55     NaN              VIEW              NaN   \n",
      "3   12354  11/20/2018 08:23:55     NaN              SORT  GROUP BY ROLLUP   \n",
      "4   12354  11/20/2018 08:23:55     NaN              VIEW              NaN   \n",
      "\n",
      "  OBJECT_NODE OBJECT_OWNER OBJECT_NAME                OBJECT_ALIAS  \\\n",
      "0         NaN          NaN         NaN                         NaN   \n",
      "1         NaN          NaN         NaN                         NaN   \n",
      "2         NaN       TPCDS1         NaN  from$_subquery$_018@SEL$11   \n",
      "3         NaN          NaN         NaN                         NaN   \n",
      "4         NaN       TPCDS1         NaN                    X@SEL$12   \n",
      "\n",
      "  OBJECT_INSTANCE     ...      \\\n",
      "0             NaN     ...       \n",
      "1             NaN     ...       \n",
      "2              18     ...       \n",
      "3             NaN     ...       \n",
      "4              19     ...       \n",
      "\n",
      "                                           OTHER_XML DISTRIBUTION    CPU_COST  \\\n",
      "0                                                NaN          NaN  1657360333   \n",
      "1  <other_xml><info type=\"db_version\">12.1.0.2</i...          NaN         NaN   \n",
      "2                                                NaN          NaN  1657360333   \n",
      "3                                                NaN          NaN  1657360333   \n",
      "4                                                NaN          NaN  1625075317   \n",
      "\n",
      "  IO_COST TEMP_SPACE ACCESS_PREDICATES FILTER_PREDICATES  \\\n",
      "0   13630        NaN               NaN               NaN   \n",
      "1     NaN        NaN               NaN       ROWNUM<=100   \n",
      "2   13630        NaN               NaN               NaN   \n",
      "3   13630        NaN               NaN               NaN   \n",
      "4   13630        NaN               NaN               NaN   \n",
      "\n",
      "                                          PROJECTION TIME QBLOCK_NAME  \n",
      "0                                                NaN    1         NaN  \n",
      "1  from$_subquery$_018.\"CHANNEL\"[VARCHAR2,15], \"f...  NaN      SEL$11  \n",
      "2  from$_subquery$_018.\"CHANNEL\"[VARCHAR2,15], \"f...    1      SEL$12  \n",
      "3  (#keys=2) \"CHANNEL\"[VARCHAR2,15], \"ID\"[VARCHAR...    1      SEL$12  \n",
      "4  CHANNEL[VARCHAR2,15], \"ID\"[VARCHAR2,28], \"SALE...    1       SET$4  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "------------------------------------------\n",
      "Index(['PLAN_ID', 'TIMESTAMP', 'REMARKS', 'OPERATION', 'OPTIONS',\n",
      "       'OBJECT_NODE', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS',\n",
      "       'OBJECT_INSTANCE', 'OBJECT_TYPE', 'OPTIMIZER', 'SEARCH_COLUMNS', 'ID',\n",
      "       'PARENT_ID', 'DEPTH', 'POSITION', 'COST', 'CARDINALITY', 'BYTES',\n",
      "       'OTHER_TAG', 'PARTITION_START', 'PARTITION_STOP', 'PARTITION_ID',\n",
      "       'OTHER', 'OTHER_XML', 'DISTRIBUTION', 'CPU_COST', 'IO_COST',\n",
      "       'TEMP_SPACE', 'ACCESS_PREDICATES', 'FILTER_PREDICATES', 'PROJECTION',\n",
      "       'TIME', 'QBLOCK_NAME'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# CSV Outlier Paths\n",
    "outlier_hints_q5_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_5.csv'\n",
    "outlier_hints_q10_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_10.csv'\n",
    "outlier_hints_q14_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_14.csv'\n",
    "outlier_hints_q18_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_18.csv'\n",
    "outlier_hints_q22_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_22.csv'\n",
    "outlier_hints_q27_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_27.csv'\n",
    "outlier_hints_q35_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_35.csv'\n",
    "outlier_hints_q36_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_36.csv'\n",
    "outlier_hints_q51_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_51.csv'\n",
    "outlier_hints_q67_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_67.csv'\n",
    "outlier_hints_q70_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_70.csv'\n",
    "outlier_hints_q77_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_77.csv'\n",
    "outlier_hints_q80_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_80.csv'\n",
    "outlier_hints_q86_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_86.csv'\n",
    "#\n",
    "outlier_predicates_q5_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_5.csv'\n",
    "outlier_predicates_q10_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_10.csv'\n",
    "outlier_predicates_q14_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_14.csv'\n",
    "outlier_predicates_q18_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_18.csv'\n",
    "outlier_predicates_q22_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_22.csv'\n",
    "outlier_predicates_q27_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_27.csv'\n",
    "outlier_predicates_q35_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_35.csv'\n",
    "outlier_predicates_q36_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_36.csv'\n",
    "outlier_predicates_q51_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_51.csv'\n",
    "outlier_predicates_q67_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_67.csv'\n",
    "outlier_predicates_q70_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_70.csv'\n",
    "outlier_predicates_q77_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_77.csv'\n",
    "outlier_predicates_q80_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_80.csv'\n",
    "outlier_predicates_q86_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_86.csv'\n",
    "#\n",
    "outlier_rownum_q5_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_5.csv'\n",
    "outlier_rownum_q10_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_10.csv'\n",
    "outlier_rownum_q14_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_14.csv'\n",
    "outlier_rownum_q18_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_18.csv'\n",
    "outlier_rownum_q22_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_22.csv'\n",
    "outlier_rownum_q27_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_27.csv'\n",
    "outlier_rownum_q35_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_35.csv'\n",
    "outlier_rownum_q36_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_36.csv'\n",
    "outlier_rownum_q51_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_51.csv'\n",
    "outlier_rownum_q67_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_67.csv'\n",
    "outlier_rownum_q70_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_70.csv'\n",
    "outlier_rownum_q77_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_77.csv'\n",
    "outlier_rownum_q80_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_80.csv'\n",
    "outlier_rownum_q86_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_86.csv'\n",
    "#\n",
    "# Read CSV Paths\n",
    "outlier_hints_q5_df = pd.read_csv(outlier_hints_q5_path,dtype=str)\n",
    "outlier_hints_q10_df = pd.read_csv(outlier_hints_q10_path,dtype=str)\n",
    "outlier_hints_q14_df = pd.read_csv(outlier_hints_q14_path,dtype=str)\n",
    "outlier_hints_q18_df = pd.read_csv(outlier_hints_q18_path,dtype=str)\n",
    "outlier_hints_q22_df = pd.read_csv(outlier_hints_q22_path,dtype=str)\n",
    "outlier_hints_q27_df = pd.read_csv(outlier_hints_q27_path,dtype=str)\n",
    "outlier_hints_q35_df = pd.read_csv(outlier_hints_q35_path,dtype=str)\n",
    "outlier_hints_q36_df = pd.read_csv(outlier_hints_q36_path,dtype=str)\n",
    "outlier_hints_q51_df = pd.read_csv(outlier_hints_q51_path,dtype=str)\n",
    "outlier_hints_q67_df = pd.read_csv(outlier_hints_q67_path,dtype=str)\n",
    "outlier_hints_q70_df = pd.read_csv(outlier_hints_q70_path,dtype=str)\n",
    "outlier_hints_q77_df = pd.read_csv(outlier_hints_q77_path,dtype=str)\n",
    "outlier_hints_q80_df = pd.read_csv(outlier_hints_q80_path,dtype=str)\n",
    "outlier_hints_q86_df = pd.read_csv(outlier_hints_q86_path,dtype=str)\n",
    "#\n",
    "outlier_predicates_q5_df = pd.read_csv(outlier_predicates_q5_path,dtype=str)\n",
    "outlier_predicates_q10_df = pd.read_csv(outlier_predicates_q10_path,dtype=str)\n",
    "outlier_predicates_q14_df = pd.read_csv(outlier_predicates_q14_path,dtype=str)\n",
    "outlier_predicates_q18_df = pd.read_csv(outlier_predicates_q18_path,dtype=str)\n",
    "outlier_predicates_q22_df = pd.read_csv(outlier_predicates_q22_path,dtype=str)\n",
    "outlier_predicates_q27_df = pd.read_csv(outlier_predicates_q27_path,dtype=str)\n",
    "outlier_predicates_q35_df = pd.read_csv(outlier_predicates_q35_path,dtype=str)\n",
    "outlier_predicates_q36_df = pd.read_csv(outlier_predicates_q36_path,dtype=str)\n",
    "outlier_predicates_q51_df = pd.read_csv(outlier_predicates_q51_path,dtype=str)\n",
    "outlier_predicates_q67_df = pd.read_csv(outlier_predicates_q67_path,dtype=str)\n",
    "outlier_predicates_q70_df = pd.read_csv(outlier_predicates_q70_path,dtype=str)\n",
    "outlier_predicates_q77_df = pd.read_csv(outlier_predicates_q77_path,dtype=str)\n",
    "outlier_predicates_q80_df = pd.read_csv(outlier_predicates_q80_path,dtype=str)\n",
    "outlier_predicates_q86_df = pd.read_csv(outlier_predicates_q86_path,dtype=str)\n",
    "#\n",
    "outlier_rownum_q5_df = pd.read_csv(outlier_rownum_q5_path,dtype=str)\n",
    "outlier_rownum_q10_df = pd.read_csv(outlier_rownum_q10_path,dtype=str)\n",
    "outlier_rownum_q14_df = pd.read_csv(outlier_rownum_q14_path,dtype=str)\n",
    "outlier_rownum_q18_df = pd.read_csv(outlier_rownum_q18_path,dtype=str)\n",
    "outlier_rownum_q22_df = pd.read_csv(outlier_rownum_q22_path,dtype=str)\n",
    "outlier_rownum_q27_df = pd.read_csv(outlier_rownum_q27_path,dtype=str)\n",
    "outlier_rownum_q35_df = pd.read_csv(outlier_rownum_q35_path,dtype=str)\n",
    "outlier_rownum_q36_df = pd.read_csv(outlier_rownum_q36_path,dtype=str)\n",
    "outlier_rownum_q51_df = pd.read_csv(outlier_rownum_q51_path,dtype=str)\n",
    "outlier_rownum_q67_df = pd.read_csv(outlier_rownum_q67_path,dtype=str)\n",
    "outlier_rownum_q70_df = pd.read_csv(outlier_rownum_q70_path,dtype=str)\n",
    "outlier_rownum_q77_df = pd.read_csv(outlier_rownum_q77_path,dtype=str)\n",
    "outlier_rownum_q80_df = pd.read_csv(outlier_rownum_q80_path,dtype=str)\n",
    "outlier_rownum_q86_df = pd.read_csv(outlier_rownum_q86_path,dtype=str)\n",
    "#\n",
    "# Merge dataframes into a single pandas matrix\n",
    "df_outliers = pd.concat([outlier_hints_q5_df, outlier_hints_q10_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q14_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q18_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q22_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q27_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q35_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q36_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q51_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q67_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q70_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q77_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q80_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q86_df], sort=False)\n",
    "#\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q5_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q10_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q14_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q18_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q22_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q27_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q35_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q36_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q51_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q67_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q70_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q77_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q80_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q86_df], sort=False)\n",
    "#\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q5_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q10_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q14_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q18_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q22_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q27_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q35_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q36_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q51_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q67_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q70_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q77_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q80_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q86_df], sort=False)   \n",
    "#\n",
    "print(df_outliers.shape)\n",
    "print(df_outliers.head())\n",
    "print('------------------------------------------')\n",
    "print(df_outliers.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N/A Columns\n",
      "\n",
      "\n",
      "REP_VSQL_PLAN Features 39: ['OPTIONS', 'OBJECT_NODE', 'OBJECT#', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS', 'OBJECT_TYPE', 'OPTIMIZER', 'PARENT_ID', 'COST', 'CARDINALITY', 'BYTES', 'OTHER_TAG', 'PARTITION_START', 'PARTITION_STOP', 'PARTITION_ID', 'OTHER', 'DISTRIBUTION', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'ACCESS_PREDICATES', 'FILTER_PREDICATES', 'PROJECTION', 'TIME', 'QBLOCK_NAME', 'REMARKS', 'OTHER_XML']\n",
      "\n",
      "\n",
      "DF_OUTLIERS Features 35: ['REMARKS', 'OPTIONS', 'OBJECT_NODE', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS', 'OBJECT_INSTANCE', 'OBJECT_TYPE', 'OPTIMIZER', 'SEARCH_COLUMNS', 'PARENT_ID', 'COST', 'CARDINALITY', 'BYTES', 'OTHER_TAG', 'PARTITION_START', 'PARTITION_STOP', 'PARTITION_ID', 'OTHER', 'OTHER_XML', 'DISTRIBUTION', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'ACCESS_PREDICATES', 'FILTER_PREDICATES', 'PROJECTION', 'TIME', 'QBLOCK_NAME']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_na_columns(df, headers):\n",
    "    \"\"\"\n",
    "    Return columns which consist of NAN values\n",
    "    \"\"\"\n",
    "    na_list = []\n",
    "    for head in headers:\n",
    "        if df[head].isnull().values.any():\n",
    "            na_list.append(head)\n",
    "    return na_list\n",
    "#\n",
    "print('N/A Columns\\n')\n",
    "print('\\nREP_VSQL_PLAN Features ' + str(len(rep_vsql_plan_df.columns)) + ': ' + str(get_na_columns(df=rep_vsql_plan_df,headers=rep_vsql_plan_df.columns)) + \"\\n\")\n",
    "print('\\nDF_OUTLIERS Features ' + str(len(df_outliers.columns)) + ': ' + str(get_na_columns(df=df_outliers,headers=df_outliers.columns)) + \"\\n\")\n",
    "#\n",
    "def fill_na(df):\n",
    "    \"\"\"\n",
    "    Replaces NA columns with 0s\n",
    "    \"\"\"\n",
    "    return df.fillna(0)\n",
    "#\n",
    "# Populating NaN values with amount '0'\n",
    "df = fill_na(df=rep_vsql_plan_df)\n",
    "df_outliers = fill_na(df=df_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "In this step, redundant features are dropped. Features are considered redundant if exhibit a standard devaition of 0 (meaning no change in value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape before changes: [(1000000, 39)]\n",
      "Shape after changes: [(1000000, 31)]\n",
      "Dropped a total [8]\n",
      "\n",
      "Shape before changes: [(1456, 35)]\n",
      "Shape after changes: [(1456, 27)]\n",
      "Dropped a total [8]\n",
      "\n",
      "After flatline column drop:\n",
      "(1000000, 31)\n",
      "Index(['SQL_ID', 'PLAN_HASH_VALUE', 'ID', 'OPERATION', 'OPTIONS',\n",
      "       'OBJECT_NODE', 'OBJECT#', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS',\n",
      "       'OBJECT_TYPE', 'OPTIMIZER', 'PARENT_ID', 'DEPTH', 'POSITION',\n",
      "       'SEARCH_COLUMNS', 'COST', 'CARDINALITY', 'BYTES', 'OTHER_TAG',\n",
      "       'PARTITION_START', 'PARTITION_STOP', 'PARTITION_ID', 'DISTRIBUTION',\n",
      "       'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'TIME', 'QBLOCK_NAME', 'TIMESTAMP',\n",
      "       'OTHER_XML'],\n",
      "      dtype='object')\n",
      "--------------------------------------------------------\n",
      "\n",
      "After outlier flatline column drop:\n",
      "(1456, 27)\n",
      "Index(['PLAN_ID', 'TIMESTAMP', 'OPERATION', 'OPTIONS', 'OBJECT_OWNER',\n",
      "       'OBJECT_NAME', 'OBJECT_ALIAS', 'OBJECT_INSTANCE', 'OBJECT_TYPE',\n",
      "       'OPTIMIZER', 'SEARCH_COLUMNS', 'ID', 'PARENT_ID', 'DEPTH', 'POSITION',\n",
      "       'COST', 'CARDINALITY', 'BYTES', 'OTHER_XML', 'CPU_COST', 'IO_COST',\n",
      "       'TEMP_SPACE', 'ACCESS_PREDICATES', 'FILTER_PREDICATES', 'PROJECTION',\n",
      "       'TIME', 'QBLOCK_NAME'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def drop_flatline_columns(df):\n",
    "    columns = df.columns\n",
    "    flatline_features = []\n",
    "    for i in range(len(columns)):\n",
    "        try:\n",
    "            std = df[columns[i]].std()\n",
    "            if std == 0:\n",
    "                flatline_features.append(columns[i])\n",
    "        except:\n",
    "            pass\n",
    "    #\n",
    "    #print('Features which are considered flatline:\\n')\n",
    "    #for col in flatline_features:\n",
    "    #    print(col)\n",
    "    print('\\nShape before changes: [' + str(df.shape) + ']')\n",
    "    df = df.drop(columns=flatline_features)\n",
    "    print('Shape after changes: [' + str(df.shape) + ']')\n",
    "    print('Dropped a total [' + str(len(flatline_features)) + ']')\n",
    "    return df\n",
    "#\n",
    "df = drop_flatline_columns(df=df)\n",
    "df_outliers = drop_flatline_columns(df=df_outliers)\n",
    "#\n",
    "print('\\nAfter flatline column drop:')\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "#\n",
    "print('--------------------------------------------------------')\n",
    "print('\\nAfter outlier flatline column drop:')\n",
    "print(df_outliers.shape)\n",
    "print(df_outliers.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding\n",
    "\n",
    "Converting labels/features into numerical representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels:\n",
      "['OPERATION', 'OPTIONS', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS', 'OBJECT_TYPE', 'OPTIMIZER', 'QBLOCK_NAME']\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "          SQL_ID  PLAN_HASH_VALUE  ID  OPERATION  OPTIONS OBJECT_NODE  \\\n",
      "0  dxv968j0352kb        103598129   0         26        0           0   \n",
      "1  dxv968j0352kb        103598129   1         28       15           0   \n",
      "2  dxv968j0352kb        103598129   2         22        0           0   \n",
      "3  dxv968j0352kb        103598129   3         24       27      :Q1001   \n",
      "4  dxv968j0352kb        103598129   4         28       15      :Q1001   \n",
      "\n",
      "   OBJECT#  OBJECT_OWNER  OBJECT_NAME  OBJECT_ALIAS  \\\n",
      "0      0.0             0            0             0   \n",
      "1      0.0             0            0             0   \n",
      "2      0.0             0            0             0   \n",
      "3      0.0             1           13             0   \n",
      "4      0.0             0            0             0   \n",
      "\n",
      "                         ...                          PARTITION_STOP  \\\n",
      "0                        ...                                       0   \n",
      "1                        ...                                       0   \n",
      "2                        ...                                       0   \n",
      "3                        ...                                       0   \n",
      "4                        ...                                       0   \n",
      "\n",
      "   PARTITION_ID  DISTRIBUTION  CPU_COST  IO_COST  TEMP_SPACE  TIME  \\\n",
      "0           0.0             0                0.0               0.0   \n",
      "1           0.0             0                0.0               0.0   \n",
      "2           0.0             0                0.0               0.0   \n",
      "3           0.0   QC (RANDOM)                0.0               0.0   \n",
      "4           0.0             0                0.0               0.0   \n",
      "\n",
      "   QBLOCK_NAME            TIMESTAMP  \\\n",
      "0            0  2018-10-07 15:52:33   \n",
      "1           11  2018-10-07 15:52:33   \n",
      "2            0  2018-10-07 15:52:33   \n",
      "3            0  2018-10-07 15:52:33   \n",
      "4            0  2018-10-07 15:52:33   \n",
      "\n",
      "                                           OTHER_XML  \n",
      "0                                                  0  \n",
      "1  <other_xml><info type=\"db_version\">12.1.0.2</i...  \n",
      "2                                                  0  \n",
      "3                                                  0  \n",
      "4                                                  0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "Encoded labels:\n",
      "['OPERATION', 'OPTIONS', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS', 'OBJECT_TYPE', 'OPTIMIZER', 'QBLOCK_NAME']\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "  PLAN_ID            TIMESTAMP  OPERATION  OPTIONS  OBJECT_OWNER  OBJECT_NAME  \\\n",
      "0   12354  11/20/2018 08:23:55         10        0             0            0   \n",
      "1   12354  11/20/2018 08:23:55          1       21             0            0   \n",
      "2   12354  11/20/2018 08:23:55         16        0             2            0   \n",
      "3   12354  11/20/2018 08:23:55         11       10             0            0   \n",
      "4   12354  11/20/2018 08:23:55         16        0             2            0   \n",
      "\n",
      "   OBJECT_ALIAS OBJECT_INSTANCE  OBJECT_TYPE  OPTIMIZER     ...      BYTES  \\\n",
      "0             0               0            0          1     ...       6400   \n",
      "1             0               0            0          0     ...          0   \n",
      "2           114              18            0          0     ...      32448   \n",
      "3             0               0            0          0     ...      32448   \n",
      "4           104              19            0          0     ...      32448   \n",
      "\n",
      "                                           OTHER_XML    CPU_COST IO_COST  \\\n",
      "0                                                  0  1657360333   13630   \n",
      "1  <other_xml><info type=\"db_version\">12.1.0.2</i...           0       0   \n",
      "2                                                  0  1657360333   13630   \n",
      "3                                                  0  1657360333   13630   \n",
      "4                                                  0  1625075317   13630   \n",
      "\n",
      "  TEMP_SPACE ACCESS_PREDICATES FILTER_PREDICATES  \\\n",
      "0          0                 0                 0   \n",
      "1          0                 0       ROWNUM<=100   \n",
      "2          0                 0                 0   \n",
      "3          0                 0                 0   \n",
      "4          0                 0                 0   \n",
      "\n",
      "                                          PROJECTION TIME QBLOCK_NAME  \n",
      "0                                                  0    1           0  \n",
      "1  from$_subquery$_018.\"CHANNEL\"[VARCHAR2,15], \"f...    0           4  \n",
      "2  from$_subquery$_018.\"CHANNEL\"[VARCHAR2,15], \"f...    1           5  \n",
      "3  (#keys=2) \"CHANNEL\"[VARCHAR2,15], \"ID\"[VARCHAR...    1           5  \n",
      "4  CHANNEL[VARCHAR2,15], \"ID\"[VARCHAR2,28], \"SALE...    1          47  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "def encode(df, encoded_labels):\n",
    "    for col in df.columns:\n",
    "        if col in encoded_labels:\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df\n",
    "#\n",
    "# Determine labels used for encoding\n",
    "encoded_labels = ['OPERATION','OPTIONS','OBJECT_OWNER','OBJECT_NAME','OBJECT_ALIAS','OBJECT_TYPE','OPTIMIZER','QBLOCK_NAME']\n",
    "#\n",
    "df = encode(df=df, encoded_labels=encoded_labels)\n",
    "print('Encoded labels:\\n' + str(encoded_labels) + \"\\n\\n----------------------------------------------\\n\\n\")\n",
    "print(df.head())\n",
    "#\n",
    "df_outliers = encode(df=df_outliers, encoded_labels=encoded_labels)\n",
    "print('Encoded labels:\\n' + str(encoded_labels) + \"\\n\\n----------------------------------------------\\n\\n\")\n",
    "print(df_outliers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floating point precision conversion\n",
    "\n",
    "Each column is converted into a column of type values which are floating point for higher precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inliers\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(1000000, 31)\n",
      "Outliers\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(1456, 27)\n"
     ]
    }
   ],
   "source": [
    "print('Inliers')\n",
    "print(type(df))\n",
    "print(df.shape)\n",
    "#\n",
    "print('Outliers')\n",
    "df_outliers[y_labels] = df_outliers[y_labels].astype('int64')\n",
    "print(type(df_outliers))\n",
    "print(df_outliers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Plan Resource Aggregation (Per Access Plan Type)\n",
    "\n",
    "This method attempts to tackle the problem of access plan anomolies by aggregating resources per explain plan. Notable resources which are being considered are as follows:\n",
    "\n",
    "* COST\n",
    "* CARDINALITY\n",
    "* BYTES\n",
    "* PARTITION_DELTA (Partition End - Partition Start)\n",
    "* CPU_COST\n",
    "* IO_COST\n",
    "* TEMP_SPACE\n",
    "* TIME\n",
    "\n",
    "The reasoning behind these fields in particular is mainly because these columns can be aggregated together. Aggregation is carried on per access plan type. Aggregation at this phase ensures that each SQL ID is represented as a mean vector, which represents the PLAN_HASH_VALUE as a vector of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "(1000000, 31)\n",
      "Index(['SQL_ID', 'PLAN_HASH_VALUE', 'ID', 'OPERATION', 'OPTIONS', 'OBJECT#',\n",
      "       'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS', 'OBJECT_TYPE',\n",
      "       'OPTIMIZER', 'PARENT_ID', 'DEPTH', 'POSITION', 'SEARCH_COLUMNS', 'COST',\n",
      "       'CARDINALITY', 'PARTITION_ID', 'IO_COST', 'TIME', 'QBLOCK_NAME'],\n",
      "      dtype='object')\n",
      "(291, 21)\n",
      "-------------------\n",
      "After\n",
      "(1456, 27)\n",
      "Index(['PLAN_ID', 'OPERATION', 'OPTIONS', 'OBJECT_OWNER', 'OBJECT_NAME',\n",
      "       'OBJECT_ALIAS', 'OBJECT_TYPE', 'OPTIMIZER', 'COST', 'CARDINALITY',\n",
      "       'BYTES', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'TIME', 'QBLOCK_NAME'],\n",
      "      dtype='object')\n",
      "(42, 16)\n"
     ]
    }
   ],
   "source": [
    "print('Before')\n",
    "print(df.shape)\n",
    "df_agg = df.groupby(['SQL_ID','PLAN_HASH_VALUE']).mean()\n",
    "df_agg.reset_index(inplace=True)\n",
    "print(df_agg.columns)\n",
    "print(df_agg.shape)\n",
    "#\n",
    "print('-------------------\\nAfter')\n",
    "print(df_outliers.shape)\n",
    "df_outliers_agg = df_outliers.groupby(['PLAN_ID']).mean()\n",
    "df_outliers_agg.reset_index(inplace=True)\n",
    "print(df_outliers_agg.columns)\n",
    "print(df_outliers_agg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Reduction\n",
    "\n",
    "Strips further columns unneccessary to the experiment, so as to have the same columns for both training data set and outlier set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['OPERATION', 'OPTIONS', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS',\n",
      "       'OBJECT_TYPE', 'OPTIMIZER', 'COST', 'CARDINALITY', 'IO_COST', 'TIME',\n",
      "       'QBLOCK_NAME'],\n",
      "      dtype='object')\n",
      "(291, 12)\n",
      "------------------------------------------\n",
      "Index(['OPERATION', 'OPTIONS', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS',\n",
      "       'OBJECT_TYPE', 'OPTIMIZER', 'COST', 'CARDINALITY', 'IO_COST', 'TIME',\n",
      "       'QBLOCK_NAME'],\n",
      "      dtype='object')\n",
      "(42, 12)\n"
     ]
    }
   ],
   "source": [
    "for col in df_outliers_agg.columns:\n",
    "    if col not in df_agg.columns:\n",
    "        df_outliers_agg.drop(columns=[col], inplace=True)\n",
    "for col in df_agg.columns:\n",
    "    if col not in df_outliers_agg.columns:\n",
    "        df_agg.drop(columns=[col], inplace=True)\n",
    "#\n",
    "print(df_agg.columns)\n",
    "print(df_agg.shape)\n",
    "print('------------------------------------------')\n",
    "print(df_outliers_agg.columns)\n",
    "print(df_outliers_agg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Training (Random Forest - Per Access Plan Type)\n",
    "\n",
    "The following section oversees the supervised training of inlier/outlier explain plans. This section first splits the training dataset into two: train + test sets, by mixing half the outliers with the inlier training set. Validation is then performed on a 50/50 mix of inlier / outlier vectors. The ability to classify explain plan vectors as inliers / outliers will be gauged.\n",
    "\n",
    "Labels are denoted as follows:\n",
    "* Inliers  - 0\n",
    "* Outliers - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Random Forest\n",
    "class RandomForest:\n",
    "    \"\"\"\n",
    "    Random Forest Class (Regression + Classification)\n",
    "    \"\"\"\n",
    "    #\n",
    "    def __init__(self, n_estimators, max_depth=None, criterion='gini', parallel_degree=1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.parallel_degree=parallel_degree\n",
    "        self.criterion = criterion\n",
    "        self.model = RandomForestClassifier(max_depth=self.max_depth,\n",
    "                                            n_estimators=self.n_estimators,\n",
    "                                            criterion=self.criterion,\n",
    "                                            n_jobs=self.parallel_degree)\n",
    "    #\n",
    "    def fit_model(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits training data to target labels\n",
    "        \"\"\"\n",
    "        self.model.fit(X,y)\n",
    "        print(self.model)\n",
    "    #\n",
    "    def predict(self, X):\n",
    "        yhat = self.model.predict(X)\n",
    "        return yhat\n",
    "    #\n",
    "    def predict_and_evaluate(self, X, y, plot=False):\n",
    "        \"\"\"\n",
    "        Runs test data through previously trained model, and evaluate differently depending if a regression of classification model\n",
    "        \"\"\"\n",
    "        yhat = self.predict(X)\n",
    "        acc = accuracy_score(y, yhat, normalize=True)\n",
    "        precision = precision_score(y, yhat, average='binary')\n",
    "        recall = recall_score(y, yhat, average='binary')\n",
    "        f1 = f1_score(y, yhat, average='binary')\n",
    "        print('Test Accuracy: ' +  str(acc))\n",
    "        print('Test Precision: ' +  str(precision))\n",
    "        print('Test Recall: ' +  str(recall))\n",
    "        print('Test FScore: ' +  str(f1) + \"\\n\")\n",
    "    #\n",
    "    @staticmethod\n",
    "    def write_results_to_disk(path, iteration, lag, test_split, estimator, score, time_train):\n",
    "        file_exists = os.path.isfile(path)\n",
    "        with open(path, 'a') as csvfile:\n",
    "            headers = ['iteration', 'lag', 'test_split', 'estimator', 'score', 'time_train']\n",
    "            writer = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=headers)\n",
    "            if not file_exists:\n",
    "                writer.writeheader()  # file doesn't exist yet, write a header\n",
    "            writer.writerow({'iteration': iteration,\n",
    "                             'lag': lag,\n",
    "                             'test_split': test_split,\n",
    "                             'estimator': estimator,\n",
    "                             'score': score,\n",
    "                             'time_train': time_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.36000000e+01 1.45000000e+01 5.00000000e-01 ... 4.00000000e+01\n",
      "  2.00000000e-01 2.20000000e+00]\n",
      " [2.31666667e+01 6.83333333e+00 1.00000000e+00 ... 1.50833333e+02\n",
      "  5.00000000e-01 7.40000000e+01]\n",
      " [2.31666667e+01 6.83333333e+00 1.00000000e+00 ... 1.41000000e+02\n",
      "  5.00000000e-01 7.40000000e+01]\n",
      " ...\n",
      " [1.05500000e+01 5.30000000e+00 9.00000000e-01 ... 2.83139000e+04\n",
      "  1.80000000e+00 9.70000000e+00]\n",
      " [9.20000000e+00 4.86666667e+00 9.33333333e-01 ... 4.07773333e+03\n",
      "  9.33333333e-01 5.46666667e+00]\n",
      " [8.75000000e+00 4.85000000e+00 9.00000000e-01 ... 5.41175000e+03\n",
      "  9.50000000e-01 5.10000000e+00]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=4,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Test Accuracy: 1.0\n",
      "Test Precision: 1.0\n",
      "Test Recall: 1.0\n",
      "Test FScore: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_labels_outliers, df_labels = [], []\n",
    "for i in range(df_agg.shape[0]):\n",
    "    df_labels.append(0)\n",
    "for i in range(df_outliers_agg.shape[0]):\n",
    "    df_labels_outliers.append(1)\n",
    "#\n",
    "# Training / Validation Splits (Inliers + Outliers)\n",
    "X_df_train, X_df_validate, y_df_train, y_df_validate = train_test_split(df_agg, df_labels, test_size=test_split)\n",
    "X_df_outlier_train, X_df_outlier_validate, y_df_outlier_train, y_df_outlier_validate = train_test_split(df_outliers_agg, df_labels_outliers, test_size=.5)\n",
    "#\n",
    "# Mixing of Inlier + Outlier data for validation purposes\n",
    "X_df_train = np.concatenate((X_df_train.values, X_df_outlier_train.values), axis=0)\n",
    "y_df_train = np.concatenate((np.array(y_df_train), np.array(y_df_outlier_train)), axis=0)\n",
    "X_df_validate = np.concatenate((X_df_validate.values, X_df_outlier_validate.values), axis=0)\n",
    "y_df_validate = np.concatenate((np.array(y_df_validate), np.array(y_df_outlier_validate)), axis=0)\n",
    "#\n",
    "# Building Model + Training\n",
    "rfc = RandomForest(n_estimators=n_estimators,\n",
    "                   max_depth=max_depth,\n",
    "                   criterion=criterion,\n",
    "                   parallel_degree=parallel_degree)\n",
    "print(X_df_train)\n",
    "print(y_df_train)\n",
    "rfc.fit_model(X=X_df_train,\n",
    "              y=y_df_train)\n",
    "# Evaluation\n",
    "rfc.predict_and_evaluate(X=X_df_validate, \n",
    "                         y=y_df_validate,\n",
    "                         plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning (Isolation Forest - Per Access Plan Type)\n",
    "\n",
    "The following section attempts to train a generalized version of input access plans using Isolation Forests. These trained models are then used to classify access plan outliers from inlier (normal) access plans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsolationForestWrapper:\n",
    "    #\n",
    "    def __init__(self, contamination=.1, parallel_degree=1):\n",
    "        \"\"\"\n",
    "        Constructor Method\n",
    "        :param X - Numpy Array\n",
    "        :param contamination - Real value\n",
    "        :param parallel_degree - Parellization parameter \n",
    "        \"\"\"\n",
    "        self.model = IsolationForest(n_estimators=100, max_samples=256, contamination=contamination, random_state=0, n_jobs=parallel_degree)\n",
    "        print(self.model)\n",
    "    #\n",
    "    def fit_model(self, X):\n",
    "        \"\"\"\n",
    "        Fits Isolation Model and plots scorings\n",
    "        \"\"\"\n",
    "        self.model.fit(X)        \n",
    "    #\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X) \n",
    "    #\n",
    "    def evaluate_model(self, X, y, plot=False):\n",
    "        yhat = self.predict(X)\n",
    "        acc = accuracy_score(y, yhat, normalize=True)\n",
    "        precision = precision_score(y, yhat, average='binary')\n",
    "        recall = recall_score(y, yhat, average='binary')\n",
    "        f1 = f1_score(y, yhat, average='binary')\n",
    "        print('Test Accuracy: ' +  str(acc))\n",
    "        print('Test Precision: ' +  str(precision))\n",
    "        print('Test Recall: ' +  str(recall))\n",
    "        print('Test FScore: ' +  str(f1) + \"\\n\")\n",
    "        if plot is True:\n",
    "            scores = self.model.decision_function(X)\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.hist(scores, bins=50);\n",
    "            plt.title('Isolation Forest Scorings')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsolationForest(bootstrap=False, contamination=0.05, max_features=1.0,\n",
      "        max_samples=256, n_estimators=100, n_jobs=4, random_state=0,\n",
      "        verbose=0)\n",
      "[[2.19444444e+01 6.00000000e+00 7.77777778e-01 ... 5.97244444e+03\n",
      "  8.88888889e-01 7.82777778e+01]\n",
      " [1.97777778e+01 9.55555556e+00 1.33333333e+00 ... 2.93000000e+02\n",
      "  6.66666667e-01 5.86666667e+01]\n",
      " [2.31666667e+01 6.83333333e+00 1.00000000e+00 ... 1.35666667e+02\n",
      "  5.00000000e-01 7.40000000e+01]\n",
      " ...\n",
      " [1.01363636e+01 6.56818182e+00 1.13636364e+00 ... 3.05686364e+03\n",
      "  8.86363636e-01 1.85227273e+01]\n",
      " [1.00217391e+01 7.17391304e+00 1.17391304e+00 ... 4.64282609e+02\n",
      "  8.91304348e-01 2.01086957e+01]\n",
      " [8.75000000e+00 4.85000000e+00 9.00000000e-01 ... 4.80025000e+03\n",
      "  9.50000000e-01 5.10000000e+00]]\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:187: UserWarning: max_samples (256) is greater than the total number of samples (253). max_samples will be set to n_samples for estimation.\n",
      "  % (self.max_samples, n_samples))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.75\n",
      "Test Precision: 0.7468354430379747\n",
      "Test Recall: 1.0\n",
      "Test FScore: 0.855072463768116\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_labels_outliers, df_labels = [], []\n",
    "for i in range(df_agg.shape[0]):\n",
    "    df_labels.append(1)\n",
    "for i in range(df_outliers_agg.shape[0]):\n",
    "    df_labels_outliers.append(-1)\n",
    "#\n",
    "# Training / Validation Splits (Inliers + Outliers)\n",
    "X_df_train, X_df_validate, y_df_train, y_df_validate = train_test_split(df_agg, df_labels, test_size=test_split)\n",
    "X_df_outlier_train, X_df_outlier_validate, y_df_outlier_train, y_df_outlier_validate = train_test_split(df_outliers_agg, df_labels_outliers, test_size=.5)\n",
    "#\n",
    "# Mixing of Inlier + Outlier data for validation purposes\n",
    "X_df_train = np.concatenate((X_df_train.values, X_df_outlier_train.values), axis=0)\n",
    "y_df_train = np.concatenate((np.array(y_df_train), np.array(y_df_outlier_train)), axis=0)\n",
    "X_df_validate = np.concatenate((X_df_validate.values, X_df_outlier_validate.values), axis=0)\n",
    "y_df_validate = np.concatenate((np.array(y_df_validate), np.array(y_df_outlier_validate)), axis=0)\n",
    "#\n",
    "# Building Model + Training\n",
    "ifw = IsolationForestWrapper(contamination=contamination,\n",
    "                             parallel_degree=parallel_degree)\n",
    "print(X_df_train)\n",
    "print(y_df_train)\n",
    "ifw.fit_model(X=X_df_train)\n",
    "#\n",
    "# Evaluation\n",
    "ifw.evaluate_model(X=X_df_validate, \n",
    "                   y=y_df_validate,\n",
    "                   plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Plan Resource Aggregation (Per Access Plan Instance)\n",
    "\n",
    "This method attempts to tackle the problem of access plan anomolies by aggregating resources per explain plan. Notable resources which are being considered are as follows:\n",
    "\n",
    "* COST\n",
    "* CARDINALITY\n",
    "* BYTES\n",
    "* PARTITION_DELTA (Partition End - Partition Start)\n",
    "* CPU_COST\n",
    "* IO_COST\n",
    "* TEMP_SPACE\n",
    "* TIME\n",
    "\n",
    "The reasoning behind these fields in particular is mainly because these columns can be aggregated together. Aggregation is carried on per access plan instance. Therefore batches are summed together with every explain plan, per timestamp. Contraty to the previous resource aggregation, whereas before plan aggregation occurred per SQL_ID class, now aggregation is carried out with every SQL_ID occurance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before transformation: (1000000, 31)\n",
      "Shape after transformation: (1000000, 32)\n",
      "Shape before transformation: (1456, 27)\n",
      "Shape after transformation: (1456, 28)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Adds a columns per SQL_ID, PLAN_HASH_VALUE grouping, which can be used to group instances together\n",
    "def add_grouping_column(df, column_identifier):\n",
    "    \"\"\"\n",
    "    Receives a pandas dataframe, and adds a new column which allows dataframe to be aggregated per \n",
    "    SQL_ID, PLAN_HASH_VALUE combination.\n",
    "    \n",
    "    :param: df                - Pandas Dataframe\n",
    "    :param: column_identifier - String denoting matrix column to group by\n",
    "    \n",
    "    :return: Pandas Dataframe, with added column    \n",
    "    \"\"\"\n",
    "    print('Shape before transformation: ' + str(df.shape))\n",
    "    new_grouping_col = []\n",
    "    counter = 0\n",
    "    last_sql_id = df[column_identifier].iloc(0) # Starts with first SQL_ID\n",
    "    for index, row in df.iterrows():\n",
    "        if column_identifier == 'SQL_ID':\n",
    "            if last_sql_id != row.SQL_ID:\n",
    "                last_sql_id = row.SQL_ID\n",
    "                counter += 1\n",
    "        elif column_identifier == 'PLAN_ID':\n",
    "            if last_sql_id != row.PLAN_ID:\n",
    "                last_sql_id = row.PLAN_ID\n",
    "                counter += 1\n",
    "        else:\n",
    "            raise ValueError('Column does not exist!')\n",
    "        new_grouping_col.append(counter)\n",
    "    #\n",
    "    # Append list as new column\n",
    "    new_col = pd.Series(new_grouping_col)\n",
    "    df['PLAN_INSTANCE'] = new_col.values\n",
    "    print('Shape after transformation: ' + str(df.shape))\n",
    "    return df\n",
    "#\n",
    "df = add_grouping_column(df=df,column_identifier='SQL_ID')\n",
    "df_outliers = add_grouping_column(df=df_outliers,column_identifier='PLAN_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['OPERATION', 'OPTIONS', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS',\n",
      "       'OBJECT_TYPE', 'OPTIMIZER', 'COST', 'CARDINALITY', 'IO_COST', 'TIME',\n",
      "       'QBLOCK_NAME'],\n",
      "      dtype='object')\n",
      "(15618, 12)\n",
      "------------------------------------------\n",
      "Index(['OPERATION', 'OPTIONS', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS',\n",
      "       'OBJECT_TYPE', 'OPTIMIZER', 'COST', 'CARDINALITY', 'IO_COST', 'TIME',\n",
      "       'QBLOCK_NAME'],\n",
      "      dtype='object')\n",
      "(42, 12)\n"
     ]
    }
   ],
   "source": [
    "df_agg = df.groupby(['SQL_ID','PLAN_HASH_VALUE','PLAN_INSTANCE']).mean()\n",
    "df_agg.reset_index(inplace=True)\n",
    "#\n",
    "df_outliers_agg = df_outliers.groupby(['PLAN_ID','PLAN_INSTANCE']).mean()\n",
    "df_outliers_agg.reset_index(inplace=True)\n",
    "#\n",
    "for col in df_outliers_agg.columns:\n",
    "    if col not in df_agg.columns:\n",
    "        df_outliers_agg.drop(columns=[col], inplace=True)\n",
    "for col in df_agg.columns:\n",
    "    if col not in df_outliers_agg.columns:\n",
    "        df_agg.drop(columns=[col], inplace=True)\n",
    "#\n",
    "df_agg.drop(columns=['PLAN_INSTANCE'], inplace=True)\n",
    "df_outliers_agg.drop(columns=['PLAN_INSTANCE'], inplace=True)\n",
    "#\n",
    "print(df_agg.columns)\n",
    "print(df_agg.shape)\n",
    "print('------------------------------------------')\n",
    "print(df_outliers_agg.columns)\n",
    "print(df_outliers_agg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Training (Random Forest - Per Access Plan Instance)\n",
    "\n",
    "The following section oversees the supervised training of inlier/outlier explain plans. This section first splits the training dataset into two: train + test sets, by mixing half the outliers with the inlier training set. Validation is then performed on a 50/50 mix of inlier / outlier vectors. The ability to classify explain plan vectors as inliers / outliers will be gauged.\n",
    "\n",
    "Labels are denoted as follows:\n",
    "* Inliers  - 0\n",
    "* Outliers - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.44400000e+01 7.52000000e+00 7.20000000e-01 ... 3.08312000e+03\n",
      "  8.40000000e-01 4.74400000e+01]\n",
      " [2.14761905e+01 8.76190476e+00 1.14285714e+00 ... 2.88176190e+03\n",
      "  9.04761905e-01 2.73809524e+01]\n",
      " [1.87714286e+01 1.36285714e+01 1.02857143e+00 ... 3.35257143e+03\n",
      "  8.28571429e-01 5.15428571e+01]\n",
      " ...\n",
      " [9.60000000e+00 6.20000000e+00 8.00000000e-01 ... 1.09743100e+05\n",
      "  4.90000000e+00 5.20000000e+00]\n",
      " [9.20000000e+00 4.86666667e+00 9.33333333e-01 ... 4.07773333e+03\n",
      "  9.33333333e-01 5.46666667e+00]\n",
      " [1.03043478e+01 6.82608696e+00 8.26086957e-01 ... 6.81947826e+03\n",
      "  9.56521739e-01 1.37826087e+01]]\n",
      "[0 0 0 ... 1 1 1]\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=4,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Test Accuracy: 0.9996820349761526\n",
      "Test Precision: 1.0\n",
      "Test Recall: 0.9523809523809523\n",
      "Test FScore: 0.975609756097561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_labels_outliers, df_labels = [], []\n",
    "for i in range(df_agg.shape[0]):\n",
    "    df_labels.append(0)\n",
    "for i in range(df_outliers_agg.shape[0]):\n",
    "    df_labels_outliers.append(1)\n",
    "#\n",
    "# Training / Validation Splits (Inliers + Outliers)\n",
    "X_df_train, X_df_validate, y_df_train, y_df_validate = train_test_split(df_agg, df_labels, test_size=test_split)\n",
    "X_df_outlier_train, X_df_outlier_validate, y_df_outlier_train, y_df_outlier_validate = train_test_split(df_outliers_agg, df_labels_outliers, test_size=.5)\n",
    "#\n",
    "# Mixing of Inlier + Outlier data for validation purposes\n",
    "X_df_train = np.concatenate((X_df_train.values, X_df_outlier_train.values), axis=0)\n",
    "y_df_train = np.concatenate((np.array(y_df_train), np.array(y_df_outlier_train)), axis=0)\n",
    "X_df_validate = np.concatenate((X_df_validate.values, X_df_outlier_validate.values), axis=0)\n",
    "y_df_validate = np.concatenate((np.array(y_df_validate), np.array(y_df_outlier_validate)), axis=0)\n",
    "#\n",
    "# Building Model + Training\n",
    "rfc = RandomForest(n_estimators=n_estimators,\n",
    "                   max_depth=max_depth,\n",
    "                   criterion=criterion,\n",
    "                   parallel_degree=parallel_degree)\n",
    "print(X_df_train)\n",
    "print(y_df_train)\n",
    "rfc.fit_model(X=X_df_train,\n",
    "              y=y_df_train)\n",
    "# Evaluation\n",
    "rfc.predict_and_evaluate(X=X_df_validate, \n",
    "                         y=y_df_validate,\n",
    "                         plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning (Isolation Forest - Per Access Plan Instance)\n",
    "\n",
    "The following section attempts to train a generalized version of input access plans using Isolation Forests. These trained models are then used to classify access plan outliers from inlier (normal) access plans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsolationForest(bootstrap=False, contamination=0.05, max_features=1.0,\n",
      "        max_samples=256, n_estimators=100, n_jobs=4, random_state=0,\n",
      "        verbose=0)\n",
      "[[2.00952381e+01 1.15238095e+01 1.41269841e+00 ... 1.68512698e+03\n",
      "  7.93650794e-01 6.66349206e+01]\n",
      " [2.19444444e+01 6.00000000e+00 7.77777778e-01 ... 5.97244444e+03\n",
      "  8.88888889e-01 7.82777778e+01]\n",
      " [1.87714286e+01 1.36285714e+01 1.02857143e+00 ... 3.35257143e+03\n",
      "  8.28571429e-01 5.15428571e+01]\n",
      " ...\n",
      " [1.02400000e+01 6.76000000e+00 8.40000000e-01 ... 6.15320000e+03\n",
      "  9.60000000e-01 1.42400000e+01]\n",
      " [9.30120482e+00 6.40963855e+00 1.01204819e+00 ... 2.81120482e+02\n",
      "  8.67469880e-01 9.39759036e+00]\n",
      " [9.03703704e+00 6.20370370e+00 1.03703704e+00 ... 2.56398148e+03\n",
      "  9.62962963e-01 1.34074074e+01]]\n",
      "[ 1  1  1 ... -1 -1 -1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9338632750397456\n",
      "Test Precision: 0.9952445652173914\n",
      "Test Recall: 0.9379001280409731\n",
      "Test FScore: 0.9657218193803561\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_labels_outliers, df_labels = [], []\n",
    "for i in range(df_agg.shape[0]):\n",
    "    df_labels.append(1)\n",
    "for i in range(df_outliers_agg.shape[0]):\n",
    "    df_labels_outliers.append(-1)\n",
    "#\n",
    "# Training / Validation Splits (Inliers + Outliers)\n",
    "X_df_train, X_df_validate, y_df_train, y_df_validate = train_test_split(df_agg, df_labels, test_size=test_split)\n",
    "X_df_outlier_train, X_df_outlier_validate, y_df_outlier_train, y_df_outlier_validate = train_test_split(df_outliers_agg, df_labels_outliers, test_size=.5)\n",
    "#\n",
    "# Mixing of Inlier + Outlier data for validation purposes\n",
    "X_df_train = np.concatenate((X_df_train.values, X_df_outlier_train.values), axis=0)\n",
    "y_df_train = np.concatenate((np.array(y_df_train), np.array(y_df_outlier_train)), axis=0)\n",
    "X_df_validate = np.concatenate((X_df_validate.values, X_df_outlier_validate.values), axis=0)\n",
    "y_df_validate = np.concatenate((np.array(y_df_validate), np.array(y_df_outlier_validate)), axis=0)\n",
    "#\n",
    "# Building Model + Training\n",
    "ifw = IsolationForestWrapper(contamination=contamination,\n",
    "                             parallel_degree=parallel_degree)\n",
    "print(X_df_train)\n",
    "print(y_df_train)\n",
    "ifw.fit_model(X=X_df_train)\n",
    "#\n",
    "# Evaluation\n",
    "ifw.evaluate_model(X=X_df_validate, \n",
    "                   y=y_df_validate,\n",
    "                   plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
