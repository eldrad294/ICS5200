{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schedule Access Plan Recommendation\n",
    "\n",
    "This notebook is dedicated to model fitting in terms of database access plans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 0.23.4\n",
      "numpy: 1.15.2\n",
      "sklearn: 0.19.0\n"
     ]
    }
   ],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "print('pandas: %s' % pd.__version__)\n",
    "# numpy\n",
    "import numpy as np\n",
    "print('numpy: %s' % np.__version__)\n",
    "# sklearn\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "print('sklearn: %s' % sk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Experiment Config\n",
    "tpcds='TPCDS1' # Schema upon which to operate test\n",
    "y_labels = ['COST',\n",
    "            'CARDINALITY',\n",
    "            'BYTES',\n",
    "            'CPU_COST',\n",
    "            'IO_COST',\n",
    "            'TEMP_SPACE',\n",
    "            'TIME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from file into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ('SQL_ID',) ('PLAN_HASH_VALUE',) ('ID',)    ('OPERATION',) ('OPTIONS',)  \\\n",
      "0  dxv968j0352kb            103598129       0  SELECT STATEMENT          NaN   \n",
      "1  dxv968j0352kb            103598129       1              SORT     GROUP BY   \n",
      "2  dxv968j0352kb            103598129       2    PX COORDINATOR          NaN   \n",
      "3  dxv968j0352kb            103598129       3           PX SEND  QC (RANDOM)   \n",
      "4  dxv968j0352kb            103598129       4              SORT     GROUP BY   \n",
      "\n",
      "  ('OBJECT_NODE',) ('OBJECT_OWNER',) ('OBJECT_NAME',) ('OBJECT_ALIAS',)  \\\n",
      "0              NaN               NaN              NaN               NaN   \n",
      "1              NaN               NaN              NaN               NaN   \n",
      "2              NaN               NaN              NaN               NaN   \n",
      "3           :Q1001               SYS         :TQ10001               NaN   \n",
      "4           :Q1001               NaN              NaN               NaN   \n",
      "\n",
      "  ('OBJECT_TYPE',)         ...          ('SEARCH_COLUMNS',) ('COST',)  \\\n",
      "0              NaN         ...                            0       880   \n",
      "1              NaN         ...                            0       NaN   \n",
      "2              NaN         ...                            0       NaN   \n",
      "3              NaN         ...                            0       NaN   \n",
      "4              NaN         ...                            0       NaN   \n",
      "\n",
      "  ('CARDINALITY',) ('BYTES',) ('CPU_COST',) ('IO_COST',) ('TEMP_SPACE',)  \\\n",
      "0              NaN        NaN           NaN          NaN             NaN   \n",
      "1                1         17           NaN          NaN             NaN   \n",
      "2              NaN        NaN           NaN          NaN             NaN   \n",
      "3                1         17           NaN          NaN             NaN   \n",
      "4                1         17           NaN          NaN             NaN   \n",
      "\n",
      "  ('TIME',) ('QBLOCK_NAME',)       ('TIMESTAMP',)  \n",
      "0       NaN              NaN  2018-10-07 15:52:33  \n",
      "1       NaN            SEL$1  2018-10-07 15:52:33  \n",
      "2       NaN              NaN  2018-10-07 15:52:33  \n",
      "3       NaN              NaN  2018-10-07 15:52:33  \n",
      "4       NaN              NaN  2018-10-07 15:52:33  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "------------------------------------------\n",
      "Index(['SQL_ID', 'PLAN_HASH_VALUE', 'ID', 'OPERATION', 'OPTIONS',\n",
      "       'OBJECT_NODE', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS',\n",
      "       'OBJECT_TYPE', 'OPTIMIZER', 'DEPTH', 'SEARCH_COLUMNS', 'COST',\n",
      "       'CARDINALITY', 'BYTES', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'TIME',\n",
      "       'QBLOCK_NAME', 'TIMESTAMP'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "rep_vsql_plan_path = 'C:/Users/gabriel.sammut/University/Data_ICS5200/Schedule/' + tpcds + '/v2/rep_vsql_plan.csv'\n",
    "#rep_vsql_plan_path = 'D:/Projects/Datagenerated_ICS5200/Schedule/' + tpcds + '/v2/rep_vsql_plan.csv'\n",
    "#\n",
    "rep_vsql_plan_df = pd.read_csv(rep_vsql_plan_path,dtype=str)\n",
    "print(rep_vsql_plan_df.head())\n",
    "#\n",
    "def prettify_header(headers):\n",
    "    \"\"\"\n",
    "    Cleans header list from unwated character strings\n",
    "    \"\"\"\n",
    "    header_list = []\n",
    "    [header_list.append(header.replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"\").replace(\",\",\"\")) for header in headers]\n",
    "    return header_list\n",
    "#\n",
    "rep_vsql_plan_df.columns = prettify_header(rep_vsql_plan_df.columns.values)\n",
    "print('------------------------------------------')\n",
    "print(rep_vsql_plan_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read outlier data from file into pandas dataframes and concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1456, 35)\n",
      "  PLAN_ID            TIMESTAMP REMARKS         OPERATION          OPTIONS  \\\n",
      "0   12354  11/20/2018 08:23:55     NaN  SELECT STATEMENT              NaN   \n",
      "1   12354  11/20/2018 08:23:55     NaN             COUNT          STOPKEY   \n",
      "2   12354  11/20/2018 08:23:55     NaN              VIEW              NaN   \n",
      "3   12354  11/20/2018 08:23:55     NaN              SORT  GROUP BY ROLLUP   \n",
      "4   12354  11/20/2018 08:23:55     NaN              VIEW              NaN   \n",
      "\n",
      "  OBJECT_NODE OBJECT_OWNER OBJECT_NAME                OBJECT_ALIAS  \\\n",
      "0         NaN          NaN         NaN                         NaN   \n",
      "1         NaN          NaN         NaN                         NaN   \n",
      "2         NaN       TPCDS1         NaN  from$_subquery$_018@SEL$11   \n",
      "3         NaN          NaN         NaN                         NaN   \n",
      "4         NaN       TPCDS1         NaN                    X@SEL$12   \n",
      "\n",
      "  OBJECT_INSTANCE     ...      \\\n",
      "0             NaN     ...       \n",
      "1             NaN     ...       \n",
      "2              18     ...       \n",
      "3             NaN     ...       \n",
      "4              19     ...       \n",
      "\n",
      "                                           OTHER_XML DISTRIBUTION    CPU_COST  \\\n",
      "0                                                NaN          NaN  1657360333   \n",
      "1  <other_xml><info type=\"db_version\">12.1.0.2</i...          NaN         NaN   \n",
      "2                                                NaN          NaN  1657360333   \n",
      "3                                                NaN          NaN  1657360333   \n",
      "4                                                NaN          NaN  1625075317   \n",
      "\n",
      "  IO_COST TEMP_SPACE ACCESS_PREDICATES FILTER_PREDICATES  \\\n",
      "0   13630        NaN               NaN               NaN   \n",
      "1     NaN        NaN               NaN       ROWNUM<=100   \n",
      "2   13630        NaN               NaN               NaN   \n",
      "3   13630        NaN               NaN               NaN   \n",
      "4   13630        NaN               NaN               NaN   \n",
      "\n",
      "                                          PROJECTION TIME QBLOCK_NAME  \n",
      "0                                                NaN    1         NaN  \n",
      "1  from$_subquery$_018.\"CHANNEL\"[VARCHAR2,15], \"f...  NaN      SEL$11  \n",
      "2  from$_subquery$_018.\"CHANNEL\"[VARCHAR2,15], \"f...    1      SEL$12  \n",
      "3  (#keys=2) \"CHANNEL\"[VARCHAR2,15], \"ID\"[VARCHAR...    1      SEL$12  \n",
      "4  CHANNEL[VARCHAR2,15], \"ID\"[VARCHAR2,28], \"SALE...    1       SET$4  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "------------------------------------------\n",
      "Index(['PLAN_ID', 'TIMESTAMP', 'REMARKS', 'OPERATION', 'OPTIONS',\n",
      "       'OBJECT_NODE', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS',\n",
      "       'OBJECT_INSTANCE', 'OBJECT_TYPE', 'OPTIMIZER', 'SEARCH_COLUMNS', 'ID',\n",
      "       'PARENT_ID', 'DEPTH', 'POSITION', 'COST', 'CARDINALITY', 'BYTES',\n",
      "       'OTHER_TAG', 'PARTITION_START', 'PARTITION_STOP', 'PARTITION_ID',\n",
      "       'OTHER', 'OTHER_XML', 'DISTRIBUTION', 'CPU_COST', 'IO_COST',\n",
      "       'TEMP_SPACE', 'ACCESS_PREDICATES', 'FILTER_PREDICATES', 'PROJECTION',\n",
      "       'TIME', 'QBLOCK_NAME'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# CSV Outlier Paths\n",
    "outlier_hints_q5_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_5.csv'\n",
    "outlier_hints_q10_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_10.csv'\n",
    "outlier_hints_q14_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_14.csv'\n",
    "outlier_hints_q18_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_18.csv'\n",
    "outlier_hints_q22_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_22.csv'\n",
    "outlier_hints_q27_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_27.csv'\n",
    "outlier_hints_q35_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_35.csv'\n",
    "outlier_hints_q36_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_36.csv'\n",
    "outlier_hints_q51_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_51.csv'\n",
    "outlier_hints_q67_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_67.csv'\n",
    "outlier_hints_q70_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_70.csv'\n",
    "outlier_hints_q77_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_77.csv'\n",
    "outlier_hints_q80_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_80.csv'\n",
    "outlier_hints_q86_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/hints/output/query_86.csv'\n",
    "#\n",
    "outlier_predicates_q5_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_5.csv'\n",
    "outlier_predicates_q10_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_10.csv'\n",
    "outlier_predicates_q14_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_14.csv'\n",
    "outlier_predicates_q18_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_18.csv'\n",
    "outlier_predicates_q22_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_22.csv'\n",
    "outlier_predicates_q27_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_27.csv'\n",
    "outlier_predicates_q35_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_35.csv'\n",
    "outlier_predicates_q36_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_36.csv'\n",
    "outlier_predicates_q51_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_51.csv'\n",
    "outlier_predicates_q67_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_67.csv'\n",
    "outlier_predicates_q70_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_70.csv'\n",
    "outlier_predicates_q77_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_77.csv'\n",
    "outlier_predicates_q80_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_80.csv'\n",
    "outlier_predicates_q86_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/predicates/output/query_86.csv'\n",
    "#\n",
    "outlier_rownum_q5_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_5.csv'\n",
    "outlier_rownum_q10_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_10.csv'\n",
    "outlier_rownum_q14_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_14.csv'\n",
    "outlier_rownum_q18_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_18.csv'\n",
    "outlier_rownum_q22_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_22.csv'\n",
    "outlier_rownum_q27_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_27.csv'\n",
    "outlier_rownum_q35_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_35.csv'\n",
    "outlier_rownum_q36_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_36.csv'\n",
    "outlier_rownum_q51_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_51.csv'\n",
    "outlier_rownum_q67_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_67.csv'\n",
    "outlier_rownum_q70_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_70.csv'\n",
    "outlier_rownum_q77_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_77.csv'\n",
    "outlier_rownum_q80_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_80.csv'\n",
    "outlier_rownum_q86_path = 'C:/Users/gabriel.sammut/University/ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/rownum/output/query_86.csv'\n",
    "#\n",
    "# Read CSV Paths\n",
    "outlier_hints_q5_df = pd.read_csv(outlier_hints_q5_path,dtype=str)\n",
    "outlier_hints_q10_df = pd.read_csv(outlier_hints_q10_path,dtype=str)\n",
    "outlier_hints_q14_df = pd.read_csv(outlier_hints_q14_path,dtype=str)\n",
    "outlier_hints_q18_df = pd.read_csv(outlier_hints_q18_path,dtype=str)\n",
    "outlier_hints_q22_df = pd.read_csv(outlier_hints_q22_path,dtype=str)\n",
    "outlier_hints_q27_df = pd.read_csv(outlier_hints_q27_path,dtype=str)\n",
    "outlier_hints_q35_df = pd.read_csv(outlier_hints_q35_path,dtype=str)\n",
    "outlier_hints_q36_df = pd.read_csv(outlier_hints_q36_path,dtype=str)\n",
    "outlier_hints_q51_df = pd.read_csv(outlier_hints_q51_path,dtype=str)\n",
    "outlier_hints_q67_df = pd.read_csv(outlier_hints_q67_path,dtype=str)\n",
    "outlier_hints_q70_df = pd.read_csv(outlier_hints_q70_path,dtype=str)\n",
    "outlier_hints_q77_df = pd.read_csv(outlier_hints_q77_path,dtype=str)\n",
    "outlier_hints_q80_df = pd.read_csv(outlier_hints_q80_path,dtype=str)\n",
    "outlier_hints_q86_df = pd.read_csv(outlier_hints_q86_path,dtype=str)\n",
    "#\n",
    "outlier_predicates_q5_df = pd.read_csv(outlier_predicates_q5_path,dtype=str)\n",
    "outlier_predicates_q10_df = pd.read_csv(outlier_predicates_q10_path,dtype=str)\n",
    "outlier_predicates_q14_df = pd.read_csv(outlier_predicates_q14_path,dtype=str)\n",
    "outlier_predicates_q18_df = pd.read_csv(outlier_predicates_q18_path,dtype=str)\n",
    "outlier_predicates_q22_df = pd.read_csv(outlier_predicates_q22_path,dtype=str)\n",
    "outlier_predicates_q27_df = pd.read_csv(outlier_predicates_q27_path,dtype=str)\n",
    "outlier_predicates_q35_df = pd.read_csv(outlier_predicates_q35_path,dtype=str)\n",
    "outlier_predicates_q36_df = pd.read_csv(outlier_predicates_q36_path,dtype=str)\n",
    "outlier_predicates_q51_df = pd.read_csv(outlier_predicates_q51_path,dtype=str)\n",
    "outlier_predicates_q67_df = pd.read_csv(outlier_predicates_q67_path,dtype=str)\n",
    "outlier_predicates_q70_df = pd.read_csv(outlier_predicates_q70_path,dtype=str)\n",
    "outlier_predicates_q77_df = pd.read_csv(outlier_predicates_q77_path,dtype=str)\n",
    "outlier_predicates_q80_df = pd.read_csv(outlier_predicates_q80_path,dtype=str)\n",
    "outlier_predicates_q86_df = pd.read_csv(outlier_predicates_q86_path,dtype=str)\n",
    "#\n",
    "outlier_rownum_q5_df = pd.read_csv(outlier_rownum_q5_path,dtype=str)\n",
    "outlier_rownum_q10_df = pd.read_csv(outlier_rownum_q10_path,dtype=str)\n",
    "outlier_rownum_q14_df = pd.read_csv(outlier_rownum_q14_path,dtype=str)\n",
    "outlier_rownum_q18_df = pd.read_csv(outlier_rownum_q18_path,dtype=str)\n",
    "outlier_rownum_q22_df = pd.read_csv(outlier_rownum_q22_path,dtype=str)\n",
    "outlier_rownum_q27_df = pd.read_csv(outlier_rownum_q27_path,dtype=str)\n",
    "outlier_rownum_q35_df = pd.read_csv(outlier_rownum_q35_path,dtype=str)\n",
    "outlier_rownum_q36_df = pd.read_csv(outlier_rownum_q36_path,dtype=str)\n",
    "outlier_rownum_q51_df = pd.read_csv(outlier_rownum_q51_path,dtype=str)\n",
    "outlier_rownum_q67_df = pd.read_csv(outlier_rownum_q67_path,dtype=str)\n",
    "outlier_rownum_q70_df = pd.read_csv(outlier_rownum_q70_path,dtype=str)\n",
    "outlier_rownum_q77_df = pd.read_csv(outlier_rownum_q77_path,dtype=str)\n",
    "outlier_rownum_q80_df = pd.read_csv(outlier_rownum_q80_path,dtype=str)\n",
    "outlier_rownum_q86_df = pd.read_csv(outlier_rownum_q86_path,dtype=str)\n",
    "#\n",
    "# Merge dataframes into a single pandas matrix\n",
    "df_outliers = pd.concat([outlier_hints_q5_df, outlier_hints_q10_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q14_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q18_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q22_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q27_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q35_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q36_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q51_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q67_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q70_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q77_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q80_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_hints_q86_df], sort=False)\n",
    "#\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q5_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q10_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q14_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q18_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q22_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q27_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q35_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q36_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q51_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q67_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q70_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q77_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q80_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_predicates_q86_df], sort=False)\n",
    "#\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q5_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q10_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q14_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q18_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q22_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q27_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q35_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q36_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q51_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q67_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q70_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q77_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q80_df], sort=False)\n",
    "df_outliers = pd.concat([df_outliers, outlier_rownum_q86_df], sort=False)   \n",
    "#\n",
    "print(df_outliers.shape)\n",
    "print(df_outliers.head())\n",
    "print('------------------------------------------')\n",
    "print(df_outliers.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N/A Columns\n",
      "\n",
      "\n",
      "REP_VSQL_PLAN Features 22: ['OPTIONS', 'OBJECT_NODE', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS', 'OBJECT_TYPE', 'OPTIMIZER', 'COST', 'CARDINALITY', 'BYTES', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'TIME', 'QBLOCK_NAME']\n",
      "\n",
      "\n",
      "DF_OUTLIERS Features 35: ['REMARKS', 'OPTIONS', 'OBJECT_NODE', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS', 'OBJECT_INSTANCE', 'OBJECT_TYPE', 'OPTIMIZER', 'SEARCH_COLUMNS', 'PARENT_ID', 'COST', 'CARDINALITY', 'BYTES', 'OTHER_TAG', 'PARTITION_START', 'PARTITION_STOP', 'PARTITION_ID', 'OTHER', 'OTHER_XML', 'DISTRIBUTION', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'ACCESS_PREDICATES', 'FILTER_PREDICATES', 'PROJECTION', 'TIME', 'QBLOCK_NAME']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_na_columns(df, headers):\n",
    "    \"\"\"\n",
    "    Return columns which consist of NAN values\n",
    "    \"\"\"\n",
    "    na_list = []\n",
    "    for head in headers:\n",
    "        if df[head].isnull().values.any():\n",
    "            na_list.append(head)\n",
    "    return na_list\n",
    "#\n",
    "print('N/A Columns\\n')\n",
    "print('\\nREP_VSQL_PLAN Features ' + str(len(rep_vsql_plan_df.columns)) + ': ' + str(get_na_columns(df=rep_vsql_plan_df,headers=rep_vsql_plan_df.columns)) + \"\\n\")\n",
    "print('\\nDF_OUTLIERS Features ' + str(len(df_outliers.columns)) + ': ' + str(get_na_columns(df=df_outliers,headers=df_outliers.columns)) + \"\\n\")\n",
    "#\n",
    "def fill_na(df):\n",
    "    \"\"\"\n",
    "    Replaces NA columns with 0s\n",
    "    \"\"\"\n",
    "    return df.fillna(0)\n",
    "#\n",
    "# Populating NaN values with amount '0'\n",
    "df = fill_na(df=rep_vsql_plan_df)\n",
    "df_outliers = fill_na(df=df_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "In this step, redundant features are dropped. Features are considered redundant if exhibit a standard devaition of 0 (meaning no change in value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape before changes: [(98794, 22)]\n",
      "Shape after changes: [(98794, 22)]\n",
      "Dropped a total [0]\n",
      "\n",
      "Shape before changes: [(1456, 35)]\n",
      "Shape after changes: [(1456, 27)]\n",
      "Dropped a total [8]\n",
      "\n",
      "After flatline column drop:\n",
      "(98794, 22)\n",
      "Index(['SQL_ID', 'PLAN_HASH_VALUE', 'ID', 'OPERATION', 'OPTIONS',\n",
      "       'OBJECT_NODE', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS',\n",
      "       'OBJECT_TYPE', 'OPTIMIZER', 'DEPTH', 'SEARCH_COLUMNS', 'COST',\n",
      "       'CARDINALITY', 'BYTES', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'TIME',\n",
      "       'QBLOCK_NAME', 'TIMESTAMP'],\n",
      "      dtype='object')\n",
      "--------------------------------------------------------\n",
      "\n",
      "After outlier flatline column drop:\n",
      "(1456, 27)\n",
      "Index(['PLAN_ID', 'TIMESTAMP', 'OPERATION', 'OPTIONS', 'OBJECT_OWNER',\n",
      "       'OBJECT_NAME', 'OBJECT_ALIAS', 'OBJECT_INSTANCE', 'OBJECT_TYPE',\n",
      "       'OPTIMIZER', 'SEARCH_COLUMNS', 'ID', 'PARENT_ID', 'DEPTH', 'POSITION',\n",
      "       'COST', 'CARDINALITY', 'BYTES', 'OTHER_XML', 'CPU_COST', 'IO_COST',\n",
      "       'TEMP_SPACE', 'ACCESS_PREDICATES', 'FILTER_PREDICATES', 'PROJECTION',\n",
      "       'TIME', 'QBLOCK_NAME'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def drop_flatline_columns(df):\n",
    "    columns = df.columns\n",
    "    flatline_features = []\n",
    "    for i in range(len(columns)):\n",
    "        try:\n",
    "            std = df[columns[i]].std()\n",
    "            if std == 0:\n",
    "                flatline_features.append(columns[i])\n",
    "        except:\n",
    "            pass\n",
    "    #\n",
    "    #print('Features which are considered flatline:\\n')\n",
    "    #for col in flatline_features:\n",
    "    #    print(col)\n",
    "    print('\\nShape before changes: [' + str(df.shape) + ']')\n",
    "    df = df.drop(columns=flatline_features)\n",
    "    print('Shape after changes: [' + str(df.shape) + ']')\n",
    "    print('Dropped a total [' + str(len(flatline_features)) + ']')\n",
    "    return df\n",
    "#\n",
    "df = drop_flatline_columns(df=df)\n",
    "df_outliers = drop_flatline_columns(df=df_outliers)\n",
    "#\n",
    "print('\\nAfter flatline column drop:')\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "#\n",
    "print('--------------------------------------------------------')\n",
    "print('\\nAfter outlier flatline column drop:')\n",
    "print(df_outliers.shape)\n",
    "print(df_outliers.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding\n",
    "\n",
    "Converting labels/features into numerical representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels:\n",
      "['OPERATION', 'OPTIONS', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS', 'OBJECT_TYPE', 'OPTIMIZER', 'QBLOCK_NAME']\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "          SQL_ID PLAN_HASH_VALUE ID  OPERATION  OPTIONS OBJECT_NODE  \\\n",
      "0  dxv968j0352kb       103598129  0         28        0           0   \n",
      "1  dxv968j0352kb       103598129  1         30       14           0   \n",
      "2  dxv968j0352kb       103598129  2         24        0           0   \n",
      "3  dxv968j0352kb       103598129  3         26       26      :Q1001   \n",
      "4  dxv968j0352kb       103598129  4         30       14      :Q1001   \n",
      "\n",
      "   OBJECT_OWNER  OBJECT_NAME  OBJECT_ALIAS  OBJECT_TYPE         ...           \\\n",
      "0             0            0             0            0         ...            \n",
      "1             0            0             0            0         ...            \n",
      "2             0            0             0            0         ...            \n",
      "3             1           11             0            0         ...            \n",
      "4             0            0             0            0         ...            \n",
      "\n",
      "   SEARCH_COLUMNS COST CARDINALITY BYTES CPU_COST IO_COST TEMP_SPACE TIME  \\\n",
      "0               0  880           0     0        0       0          0    0   \n",
      "1               0    0           1    17        0       0          0    0   \n",
      "2               0    0           0     0        0       0          0    0   \n",
      "3               0    0           1    17        0       0          0    0   \n",
      "4               0    0           1    17        0       0          0    0   \n",
      "\n",
      "  QBLOCK_NAME            TIMESTAMP  \n",
      "0           0  2018-10-07 15:52:33  \n",
      "1           9  2018-10-07 15:52:33  \n",
      "2           0  2018-10-07 15:52:33  \n",
      "3           0  2018-10-07 15:52:33  \n",
      "4           0  2018-10-07 15:52:33  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "Encoded labels:\n",
      "['OPERATION', 'OPTIONS', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS', 'OBJECT_TYPE', 'OPTIMIZER', 'QBLOCK_NAME']\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "  PLAN_ID            TIMESTAMP  OPERATION  OPTIONS  OBJECT_OWNER  OBJECT_NAME  \\\n",
      "0   12354  11/20/2018 08:23:55         10        0             0            0   \n",
      "1   12354  11/20/2018 08:23:55          1       21             0            0   \n",
      "2   12354  11/20/2018 08:23:55         16        0             2            0   \n",
      "3   12354  11/20/2018 08:23:55         11       10             0            0   \n",
      "4   12354  11/20/2018 08:23:55         16        0             2            0   \n",
      "\n",
      "   OBJECT_ALIAS OBJECT_INSTANCE  OBJECT_TYPE  OPTIMIZER     ...      BYTES  \\\n",
      "0             0               0            0          1     ...       6400   \n",
      "1             0               0            0          0     ...          0   \n",
      "2           114              18            0          0     ...      32448   \n",
      "3             0               0            0          0     ...      32448   \n",
      "4           104              19            0          0     ...      32448   \n",
      "\n",
      "                                           OTHER_XML    CPU_COST IO_COST  \\\n",
      "0                                                  0  1657360333   13630   \n",
      "1  <other_xml><info type=\"db_version\">12.1.0.2</i...           0       0   \n",
      "2                                                  0  1657360333   13630   \n",
      "3                                                  0  1657360333   13630   \n",
      "4                                                  0  1625075317   13630   \n",
      "\n",
      "  TEMP_SPACE ACCESS_PREDICATES FILTER_PREDICATES  \\\n",
      "0          0                 0                 0   \n",
      "1          0                 0       ROWNUM<=100   \n",
      "2          0                 0                 0   \n",
      "3          0                 0                 0   \n",
      "4          0                 0                 0   \n",
      "\n",
      "                                          PROJECTION TIME QBLOCK_NAME  \n",
      "0                                                  0    1           0  \n",
      "1  from$_subquery$_018.\"CHANNEL\"[VARCHAR2,15], \"f...    0           4  \n",
      "2  from$_subquery$_018.\"CHANNEL\"[VARCHAR2,15], \"f...    1           5  \n",
      "3  (#keys=2) \"CHANNEL\"[VARCHAR2,15], \"ID\"[VARCHAR...    1           5  \n",
      "4  CHANNEL[VARCHAR2,15], \"ID\"[VARCHAR2,28], \"SALE...    1          47  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "def encode(df, encoded_labels):\n",
    "    for col in df.columns:\n",
    "        if col in encoded_labels:\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df\n",
    "#\n",
    "# Determine labels used for encoding\n",
    "encoded_labels = ['OPERATION','OPTIONS','OBJECT_OWNER','OBJECT_NAME','OBJECT_ALIAS','OBJECT_TYPE','OPTIMIZER','QBLOCK_NAME']\n",
    "#\n",
    "df = encode(df=df, encoded_labels=encoded_labels)\n",
    "print('Encoded labels:\\n' + str(encoded_labels) + \"\\n\\n----------------------------------------------\\n\\n\")\n",
    "print(df.head())\n",
    "#\n",
    "df_outliers = encode(df=df_outliers, encoded_labels=encoded_labels)\n",
    "print('Encoded labels:\\n' + str(encoded_labels) + \"\\n\\n----------------------------------------------\\n\\n\")\n",
    "print(df_outliers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floating point precision conversion\n",
    "\n",
    "Each column is converted into a column of type values which are floating point for higher precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(98794, 22)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(1456, 27)\n"
     ]
    }
   ],
   "source": [
    "df[y_labels] = df[y_labels].astype(float)\n",
    "df[y_labels] = np.round(df[y_labels], 3) # rounds to 3 dp\n",
    "print(type(df))\n",
    "print(df.shape)\n",
    "#\n",
    "df_outliers[y_labels] = df_outliers[y_labels].astype(float)\n",
    "df_outliers[y_labels] = np.round(df_outliers[y_labels], 3) # rounds to 3 dp\n",
    "print(type(df_outliers))\n",
    "print(df_outliers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ordering\n",
    "\n",
    "Sorting of datasets in order of \n",
    "* TIMESTAMP\n",
    "* PLAN_HASH_VALUE\n",
    "* ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              SQL_ID PLAN_HASH_VALUE ID  OPERATION  OPTIONS OBJECT_NODE  \\\n",
      "0      dxv968j0352kb       103598129  0         28        0           0   \n",
      "50644  dxv968j0352kb       103598129  0         28        0           0   \n",
      "1      dxv968j0352kb       103598129  1         30       14           0   \n",
      "50645  dxv968j0352kb       103598129  1         30       14           0   \n",
      "2      dxv968j0352kb       103598129  2         24        0           0   \n",
      "\n",
      "       OBJECT_OWNER  OBJECT_NAME  OBJECT_ALIAS  OBJECT_TYPE  \\\n",
      "0                 0            0             0            0   \n",
      "50644             0            0             0            0   \n",
      "1                 0            0             0            0   \n",
      "50645             0            0             0            0   \n",
      "2                 0            0             0            0   \n",
      "\n",
      "              ...           SEARCH_COLUMNS   COST CARDINALITY  BYTES  \\\n",
      "0             ...                        0  880.0         0.0    0.0   \n",
      "50644         ...                        0  880.0         0.0    0.0   \n",
      "1             ...                        0    0.0         1.0   17.0   \n",
      "50645         ...                        0    0.0         1.0   17.0   \n",
      "2             ...                        0    0.0         0.0    0.0   \n",
      "\n",
      "       CPU_COST  IO_COST  TEMP_SPACE  TIME  QBLOCK_NAME            TIMESTAMP  \n",
      "0           0.0      0.0         0.0   0.0            0  2018-10-07 15:52:33  \n",
      "50644       0.0      0.0         0.0   0.0            0  2018-10-07 15:52:33  \n",
      "1           0.0      0.0         0.0   0.0            9  2018-10-07 15:52:33  \n",
      "50645       0.0      0.0         0.0   0.0            9  2018-10-07 15:52:33  \n",
      "2           0.0      0.0         0.0   0.0            0  2018-10-07 15:52:33  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "-------------------------------\n",
      "   PLAN_ID            TIMESTAMP  OPERATION  OPTIONS  OBJECT_OWNER  \\\n",
      "0    12354  11/20/2018 08:23:55         10        0             0   \n",
      "1    12354  11/20/2018 08:23:55          1       21             0   \n",
      "10   12354  11/20/2018 08:23:55         13        6             2   \n",
      "11   12354  11/20/2018 08:23:55         16        0             2   \n",
      "12   12354  11/20/2018 08:23:55         15        0             0   \n",
      "\n",
      "    OBJECT_NAME  OBJECT_ALIAS OBJECT_INSTANCE  OBJECT_TYPE  OPTIMIZER  \\\n",
      "0             0             0               0            0          1   \n",
      "1             0             0               0            0          0   \n",
      "10           12            29               4            3          2   \n",
      "11            0            57               1            0          0   \n",
      "12            0             0               0            0          0   \n",
      "\n",
      "       ...            BYTES  \\\n",
      "0      ...           6400.0   \n",
      "1      ...              0.0   \n",
      "10     ...            374.0   \n",
      "11     ...       63070846.0   \n",
      "12     ...              0.0   \n",
      "\n",
      "                                            OTHER_XML      CPU_COST  IO_COST  \\\n",
      "0                                                   0  1.657360e+09  13630.0   \n",
      "1   <other_xml><info type=\"db_version\">12.1.0.2</i...  0.000000e+00      0.0   \n",
      "10                                                  0  2.916955e+07    375.0   \n",
      "11                                                  0  2.174856e+09  12289.0   \n",
      "12                                                  0  0.000000e+00      0.0   \n",
      "\n",
      "   TEMP_SPACE  ACCESS_PREDICATES  \\\n",
      "0         0.0                  0   \n",
      "1         0.0                  0   \n",
      "10        0.0                  0   \n",
      "11        0.0                  0   \n",
      "12        0.0                  0   \n",
      "\n",
      "                                  FILTER_PREDICATES  \\\n",
      "0                                                 0   \n",
      "1                                       ROWNUM<=100   \n",
      "10  D_DATE>='2000-08-19' AND \"D_DATE\"<='2000-09-02'   \n",
      "11                                                0   \n",
      "12                                                0   \n",
      "\n",
      "                                           PROJECTION TIME  QBLOCK_NAME  \n",
      "0                                                   0  1.0            0  \n",
      "1   from$_subquery$_018.\"CHANNEL\"[VARCHAR2,15], \"f...  0.0            4  \n",
      "10  (rowset=200) \"D_DATE_SK\"[NUMBER,22], \"D_DATE\"[...  1.0           37  \n",
      "11  STORE_SK[NUMBER,22], \"DATE_SK\"[NUMBER,22], \"SA...  1.0           44  \n",
      "12  STRDEF[22], STRDEF[22], STRDEF[22], STRDEF[22]...  0.0           44  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "df.sort_values(by=['TIMESTAMP','PLAN_HASH_VALUE','ID'], ascending=True, inplace=True)\n",
    "print(df.head())\n",
    "print('-------------------------------')\n",
    "df_outliers.sort_values(by=['TIMESTAMP','PLAN_ID','ID'], ascending=True, inplace=True)\n",
    "print(df_outliers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Plan Resource Aggregation\n",
    "\n",
    "This method attempts to tackle the problem of access plan anomolies by aggregating resources per explain plan. Notable resources which are being considered are as follows:\n",
    "\n",
    "* COST\n",
    "* CARDINALITY\n",
    "* BYTES\n",
    "* PARTITION_DELTA (Partition End - Partition Start)\n",
    "* CPU_COST\n",
    "* IO_COST\n",
    "* TEMP_SPACE\n",
    "* TIME\n",
    "\n",
    "The reasoning behind these fields in particular is mainly because these columns can be aggregated together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98794, 22)\n",
      "Index(['SQL_ID', 'PLAN_HASH_VALUE', 'OPERATION', 'OPTIONS', 'OBJECT_OWNER',\n",
      "       'OBJECT_NAME', 'OBJECT_ALIAS', 'OBJECT_TYPE', 'OPTIMIZER', 'COST',\n",
      "       'CARDINALITY', 'BYTES', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'TIME',\n",
      "       'QBLOCK_NAME'],\n",
      "      dtype='object')\n",
      "(270, 17)\n",
      "(1456, 27)\n",
      "Index(['PLAN_ID', 'OPERATION', 'OPTIONS', 'OBJECT_OWNER', 'OBJECT_NAME',\n",
      "       'OBJECT_ALIAS', 'OBJECT_TYPE', 'OPTIMIZER', 'COST', 'CARDINALITY',\n",
      "       'BYTES', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'TIME', 'QBLOCK_NAME'],\n",
      "      dtype='object')\n",
      "(42, 16)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df.groupby(['SQL_ID','PLAN_HASH_VALUE']).sum()\n",
    "df.reset_index(inplace=True)\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "#\n",
    "print(df_outliers.shape)\n",
    "df_outliers = df_outliers.groupby(['PLAN_ID']).sum()\n",
    "df_outliers.reset_index(inplace=True)\n",
    "print(df_outliers.columns)\n",
    "print(df_outliers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Reduction\n",
    "\n",
    "Strips further columns unneccessary to the experiment, so as to have the same columns for both training data set and outlier set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['OPERATION', 'OPTIONS', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS',\n",
      "       'OBJECT_TYPE', 'OPTIMIZER', 'COST', 'CARDINALITY', 'BYTES', 'CPU_COST',\n",
      "       'IO_COST', 'TEMP_SPACE', 'TIME', 'QBLOCK_NAME'],\n",
      "      dtype='object')\n",
      "(270, 15)\n",
      "------------------------------------------\n",
      "Index(['OPERATION', 'OPTIONS', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS',\n",
      "       'OBJECT_TYPE', 'OPTIMIZER', 'COST', 'CARDINALITY', 'BYTES', 'CPU_COST',\n",
      "       'IO_COST', 'TEMP_SPACE', 'TIME', 'QBLOCK_NAME'],\n",
      "      dtype='object')\n",
      "(42, 15)\n"
     ]
    }
   ],
   "source": [
    "for col in df_outliers.columns:\n",
    "    if col not in df.columns:\n",
    "        df_outliers.drop(columns=[col], inplace=True)\n",
    "for col in df.columns:\n",
    "    if col not in df_outliers.columns:\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "#\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "print('------------------------------------------')\n",
    "print(df_outliers.columns)\n",
    "print(df_outliers.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
