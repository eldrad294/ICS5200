{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schedule TPC-DS1 Statistical Recommendation Evaluation\n",
    "\n",
    "This experiment is intended at quantifying the statistical recommendation technique, through comparison of two query streams. The query streams are denoted as follows:\n",
    "\n",
    "* Expected Stream - Denotes a sequence of baseline query plans, against which comparison will be made.\n",
    "* Variation Stream - Denotes a sequence of upcoming query plans. Queries found within the upcoming stream mirror those established in the Expected Stream, with a number of exceptions. These exceptions are considered as query variants, and contain a degree of change from the original queries taken from the prior stream.\n",
    "\n",
    "Query variants are denoted below, and are therefore eligable to be flagged during the evaluation phase:\n",
    "\n",
    "* Query 5  \n",
    "* Query 10\n",
    "* Query 14\n",
    "* Query 18\n",
    "* Query 22\n",
    "* Query 27\n",
    "* Query 35\n",
    "* Query 36\n",
    "* Query 51\n",
    "* Query 67\n",
    "* Query 70\n",
    "* Query 77\n",
    "* Query 80\n",
    "* Query 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 0.23.4\n",
      "numpy: 1.15.4\n"
     ]
    }
   ],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "print('pandas: %s' % pd.__version__)\n",
    "# numpy\n",
    "import numpy as np\n",
    "print('numpy: %s' % np.__version__)\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# sklearn\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "# AnyTree\n",
    "from anytree import Node, RenderTree, PostOrderIter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Cell\n",
    "\n",
    "Tweak parametric changes from this cell to influence outcome of experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Config\n",
    "tpcds='TPCDS1' # Schema upon which to operate test\n",
    "test_split=.2\n",
    "y_labels = ['COST',\n",
    "            'CARDINALITY',\n",
    "            'BYTES',\n",
    "            'CPU_COST',\n",
    "            'IO_COST',\n",
    "            'TEMP_SPACE',\n",
    "            'TIME']\n",
    "black_list = ['TIMESTAMP',\n",
    "              'SQL_ID',\n",
    "              'OPERATION',\n",
    "              'OPTIONS',\n",
    "              'OBJECT_NAME',\n",
    "              'OBJECT_OWNER',\n",
    "              'PARTITION_STOP',\n",
    "              'PARTITION_START'] # Columns which will be ignored during type conversion, and later used for aggregation\n",
    "nrows = 10000\n",
    "variant_ids = (5, 10, 14, 18, 22, 27, 35, 36, 51, 67, 70, 77, 80, 86)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from file into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ('DBID',)    ('SQL_ID',)  ('PLAN_HASH_VALUE',)  ('ID',)    ('OPERATION',)  \\\n",
      "0  2634225673  dxv968j0352kb             103598129        0  SELECT STATEMENT   \n",
      "1  2634225673  dxv968j0352kb             103598129        1              SORT   \n",
      "2  2634225673  dxv968j0352kb             103598129        2    PX COORDINATOR   \n",
      "3  2634225673  dxv968j0352kb             103598129        3           PX SEND   \n",
      "4  2634225673  dxv968j0352kb             103598129        4              SORT   \n",
      "\n",
      "  ('OPTIONS',) ('OBJECT_NODE',)  ('OBJECT#',) ('OBJECT_OWNER',)  \\\n",
      "0          NaN              NaN           NaN               NaN   \n",
      "1     GROUP BY              NaN           NaN               NaN   \n",
      "2          NaN              NaN           NaN               NaN   \n",
      "3  QC (RANDOM)           :Q1001           NaN               SYS   \n",
      "4     GROUP BY           :Q1001           NaN               NaN   \n",
      "\n",
      "  ('OBJECT_NAME',)     ...     ('ACCESS_PREDICATES',) ('FILTER_PREDICATES',)  \\\n",
      "0              NaN     ...                        NaN                    NaN   \n",
      "1              NaN     ...                        NaN                    NaN   \n",
      "2              NaN     ...                        NaN                    NaN   \n",
      "3         :TQ10001     ...                        NaN                    NaN   \n",
      "4              NaN     ...                        NaN                    NaN   \n",
      "\n",
      "  ('PROJECTION',)  ('TIME',)  ('QBLOCK_NAME',)  ('REMARKS',)  \\\n",
      "0             NaN        NaN               NaN           NaN   \n",
      "1             NaN        NaN             SEL$1           NaN   \n",
      "2             NaN        NaN               NaN           NaN   \n",
      "3             NaN        NaN               NaN           NaN   \n",
      "4             NaN        NaN               NaN           NaN   \n",
      "\n",
      "        ('TIMESTAMP',)                                     ('OTHER_XML',)  \\\n",
      "0  2018-10-07 15:52:33                                                NaN   \n",
      "1  2018-10-07 15:52:33  <other_xml><info type=\"db_version\">12.1.0.2</i...   \n",
      "2  2018-10-07 15:52:33                                                NaN   \n",
      "3  2018-10-07 15:52:33                                                NaN   \n",
      "4  2018-10-07 15:52:33                                                NaN   \n",
      "\n",
      "   ('CON_DBID',) ('CON_ID',)  \n",
      "0     2634225673           0  \n",
      "1     2634225673           0  \n",
      "2     2634225673           0  \n",
      "3     2634225673           0  \n",
      "4     2634225673           0  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "------------------------------------------\n",
      "Index(['DBID', 'SQL_ID', 'PLAN_HASH_VALUE', 'ID', 'OPERATION', 'OPTIONS',\n",
      "       'OBJECT_NODE', 'OBJECT#', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS',\n",
      "       'OBJECT_TYPE', 'OPTIMIZER', 'PARENT_ID', 'DEPTH', 'POSITION',\n",
      "       'SEARCH_COLUMNS', 'COST', 'CARDINALITY', 'BYTES', 'OTHER_TAG',\n",
      "       'PARTITION_START', 'PARTITION_STOP', 'PARTITION_ID', 'OTHER',\n",
      "       'DISTRIBUTION', 'CPU_COST', 'IO_COST', 'TEMP_SPACE',\n",
      "       'ACCESS_PREDICATES', 'FILTER_PREDICATES', 'PROJECTION', 'TIME',\n",
      "       'QBLOCK_NAME', 'REMARKS', 'TIMESTAMP', 'OTHER_XML', 'CON_DBID',\n",
      "       'CON_ID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Root path\n",
    "#base_dir = 'C:/Users/gabriel.sammut/University/'\n",
    "base_dir = 'D:/Projects/'\n",
    "root_dir = base_dir + 'Datagenerated_ICS5200/Schedule/' + tpcds\n",
    "src_dir = base_dir + 'ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/'\n",
    "\n",
    "rep_vsql_plan_path = root_dir + '/rep_vsql_plan.csv'\n",
    "#rep_vsql_plan_path = root_dir + '/rep_vsql_plan.csv'\n",
    "\n",
    "dtype={'COST':'int64',\n",
    "       'CARDINALITY':'int64',\n",
    "       'BYTES':'int64',\n",
    "       'CPU_COST':'int64',\n",
    "       'IO_COST':'int64',\n",
    "       'TEMP_SPACE':'int64',\n",
    "       'TIME':'int64',\n",
    "       'OPERATION':'str',\n",
    "       'OBJECT_NAME':'str'}\n",
    "rep_vsql_plan_df = pd.read_csv(rep_vsql_plan_path, nrows=nrows, dtype=dtype)\n",
    "print(rep_vsql_plan_df.head())\n",
    "\n",
    "def prettify_header(headers):\n",
    "    \"\"\"\n",
    "    Cleans header list from unwated character strings\n",
    "    \"\"\"\n",
    "    header_list = []\n",
    "    [header_list.append(header.replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"\").replace(\",\",\"\")) for header in headers]\n",
    "    return header_list\n",
    "\n",
    "rep_vsql_plan_df.columns = prettify_header(rep_vsql_plan_df.columns.values)\n",
    "print('------------------------------------------')\n",
    "print(rep_vsql_plan_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read outlier data from file into pandas dataframes and concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(465, 35)\n",
      "  PLAN_ID            TIMESTAMP REMARKS         OPERATION          OPTIONS  \\\n",
      "0   12354  11/20/2018 08:23:55     NaN  SELECT STATEMENT              NaN   \n",
      "1   12354  11/20/2018 08:23:55     NaN             COUNT          STOPKEY   \n",
      "2   12354  11/20/2018 08:23:55     NaN              VIEW              NaN   \n",
      "3   12354  11/20/2018 08:23:55     NaN              SORT  GROUP BY ROLLUP   \n",
      "4   12354  11/20/2018 08:23:55     NaN              VIEW              NaN   \n",
      "\n",
      "  OBJECT_NODE OBJECT_OWNER OBJECT_NAME                OBJECT_ALIAS  \\\n",
      "0         NaN          NaN         NaN                         NaN   \n",
      "1         NaN          NaN         NaN                         NaN   \n",
      "2         NaN       TPCDS1         NaN  from$_subquery$_018@SEL$11   \n",
      "3         NaN          NaN         NaN                         NaN   \n",
      "4         NaN       TPCDS1         NaN                    X@SEL$12   \n",
      "\n",
      "  OBJECT_INSTANCE     ...      \\\n",
      "0             NaN     ...       \n",
      "1             NaN     ...       \n",
      "2              18     ...       \n",
      "3             NaN     ...       \n",
      "4              19     ...       \n",
      "\n",
      "                                           OTHER_XML DISTRIBUTION    CPU_COST  \\\n",
      "0                                                NaN          NaN  1657360333   \n",
      "1  <other_xml><info type=\"db_version\">12.1.0.2</i...          NaN         NaN   \n",
      "2                                                NaN          NaN  1657360333   \n",
      "3                                                NaN          NaN  1657360333   \n",
      "4                                                NaN          NaN  1625075317   \n",
      "\n",
      "  IO_COST TEMP_SPACE ACCESS_PREDICATES FILTER_PREDICATES  \\\n",
      "0   13630        NaN               NaN               NaN   \n",
      "1     NaN        NaN               NaN       ROWNUM<=100   \n",
      "2   13630        NaN               NaN               NaN   \n",
      "3   13630        NaN               NaN               NaN   \n",
      "4   13630        NaN               NaN               NaN   \n",
      "\n",
      "                                          PROJECTION TIME QBLOCK_NAME  \n",
      "0                                                NaN    1         NaN  \n",
      "1  from$_subquery$_018.\"CHANNEL\"[VARCHAR2,15], \"f...  NaN      SEL$11  \n",
      "2  from$_subquery$_018.\"CHANNEL\"[VARCHAR2,15], \"f...    1      SEL$12  \n",
      "3  (#keys=2) \"CHANNEL\"[VARCHAR2,15], \"ID\"[VARCHAR...    1      SEL$12  \n",
      "4  CHANNEL[VARCHAR2,15], \"ID\"[VARCHAR2,28], \"SALE...    1       SET$4  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "------------------------------------------\n",
      "(491, 35)\n",
      "  PLAN_ID            TIMESTAMP REMARKS         OPERATION          OPTIONS  \\\n",
      "0   12372  11/20/2018 08:40:58     NaN  SELECT STATEMENT              NaN   \n",
      "1   12372  11/20/2018 08:40:58     NaN             COUNT          STOPKEY   \n",
      "2   12372  11/20/2018 08:40:58     NaN              VIEW              NaN   \n",
      "3   12372  11/20/2018 08:40:58     NaN              SORT  GROUP BY ROLLUP   \n",
      "4   12372  11/20/2018 08:40:58     NaN              VIEW              NaN   \n",
      "\n",
      "  OBJECT_NODE OBJECT_OWNER OBJECT_NAME                OBJECT_ALIAS  \\\n",
      "0         NaN          NaN         NaN                         NaN   \n",
      "1         NaN          NaN         NaN                         NaN   \n",
      "2         NaN       TPCDS1         NaN  from$_subquery$_018@SEL$11   \n",
      "3         NaN          NaN         NaN                         NaN   \n",
      "4         NaN       TPCDS1         NaN                    X@SEL$12   \n",
      "\n",
      "  OBJECT_INSTANCE     ...      \\\n",
      "0             NaN     ...       \n",
      "1             NaN     ...       \n",
      "2              18     ...       \n",
      "3             NaN     ...       \n",
      "4              19     ...       \n",
      "\n",
      "                                           OTHER_XML DISTRIBUTION   CPU_COST  \\\n",
      "0                                                NaN          NaN  242094911   \n",
      "1  <other_xml><info type=\"db_version\">12.1.0.2</i...          NaN        NaN   \n",
      "2                                                NaN          NaN  242094911   \n",
      "3                                                NaN          NaN  242094911   \n",
      "4                                                NaN          NaN  209150318   \n",
      "\n",
      "  IO_COST TEMP_SPACE ACCESS_PREDICATES FILTER_PREDICATES  \\\n",
      "0    2549        NaN               NaN               NaN   \n",
      "1     NaN        NaN               NaN       ROWNUM<=100   \n",
      "2    2549        NaN               NaN               NaN   \n",
      "3    2549        NaN               NaN               NaN   \n",
      "4    2549        NaN               NaN               NaN   \n",
      "\n",
      "                                          PROJECTION TIME QBLOCK_NAME  \n",
      "0                                                NaN    1         NaN  \n",
      "1  from$_subquery$_018.\"CHANNEL\"[VARCHAR2,15], \"f...  NaN      SEL$11  \n",
      "2  from$_subquery$_018.\"CHANNEL\"[VARCHAR2,15], \"f...    1      SEL$12  \n",
      "3  (#keys=2) \"CHANNEL\"[VARCHAR2,15], \"ID\"[VARCHAR...    1      SEL$12  \n",
      "4  CHANNEL[VARCHAR2,15], \"ID\"[VARCHAR2,28], \"SALE...    1       SET$4  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "------------------------------------------\n",
      "(500, 35)\n",
      "  PLAN_ID            TIMESTAMP REMARKS         OPERATION          OPTIONS  \\\n",
      "0   12386  11/20/2018 08:52:27     NaN  SELECT STATEMENT              NaN   \n",
      "1   12386  11/20/2018 08:52:27     NaN             COUNT          STOPKEY   \n",
      "2   12386  11/20/2018 08:52:27     NaN              VIEW              NaN   \n",
      "3   12386  11/20/2018 08:52:27     NaN              SORT  GROUP BY ROLLUP   \n",
      "4   12386  11/20/2018 08:52:27     NaN              VIEW              NaN   \n",
      "\n",
      "  OBJECT_NODE OBJECT_OWNER OBJECT_NAME                OBJECT_ALIAS  \\\n",
      "0         NaN          NaN         NaN                         NaN   \n",
      "1         NaN          NaN         NaN                         NaN   \n",
      "2         NaN       TPCDS1         NaN  from$_subquery$_018@SEL$11   \n",
      "3         NaN          NaN         NaN                         NaN   \n",
      "4         NaN       TPCDS1         NaN                    X@SEL$12   \n",
      "\n",
      "  OBJECT_INSTANCE     ...      \\\n",
      "0             NaN     ...       \n",
      "1             NaN     ...       \n",
      "2              18     ...       \n",
      "3             NaN     ...       \n",
      "4              19     ...       \n",
      "\n",
      "                                           OTHER_XML DISTRIBUTION   CPU_COST  \\\n",
      "0                                                NaN          NaN  226837615   \n",
      "1  <other_xml><info type=\"db_version\">12.1.0.2</i...          NaN        NaN   \n",
      "2                                                NaN          NaN  226837615   \n",
      "3                                                NaN          NaN  226837615   \n",
      "4                                                NaN          NaN  194552599   \n",
      "\n",
      "  IO_COST TEMP_SPACE ACCESS_PREDICATES FILTER_PREDICATES  \\\n",
      "0    1563        NaN               NaN               NaN   \n",
      "1     NaN        NaN               NaN     ROWNUM<=10000   \n",
      "2    1563        NaN               NaN               NaN   \n",
      "3    1563        NaN               NaN               NaN   \n",
      "4    1563        NaN               NaN               NaN   \n",
      "\n",
      "                                          PROJECTION TIME QBLOCK_NAME  \n",
      "0                                                NaN    1         NaN  \n",
      "1  from$_subquery$_018.\"CHANNEL\"[VARCHAR2,15], \"f...  NaN      SEL$11  \n",
      "2  from$_subquery$_018.\"CHANNEL\"[VARCHAR2,15], \"f...    1      SEL$12  \n",
      "3  (#keys=2) \"CHANNEL\"[VARCHAR2,15], \"ID\"[VARCHAR...    1      SEL$12  \n",
      "4  CHANNEL[VARCHAR2,15], \"ID\"[VARCHAR2,28], \"SALE...    1       SET$4  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# CSV Outlier Paths\n",
    "outlier_hints_q5_path = src_dir + 'hints/output/query_5.csv'\n",
    "outlier_hints_q10_path = src_dir + 'hints/output/query_10.csv'\n",
    "outlier_hints_q14_path = src_dir + 'hints/output/query_14.csv'\n",
    "outlier_hints_q18_path = src_dir + 'hints/output/query_18.csv'\n",
    "outlier_hints_q22_path = src_dir + 'hints/output/query_22.csv'\n",
    "outlier_hints_q27_path = src_dir + 'hints/output/query_27.csv'\n",
    "outlier_hints_q35_path = src_dir + 'hints/output/query_35.csv'\n",
    "outlier_hints_q36_path = src_dir + 'hints/output/query_36.csv'\n",
    "outlier_hints_q51_path = src_dir + 'hints/output/query_51.csv'\n",
    "outlier_hints_q67_path = src_dir + 'hints/output/query_67.csv'\n",
    "outlier_hints_q70_path = src_dir + 'hints/output/query_70.csv'\n",
    "outlier_hints_q77_path = src_dir + 'hints/output/query_77.csv'\n",
    "outlier_hints_q80_path = src_dir + 'hints/output/query_80.csv'\n",
    "outlier_hints_q86_path = src_dir + 'hints/output/query_86.csv'\n",
    "\n",
    "outlier_predicates_q5_path = src_dir + 'predicates/output/query_5.csv'\n",
    "outlier_predicates_q10_path = src_dir + 'predicates/output/query_10.csv'\n",
    "outlier_predicates_q14_path = src_dir + 'predicates/output/query_14.csv'\n",
    "outlier_predicates_q18_path = src_dir + 'predicates/output/query_18.csv'\n",
    "outlier_predicates_q22_path = src_dir + 'predicates/output/query_22.csv'\n",
    "outlier_predicates_q27_path = src_dir + 'predicates/output/query_27.csv'\n",
    "outlier_predicates_q35_path = src_dir + 'predicates/output/query_35.csv'\n",
    "outlier_predicates_q36_path = src_dir + 'predicates/output/query_36.csv'\n",
    "outlier_predicates_q51_path = src_dir + 'predicates/output/query_51.csv'\n",
    "outlier_predicates_q67_path = src_dir + 'predicates/output/query_67.csv'\n",
    "outlier_predicates_q70_path = src_dir + 'predicates/output/query_70.csv'\n",
    "outlier_predicates_q77_path = src_dir + 'predicates/output/query_77.csv'\n",
    "outlier_predicates_q80_path = src_dir + 'predicates/output/query_80.csv'\n",
    "outlier_predicates_q86_path = src_dir + 'predicates/output/query_86.csv'\n",
    "\n",
    "outlier_rownum_q5_path = src_dir + 'rownum/output/query_5.csv'\n",
    "outlier_rownum_q10_path = src_dir + 'rownum/output/query_10.csv'\n",
    "outlier_rownum_q14_path = src_dir + 'rownum/output/query_14.csv'\n",
    "outlier_rownum_q18_path = src_dir + 'rownum/output/query_18.csv'\n",
    "outlier_rownum_q22_path = src_dir + 'rownum/output/query_22.csv'\n",
    "outlier_rownum_q27_path = src_dir + 'rownum/output/query_27.csv'\n",
    "outlier_rownum_q35_path = src_dir + 'rownum/output/query_35.csv'\n",
    "outlier_rownum_q36_path = src_dir + 'rownum/output/query_36.csv'\n",
    "outlier_rownum_q51_path = src_dir + 'rownum/output/query_51.csv'\n",
    "outlier_rownum_q67_path = src_dir + 'rownum/output/query_67.csv'\n",
    "outlier_rownum_q70_path = src_dir + 'rownum/output/query_70.csv'\n",
    "outlier_rownum_q77_path = src_dir + 'rownum/output/query_77.csv'\n",
    "outlier_rownum_q80_path = src_dir + 'rownum/output/query_80.csv'\n",
    "outlier_rownum_q86_path = src_dir + 'rownum/output/query_86.csv'\n",
    "\n",
    "# Read CSV Paths\n",
    "outlier_hints_q5_df = pd.read_csv(outlier_hints_q5_path,dtype=str)\n",
    "outlier_hints_q10_df = pd.read_csv(outlier_hints_q10_path,dtype=str)\n",
    "outlier_hints_q14_df = pd.read_csv(outlier_hints_q14_path,dtype=str)\n",
    "outlier_hints_q18_df = pd.read_csv(outlier_hints_q18_path,dtype=str)\n",
    "outlier_hints_q22_df = pd.read_csv(outlier_hints_q22_path,dtype=str)\n",
    "outlier_hints_q27_df = pd.read_csv(outlier_hints_q27_path,dtype=str)\n",
    "outlier_hints_q35_df = pd.read_csv(outlier_hints_q35_path,dtype=str)\n",
    "outlier_hints_q36_df = pd.read_csv(outlier_hints_q36_path,dtype=str)\n",
    "outlier_hints_q51_df = pd.read_csv(outlier_hints_q51_path,dtype=str)\n",
    "outlier_hints_q67_df = pd.read_csv(outlier_hints_q67_path,dtype=str)\n",
    "outlier_hints_q70_df = pd.read_csv(outlier_hints_q70_path,dtype=str)\n",
    "outlier_hints_q77_df = pd.read_csv(outlier_hints_q77_path,dtype=str)\n",
    "outlier_hints_q80_df = pd.read_csv(outlier_hints_q80_path,dtype=str)\n",
    "outlier_hints_q86_df = pd.read_csv(outlier_hints_q86_path,dtype=str)\n",
    "\n",
    "outlier_predicates_q5_df = pd.read_csv(outlier_predicates_q5_path,dtype=str)\n",
    "outlier_predicates_q10_df = pd.read_csv(outlier_predicates_q10_path,dtype=str)\n",
    "outlier_predicates_q14_df = pd.read_csv(outlier_predicates_q14_path,dtype=str)\n",
    "outlier_predicates_q18_df = pd.read_csv(outlier_predicates_q18_path,dtype=str)\n",
    "outlier_predicates_q22_df = pd.read_csv(outlier_predicates_q22_path,dtype=str)\n",
    "outlier_predicates_q27_df = pd.read_csv(outlier_predicates_q27_path,dtype=str)\n",
    "outlier_predicates_q35_df = pd.read_csv(outlier_predicates_q35_path,dtype=str)\n",
    "outlier_predicates_q36_df = pd.read_csv(outlier_predicates_q36_path,dtype=str)\n",
    "outlier_predicates_q51_df = pd.read_csv(outlier_predicates_q51_path,dtype=str)\n",
    "outlier_predicates_q67_df = pd.read_csv(outlier_predicates_q67_path,dtype=str)\n",
    "outlier_predicates_q70_df = pd.read_csv(outlier_predicates_q70_path,dtype=str)\n",
    "outlier_predicates_q77_df = pd.read_csv(outlier_predicates_q77_path,dtype=str)\n",
    "outlier_predicates_q80_df = pd.read_csv(outlier_predicates_q80_path,dtype=str)\n",
    "outlier_predicates_q86_df = pd.read_csv(outlier_predicates_q86_path,dtype=str)\n",
    "\n",
    "outlier_rownum_q5_df = pd.read_csv(outlier_rownum_q5_path,dtype=str)\n",
    "outlier_rownum_q10_df = pd.read_csv(outlier_rownum_q10_path,dtype=str)\n",
    "outlier_rownum_q14_df = pd.read_csv(outlier_rownum_q14_path,dtype=str)\n",
    "outlier_rownum_q18_df = pd.read_csv(outlier_rownum_q18_path,dtype=str)\n",
    "outlier_rownum_q22_df = pd.read_csv(outlier_rownum_q22_path,dtype=str)\n",
    "outlier_rownum_q27_df = pd.read_csv(outlier_rownum_q27_path,dtype=str)\n",
    "outlier_rownum_q35_df = pd.read_csv(outlier_rownum_q35_path,dtype=str)\n",
    "outlier_rownum_q36_df = pd.read_csv(outlier_rownum_q36_path,dtype=str)\n",
    "outlier_rownum_q51_df = pd.read_csv(outlier_rownum_q51_path,dtype=str)\n",
    "outlier_rownum_q67_df = pd.read_csv(outlier_rownum_q67_path,dtype=str)\n",
    "outlier_rownum_q70_df = pd.read_csv(outlier_rownum_q70_path,dtype=str)\n",
    "outlier_rownum_q77_df = pd.read_csv(outlier_rownum_q77_path,dtype=str)\n",
    "outlier_rownum_q80_df = pd.read_csv(outlier_rownum_q80_path,dtype=str)\n",
    "outlier_rownum_q86_df = pd.read_csv(outlier_rownum_q86_path,dtype=str)\n",
    "\n",
    "# Merge dataframes into a single pandas matrix\n",
    "df_hints_outliers = pd.concat([outlier_hints_q5_df, outlier_hints_q10_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q14_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q18_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q22_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q27_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q35_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q36_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q51_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q67_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q70_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q77_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q80_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q86_df], sort=False)\n",
    "\n",
    "df_predicate_outliers = pd.concat([outlier_predicates_q5_df, outlier_predicates_q10_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q14_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q18_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q22_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q27_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q35_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q36_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q51_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q67_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q70_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q77_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q80_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q86_df], sort=False)\n",
    "\n",
    "df_rownum_outliers = pd.concat([outlier_rownum_q5_df, outlier_rownum_q10_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q14_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q18_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q22_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q27_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q35_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q36_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q51_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q67_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q70_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q77_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q80_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q86_df], sort=False)\n",
    "\n",
    "print(df_hints_outliers.shape)\n",
    "print(df_hints_outliers.head())\n",
    "print('------------------------------------------')\n",
    "print(df_predicate_outliers.shape)\n",
    "print(df_predicate_outliers.head())\n",
    "print('------------------------------------------')\n",
    "print(df_rownum_outliers.shape)\n",
    "print(df_rownum_outliers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N/A Columns\n",
      "\n",
      "\n",
      "REP_VSQL_PLAN Features 39: ['OPTIONS', 'OBJECT_NODE', 'OBJECT#', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS', 'OBJECT_TYPE', 'OPTIMIZER', 'PARENT_ID', 'COST', 'CARDINALITY', 'OTHER_TAG', 'PARTITION_START', 'PARTITION_STOP', 'PARTITION_ID', 'OTHER', 'DISTRIBUTION', 'IO_COST', 'ACCESS_PREDICATES', 'FILTER_PREDICATES', 'PROJECTION', 'TIME', 'QBLOCK_NAME', 'REMARKS', 'OTHER_XML']\n",
      "\n",
      "\n",
      "DF_HINT_OUTLIERS Features 35: ['REMARKS', 'OPTIONS', 'OBJECT_NODE', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS', 'OBJECT_INSTANCE', 'OBJECT_TYPE', 'OPTIMIZER', 'SEARCH_COLUMNS', 'PARENT_ID', 'COST', 'CARDINALITY', 'BYTES', 'OTHER_TAG', 'PARTITION_START', 'PARTITION_STOP', 'PARTITION_ID', 'OTHER', 'OTHER_XML', 'DISTRIBUTION', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'ACCESS_PREDICATES', 'FILTER_PREDICATES', 'PROJECTION', 'TIME', 'QBLOCK_NAME']\n",
      "\n",
      "\n",
      "DF_PREDICATE_OUTLIERS Features 35: ['REMARKS', 'OPTIONS', 'OBJECT_NODE', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS', 'OBJECT_INSTANCE', 'OBJECT_TYPE', 'OPTIMIZER', 'SEARCH_COLUMNS', 'PARENT_ID', 'COST', 'CARDINALITY', 'BYTES', 'OTHER_TAG', 'PARTITION_START', 'PARTITION_STOP', 'PARTITION_ID', 'OTHER', 'OTHER_XML', 'DISTRIBUTION', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'ACCESS_PREDICATES', 'FILTER_PREDICATES', 'PROJECTION', 'TIME', 'QBLOCK_NAME']\n",
      "\n",
      "\n",
      "DF_ROWNUM_OUTLIERS Features 35: ['REMARKS', 'OPTIONS', 'OBJECT_NODE', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS', 'OBJECT_INSTANCE', 'OBJECT_TYPE', 'OPTIMIZER', 'SEARCH_COLUMNS', 'PARENT_ID', 'COST', 'CARDINALITY', 'BYTES', 'OTHER_TAG', 'PARTITION_START', 'PARTITION_STOP', 'PARTITION_ID', 'OTHER', 'OTHER_XML', 'DISTRIBUTION', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'ACCESS_PREDICATES', 'FILTER_PREDICATES', 'PROJECTION', 'TIME', 'QBLOCK_NAME']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_na_columns(df, headers):\n",
    "    \"\"\"\n",
    "    Return columns which consist of NAN values\n",
    "    \"\"\"\n",
    "    na_list = []\n",
    "    for head in headers:\n",
    "        if df[head].isnull().values.any():\n",
    "            na_list.append(head)\n",
    "    return na_list\n",
    "\n",
    "print('N/A Columns\\n')\n",
    "print('\\nREP_VSQL_PLAN Features ' + str(len(rep_vsql_plan_df.columns)) + ': ' + str(get_na_columns(df=rep_vsql_plan_df,headers=rep_vsql_plan_df.columns)) + \"\\n\")\n",
    "print('\\nDF_HINT_OUTLIERS Features ' + str(len(df_hints_outliers.columns)) + ': ' + str(get_na_columns(df=df_hints_outliers,headers=df_hints_outliers.columns)) + \"\\n\")\n",
    "print('\\nDF_PREDICATE_OUTLIERS Features ' + str(len(df_predicate_outliers.columns)) + ': ' + str(get_na_columns(df=df_predicate_outliers,headers=df_predicate_outliers.columns)) + \"\\n\")\n",
    "print('\\nDF_ROWNUM_OUTLIERS Features ' + str(len(df_rownum_outliers.columns)) + ': ' + str(get_na_columns(df=df_rownum_outliers,headers=df_rownum_outliers.columns)) + \"\\n\")\n",
    "#\n",
    "def fill_na(df):\n",
    "    \"\"\"\n",
    "    Replaces NA columns with 0s\n",
    "    \"\"\"\n",
    "    return df.fillna(0)\n",
    "\n",
    "# Populating NaN values with amount '0'\n",
    "df = fill_na(df=rep_vsql_plan_df)\n",
    "df_hints_outliers = fill_na(df=df_hints_outliers)\n",
    "df_predicate_outliers = fill_na(df=df_predicate_outliers)\n",
    "df_rownum_outliers = fill_na(df=df_rownum_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type conversion\n",
    "\n",
    "Each column is converted into a column of type values which are Integer64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "Dropped column [OBJECT_ALIAS]\n",
      "Dropped column [OBJECT_TYPE]\n",
      "Dropped column [OPTIMIZER]\n",
      "Dropped column [OTHER_XML]\n",
      "Dropped column [ACCESS_PREDICATES]\n",
      "Dropped column [FILTER_PREDICATES]\n",
      "Dropped column [PROJECTION]\n",
      "Dropped column [QBLOCK_NAME]\n",
      "-------------------------------------------------------------\n",
      "Dropped column [OBJECT_ALIAS]\n",
      "Dropped column [OBJECT_TYPE]\n",
      "Dropped column [OPTIMIZER]\n",
      "Dropped column [OTHER_XML]\n",
      "Dropped column [ACCESS_PREDICATES]\n",
      "Dropped column [FILTER_PREDICATES]\n",
      "Dropped column [PROJECTION]\n",
      "Dropped column [QBLOCK_NAME]\n",
      "-------------------------------------------------------------\n",
      "Dropped column [OBJECT_ALIAS]\n",
      "Dropped column [OBJECT_TYPE]\n",
      "Dropped column [OPTIMIZER]\n",
      "Dropped column [OTHER_XML]\n",
      "Dropped column [ACCESS_PREDICATES]\n",
      "Dropped column [FILTER_PREDICATES]\n",
      "Dropped column [PROJECTION]\n",
      "Dropped column [QBLOCK_NAME]\n",
      "-------------------------------------------------------------\n",
      "Index(['DBID', 'SQL_ID', 'PLAN_HASH_VALUE', 'ID', 'OPERATION', 'OPTIONS',\n",
      "       'OBJECT_NODE', 'OBJECT#', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS',\n",
      "       'OBJECT_TYPE', 'OPTIMIZER', 'PARENT_ID', 'DEPTH', 'POSITION',\n",
      "       'SEARCH_COLUMNS', 'COST', 'CARDINALITY', 'BYTES', 'OTHER_TAG',\n",
      "       'PARTITION_START', 'PARTITION_STOP', 'PARTITION_ID', 'OTHER',\n",
      "       'DISTRIBUTION', 'CPU_COST', 'IO_COST', 'TEMP_SPACE',\n",
      "       'ACCESS_PREDICATES', 'FILTER_PREDICATES', 'PROJECTION', 'TIME',\n",
      "       'QBLOCK_NAME', 'REMARKS', 'TIMESTAMP', 'OTHER_XML', 'CON_DBID',\n",
      "       'CON_ID'],\n",
      "      dtype='object')\n",
      "Index(['PLAN_ID', 'TIMESTAMP', 'REMARKS', 'OPERATION', 'OPTIONS',\n",
      "       'OBJECT_NODE', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_INSTANCE',\n",
      "       'SEARCH_COLUMNS', 'ID', 'PARENT_ID', 'DEPTH', 'POSITION', 'COST',\n",
      "       'CARDINALITY', 'BYTES', 'OTHER_TAG', 'PARTITION_START',\n",
      "       'PARTITION_STOP', 'PARTITION_ID', 'OTHER', 'DISTRIBUTION', 'CPU_COST',\n",
      "       'IO_COST', 'TEMP_SPACE', 'TIME'],\n",
      "      dtype='object')\n",
      "Index(['PLAN_ID', 'TIMESTAMP', 'REMARKS', 'OPERATION', 'OPTIONS',\n",
      "       'OBJECT_NODE', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_INSTANCE',\n",
      "       'SEARCH_COLUMNS', 'ID', 'PARENT_ID', 'DEPTH', 'POSITION', 'COST',\n",
      "       'CARDINALITY', 'BYTES', 'OTHER_TAG', 'PARTITION_START',\n",
      "       'PARTITION_STOP', 'PARTITION_ID', 'OTHER', 'DISTRIBUTION', 'CPU_COST',\n",
      "       'IO_COST', 'TEMP_SPACE', 'TIME'],\n",
      "      dtype='object')\n",
      "Index(['PLAN_ID', 'TIMESTAMP', 'REMARKS', 'OPERATION', 'OPTIONS',\n",
      "       'OBJECT_NODE', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_INSTANCE',\n",
      "       'SEARCH_COLUMNS', 'ID', 'PARENT_ID', 'DEPTH', 'POSITION', 'COST',\n",
      "       'CARDINALITY', 'BYTES', 'OTHER_TAG', 'PARTITION_START',\n",
      "       'PARTITION_STOP', 'PARTITION_ID', 'OTHER', 'DISTRIBUTION', 'CPU_COST',\n",
      "       'IO_COST', 'TEMP_SPACE', 'TIME'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def handle_numeric_overflows(x):\n",
    "    \"\"\"\n",
    "    Accepts a dataframe column, and \n",
    "    \"\"\"\n",
    "    try:\n",
    "        #df = df.astype('int64')\n",
    "        x1 = pd.DataFrame([x],dtype='int64')\n",
    "    except ValueError:\n",
    "        x = 9223372036854775807 # Max int size\n",
    "    return x\n",
    "\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        if col in black_list:\n",
    "            continue\n",
    "        df[col] = df[col].apply(handle_numeric_overflows)\n",
    "        df[col].astype('int64',inplace=True)\n",
    "    except:\n",
    "        df.drop(columns=col, inplace=True)\n",
    "        print('Dropped column [' + col + ']')\n",
    "\n",
    "print('-------------------------------------------------------------')\n",
    "\n",
    "for col in df_hints_outliers.columns:\n",
    "    try:\n",
    "        if col in black_list:\n",
    "            continue\n",
    "        df_hints_outliers[col] = df_hints_outliers[col].astype('int64')\n",
    "    except OverflowError:\n",
    "        #\n",
    "        # Handles numeric overflow conversions by replacing such values with max value inside the dataset.\n",
    "        df_hints_outliers[col] = df_hints_outliers[col].apply(handle_numeric_overflows)\n",
    "        df_hints_outliers[col] = df_hints_outliers[col].astype('int64')\n",
    "    except Exception as e:\n",
    "        df_hints_outliers.drop(columns=col, inplace=True)\n",
    "        print('Dropped column [' + col + ']')\n",
    "\n",
    "print('-------------------------------------------------------------')\n",
    "\n",
    "for col in df_predicate_outliers.columns:\n",
    "    try:\n",
    "        if col in black_list:\n",
    "            continue\n",
    "        df_predicate_outliers[col] = df_predicate_outliers[col].astype('int64')\n",
    "    except OverflowError:\n",
    "        \n",
    "        # Handles numeric overflow conversions by replacing such values with max value inside the dataset.\n",
    "        df_predicate_outliers[col] = df_predicate_outliers[col].apply(handle_numeric_overflows)\n",
    "        df_predicate_outliers[col] = df_predicate_outliers[col].astype('int64')\n",
    "    except Exception as e:\n",
    "        df_predicate_outliers.drop(columns=col, inplace=True)\n",
    "        print('Dropped column [' + col + ']')       \n",
    "\n",
    "print('-------------------------------------------------------------')\n",
    "\n",
    "for col in df_rownum_outliers.columns:\n",
    "    try:\n",
    "        if col in black_list:\n",
    "            continue\n",
    "        df_rownum_outliers[col] = df_rownum_outliers[col].astype('int64')\n",
    "    except OverflowError:\n",
    "        #\n",
    "        # Handles numeric overflow conversions by replacing such values with max value inside the dataset.\n",
    "        df_rownum_outliers[col] = df_rownum_outliers[col].apply(handle_numeric_overflows)\n",
    "        df_rownum_outliers[col] = df_rownum_outliers[col].astype('int64')\n",
    "    except Exception as e:\n",
    "        df_rownum_outliers.drop(columns=col, inplace=True)\n",
    "        print('Dropped column [' + col + ']')    \n",
    "\n",
    "print('-------------------------------------------------------------')\n",
    "      \n",
    "print(df.columns)\n",
    "print(df_hints_outliers.columns)\n",
    "print(df_predicate_outliers.columns)\n",
    "print(df_rownum_outliers.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Elimination\n",
    "\n",
    "In this step, redundant features are dropped. Features are considered redundant if exhibit a standard devaition of 0 (meaning no change in value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape before changes: [(10000, 39)]\n",
      "Shape after changes: [(10000, 30)]\n",
      "Dropped a total [9]\n",
      "\n",
      "Shape before changes: [(465, 27)]\n",
      "Shape after changes: [(465, 21)]\n",
      "Dropped a total [6]\n",
      "\n",
      "Shape before changes: [(491, 27)]\n",
      "Shape after changes: [(491, 21)]\n",
      "Dropped a total [6]\n",
      "\n",
      "Shape before changes: [(500, 27)]\n",
      "Shape after changes: [(500, 21)]\n",
      "Dropped a total [6]\n",
      "\n",
      "After flatline column drop:\n",
      "(10000, 30)\n",
      "Index(['SQL_ID', 'PLAN_HASH_VALUE', 'ID', 'OPERATION', 'OPTIONS',\n",
      "       'OBJECT_NODE', 'OBJECT#', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS',\n",
      "       'OBJECT_TYPE', 'OPTIMIZER', 'PARENT_ID', 'DEPTH', 'POSITION',\n",
      "       'SEARCH_COLUMNS', 'COST', 'CARDINALITY', 'BYTES', 'OTHER_TAG',\n",
      "       'PARTITION_START', 'PARTITION_STOP', 'DISTRIBUTION', 'CPU_COST',\n",
      "       'IO_COST', 'TEMP_SPACE', 'TIME', 'QBLOCK_NAME', 'TIMESTAMP',\n",
      "       'OTHER_XML'],\n",
      "      dtype='object')\n",
      "--------------------------------------------------------\n",
      "\n",
      "After outlier flatline column drop [df_hints_outliers]:\n",
      "(465, 21)\n",
      "Index(['PLAN_ID', 'TIMESTAMP', 'OPERATION', 'OPTIONS', 'OBJECT_OWNER',\n",
      "       'OBJECT_NAME', 'OBJECT_INSTANCE', 'SEARCH_COLUMNS', 'ID', 'PARENT_ID',\n",
      "       'DEPTH', 'POSITION', 'COST', 'CARDINALITY', 'BYTES', 'PARTITION_START',\n",
      "       'PARTITION_STOP', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'TIME'],\n",
      "      dtype='object')\n",
      "--------------------------------------------------------\n",
      "\n",
      "After outlier flatline column drop [df_predicate_outliers]:\n",
      "(491, 21)\n",
      "Index(['PLAN_ID', 'TIMESTAMP', 'OPERATION', 'OPTIONS', 'OBJECT_OWNER',\n",
      "       'OBJECT_NAME', 'OBJECT_INSTANCE', 'SEARCH_COLUMNS', 'ID', 'PARENT_ID',\n",
      "       'DEPTH', 'POSITION', 'COST', 'CARDINALITY', 'BYTES', 'PARTITION_START',\n",
      "       'PARTITION_STOP', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'TIME'],\n",
      "      dtype='object')\n",
      "--------------------------------------------------------\n",
      "\n",
      "After outlier flatline column drop [df_rownum_outliers]:\n",
      "(500, 21)\n",
      "Index(['PLAN_ID', 'TIMESTAMP', 'OPERATION', 'OPTIONS', 'OBJECT_OWNER',\n",
      "       'OBJECT_NAME', 'OBJECT_INSTANCE', 'SEARCH_COLUMNS', 'ID', 'PARENT_ID',\n",
      "       'DEPTH', 'POSITION', 'COST', 'CARDINALITY', 'BYTES', 'PARTITION_START',\n",
      "       'PARTITION_STOP', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'TIME'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def drop_flatline_columns(df):\n",
    "    columns = df.columns\n",
    "    flatline_features = []\n",
    "    for i in range(len(columns)):\n",
    "        try:\n",
    "            #\n",
    "            if columns[i] in black_list:\n",
    "                continue\n",
    "            #\n",
    "            std = df[columns[i]].std()\n",
    "            if std == 0:\n",
    "                flatline_features.append(columns[i])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #print('Features which are considered flatline:\\n')\n",
    "    #for col in flatline_features:\n",
    "    #    print(col)\n",
    "    print('\\nShape before changes: [' + str(df.shape) + ']')\n",
    "    df = df.drop(columns=flatline_features)\n",
    "    print('Shape after changes: [' + str(df.shape) + ']')\n",
    "    print('Dropped a total [' + str(len(flatline_features)) + ']')\n",
    "    return df\n",
    "\n",
    "df = drop_flatline_columns(df=df)\n",
    "df_hints_outliers = drop_flatline_columns(df=df_hints_outliers)\n",
    "df_predicate_outliers = drop_flatline_columns(df=df_predicate_outliers)\n",
    "df_rownum_outliers = drop_flatline_columns(df=df_rownum_outliers)\n",
    "\n",
    "print('\\nAfter flatline column drop:')\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "\n",
    "print('--------------------------------------------------------')\n",
    "print('\\nAfter outlier flatline column drop [df_hints_outliers]:')\n",
    "print(df_hints_outliers.shape)\n",
    "print(df_hints_outliers.columns)\n",
    "\n",
    "print('--------------------------------------------------------')\n",
    "print('\\nAfter outlier flatline column drop [df_predicate_outliers]:')\n",
    "print(df_predicate_outliers.shape)\n",
    "print(df_predicate_outliers.columns)\n",
    "\n",
    "print('--------------------------------------------------------')\n",
    "print('\\nAfter outlier flatline column drop [df_rownum_outliers]:')\n",
    "print(df_rownum_outliers.shape)\n",
    "print(df_rownum_outliers.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling columns\n",
    "\n",
    "This section attempts to process a number of data columns through a MinMax Scaler. This is done, to normalize data on a similar scaler, particularly before comparing column measurements using a euclidean based measure. The following columns will be targetted:\n",
    "\n",
    "* CARDINALITY\n",
    "* BYTES\n",
    "* PARTITION_START\n",
    "* PARTITION_STOP\n",
    "* CPU_COST\n",
    "* IO_COST\n",
    "* TEMP_SPACE\n",
    "* TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "Minimal Vector Points: [0.000e+00 2.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.156e+06\n",
      " 0.000e+00]\n",
      "Maximal Vector Points: [2.85716704e+16 9.22337204e+18 0.00000000e+00 0.00000000e+00\n",
      " 9.22337204e+18 7.78425143e+09 9.22337204e+18 1.58287675e+08]\n",
      "\n",
      "After scaled column transformation:\n",
      "(10000, 30)\n",
      "Index(['SQL_ID', 'PLAN_HASH_VALUE', 'ID', 'OPERATION', 'OPTIONS',\n",
      "       'OBJECT_NODE', 'OBJECT#', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS',\n",
      "       'OBJECT_TYPE', 'OPTIMIZER', 'PARENT_ID', 'DEPTH', 'POSITION',\n",
      "       'SEARCH_COLUMNS', 'COST', 'CARDINALITY', 'BYTES', 'OTHER_TAG',\n",
      "       'PARTITION_START', 'PARTITION_STOP', 'DISTRIBUTION', 'CPU_COST',\n",
      "       'IO_COST', 'TEMP_SPACE', 'TIME', 'QBLOCK_NAME', 'TIMESTAMP',\n",
      "       'OTHER_XML'],\n",
      "      dtype='object')\n",
      "--------------------------------------------------------\n",
      "\n",
      "After outlier scaled column transformation [df_hints_outliers]:\n",
      "(465, 21)\n",
      "Index(['PLAN_ID', 'TIMESTAMP', 'OPERATION', 'OPTIONS', 'OBJECT_OWNER',\n",
      "       'OBJECT_NAME', 'OBJECT_INSTANCE', 'SEARCH_COLUMNS', 'ID', 'PARENT_ID',\n",
      "       'DEPTH', 'POSITION', 'COST', 'CARDINALITY', 'BYTES', 'PARTITION_START',\n",
      "       'PARTITION_STOP', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'TIME'],\n",
      "      dtype='object')\n",
      "--------------------------------------------------------\n",
      "\n",
      "After outlier scaled column transformation [df_predicate_outliers]:\n",
      "(491, 21)\n",
      "Index(['PLAN_ID', 'TIMESTAMP', 'OPERATION', 'OPTIONS', 'OBJECT_OWNER',\n",
      "       'OBJECT_NAME', 'OBJECT_INSTANCE', 'SEARCH_COLUMNS', 'ID', 'PARENT_ID',\n",
      "       'DEPTH', 'POSITION', 'COST', 'CARDINALITY', 'BYTES', 'PARTITION_START',\n",
      "       'PARTITION_STOP', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'TIME'],\n",
      "      dtype='object')\n",
      "--------------------------------------------------------\n",
      "\n",
      "After outlier scaled column transformation [df_rownum_outliers]:\n",
      "(500, 21)\n",
      "Index(['PLAN_ID', 'TIMESTAMP', 'OPERATION', 'OPTIONS', 'OBJECT_OWNER',\n",
      "       'OBJECT_NAME', 'OBJECT_INSTANCE', 'SEARCH_COLUMNS', 'ID', 'PARENT_ID',\n",
      "       'DEPTH', 'POSITION', 'COST', 'CARDINALITY', 'BYTES', 'PARTITION_START',\n",
      "       'PARTITION_STOP', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'TIME'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype float64, object were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaled_columns = ['CARDINALITY',\n",
    "                'BYTES',\n",
    "                'PARTITION_START',\n",
    "                'PARTITION_STOP',\n",
    "                'CPU_COST',\n",
    "                'IO_COST',\n",
    "                'TEMP_SPACE',\n",
    "                'TIME']\n",
    "print(df['PARTITION_START'].iloc[0])\n",
    "df[scaled_columns] = scaler.fit_transform(df[scaled_columns])\n",
    "print(df['PARTITION_START'].iloc[0])\n",
    "print(\"Minimal Vector Points: \" + str(scaler.data_min_))\n",
    "print(\"Maximal Vector Points: \" + str(scaler.data_max_))\n",
    "\n",
    "print('\\nAfter scaled column transformation:')\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "\n",
    "print('--------------------------------------------------------')\n",
    "print('\\nAfter outlier scaled column transformation [df_hints_outliers]:')\n",
    "print(df_hints_outliers.shape)\n",
    "print(df_hints_outliers.columns)\n",
    "\n",
    "print('--------------------------------------------------------')\n",
    "print('\\nAfter outlier scaled column transformation [df_predicate_outliers]:')\n",
    "print(df_predicate_outliers.shape)\n",
    "print(df_predicate_outliers.columns)\n",
    "\n",
    "print('--------------------------------------------------------')\n",
    "print('\\nAfter outlier scaled column transformation [df_rownum_outliers]:')\n",
    "print(df_rownum_outliers.shape)\n",
    "print(df_rownum_outliers.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Grouping Column\n",
    "\n",
    "An extra column is added to allow access plans to be isolated per instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before transformation: (10000, 30)\n",
      "Shape after transformation: (10000, 31)\n",
      "Shape before transformation: (465, 21)\n",
      "Shape after transformation: (465, 22)\n",
      "Shape before transformation: (491, 21)\n",
      "Shape after transformation: (491, 22)\n",
      "Shape before transformation: (500, 21)\n",
      "Shape after transformation: (500, 22)\n"
     ]
    }
   ],
   "source": [
    "# Adds a columns per SQL_ID, PLAN_HASH_VALUE grouping, which can be used to group instances together\n",
    "def add_grouping_column(df, column_identifier):\n",
    "    \"\"\"\n",
    "    Receives a pandas dataframe, and adds a new column which allows dataframe to be aggregated per \n",
    "    SQL_ID, PLAN_HASH_VALUE combination.\n",
    "    \n",
    "    :param: df                - Pandas Dataframe\n",
    "    :param: column_identifier - String denoting matrix column to group by\n",
    "    \n",
    "    :return: Pandas Dataframe, with added column    \n",
    "    \"\"\"\n",
    "    print('Shape before transformation: ' + str(df.shape))\n",
    "    new_grouping_col = []\n",
    "    counter = 0\n",
    "    last_sql_id = df[column_identifier].iloc(0) # Starts with first SQL_ID\n",
    "    for index, row in df.iterrows():\n",
    "        if column_identifier == 'SQL_ID':\n",
    "            if last_sql_id != row.SQL_ID:\n",
    "                last_sql_id = row.SQL_ID\n",
    "                counter += 1\n",
    "        elif column_identifier == 'PLAN_ID':\n",
    "            if last_sql_id != row.PLAN_ID:\n",
    "                last_sql_id = row.PLAN_ID\n",
    "                counter += 1\n",
    "        else:\n",
    "            raise ValueError('Column does not exist!')\n",
    "        new_grouping_col.append(counter)\n",
    "    \n",
    "    # Append list as new column\n",
    "    new_col = pd.Series(new_grouping_col)\n",
    "    df['PLAN_INSTANCE'] = new_col.values\n",
    "    print('Shape after transformation: ' + str(df.shape))\n",
    "    return df\n",
    "\n",
    "df = add_grouping_column(df=df,column_identifier='SQL_ID')\n",
    "df_hints_outliers = add_grouping_column(df=df_hints_outliers,column_identifier='PLAN_ID')\n",
    "df_predicate_outliers = add_grouping_column(df=df_predicate_outliers,column_identifier='PLAN_ID')\n",
    "df_rownum_outliers = add_grouping_column(df=df_rownum_outliers,column_identifier='PLAN_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Formatting\n",
    "\n",
    "Constructs the tree plan structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanTreeModeller:\n",
    "    \"\"\"\n",
    "    This class simulates an access plan in the form of a tree structure\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def __create_node(node_name, parent=None):\n",
    "        \"\"\"\n",
    "        Builds a node which will be added to the tree. If the parent is 'None', it is assumed that this\n",
    "        node will be used as the root/parent Node.\n",
    "        \n",
    "        :param: node_name - String specifying node name.\n",
    "        :param: parent    - Parent node specifying parent node name.\n",
    "        \n",
    "        :return: anytree object\n",
    "        \"\"\"\n",
    "        if node_name is None:\n",
    "            raise ValueError('Node name was not specified!')\n",
    "        \n",
    "        if parent is None:\n",
    "            node = Node(node_name)\n",
    "        else:\n",
    "            node = Node(node_name, parent=parent)\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_tree(df):\n",
    "        \"\"\"\n",
    "        This method receives a pandas dataframe, and converts it into a searchable python tree\n",
    "        \n",
    "        :param: df - Pandas Dataframe, pertaining to input access plan\n",
    "        \n",
    "        :return: Dictionary object, consisting of node objects (which are linked in a tree fashion)\n",
    "        \"\"\"\n",
    "        parent_node = None\n",
    "        node_dict = {}\n",
    "        for index, row in df.iterrows():\n",
    "            \n",
    "            # Build Node and add to parent\n",
    "            row_id = int(row['ID'])\n",
    "            parent_id = int(row['PARENT_ID'])\n",
    "            \n",
    "            if row_id == 0:\n",
    "                node = PlanTreeModeller.__create_node(node_name=row_id)\n",
    "            else:\n",
    "                parent_node = node_dict[parent_id]\n",
    "                node = PlanTreeModeller.__create_node(node_name=row_id, parent=parent_node)\n",
    "            node_dict[row_id] = node\n",
    "        \n",
    "        return node_dict # Dictionary consisting of tree nodes\n",
    "    \n",
    "    @staticmethod\n",
    "    def __retrieve_plan_details(df, node_name):\n",
    "        \"\"\"\n",
    "        Accepts a dataframe, and the node_name. Retrieves features pertaining to the row id in the access plan\n",
    "        \n",
    "        :param: df - Dataframe consisting of access plan features\n",
    "        :param: id - String id denoting which row to retrieve from the parameter dataframe\n",
    "        \n",
    "        :return: Dictionary consisting of access plan attributes\n",
    "        \"\"\"\n",
    "        operation = str(df[df['ID'] == node_name]['OPERATION'].iloc[0])\n",
    "        options = str(df[df['ID'] == node_name]['OPTIONS'].iloc[0])\n",
    "        object_name = str(df[df['ID'] == node_name]['OBJECT_NAME'].iloc[0])\n",
    "        cardinality = int(df[df['ID'] == node_name]['CARDINALITY'].iloc[0])\n",
    "        bytess = int(df[df['ID'] == node_name]['BYTES'].iloc[0])\n",
    "        partition_delta = int(df[df['ID'] == node_name]['PARTITION_STOP'].iloc[0]) - int(df[df['ID'] == node_name]['PARTITION_START'].iloc[0])\n",
    "        cpu_cost = int(df[df['ID'] == node_name]['CPU_COST'].iloc[0])\n",
    "        io_cost = int(df[df['ID'] == node_name]['IO_COST'].iloc[0])\n",
    "        temp_space = int(df[df['ID'] == node_name]['TEMP_SPACE'].iloc[0])\n",
    "        time = int(df[df['ID'] == node_name]['TIME'].iloc[0]) \n",
    "        \n",
    "        return {'OPERATION':operation,\n",
    "                'OPTIONS':options,\n",
    "                'OBJECT_NAME':object_name,\n",
    "                'CARDINALITY':cardinality,\n",
    "                'BYTES':bytess,\n",
    "                'PARTITION_DELTA':partition_delta,\n",
    "                'CPU_COST':cpu_cost,\n",
    "                'IO_COST':io_cost,\n",
    "                'TEMP_SPACE':temp_space,\n",
    "                'TIME':time}\n",
    "    \n",
    "    @staticmethod\n",
    "    def __tree_node_euclidean(tree_dict1, tree_dict2):\n",
    "        \"\"\"\n",
    "        This method calculates the eucldiean distance between two vectors.\n",
    "        \n",
    "        :param: tree_dict1 - Dictionary denoting a single node within plan / tree 1\n",
    "        :param: tree_dict2 - Dictionary denoting a single node within plan / tree 2\n",
    "        \n",
    "        :return: List denoting euclidean distance\n",
    "        \"\"\"\n",
    "        tree_vector_1 = [tree_dict1['CARDINALITY'],\n",
    "                         tree_dict1['BYTES'],\n",
    "                         tree_dict1['PARTITION_DELTA'],\n",
    "                         tree_dict1['CPU_COST'],\n",
    "                         tree_dict1['IO_COST'],\n",
    "                         tree_dict1['TEMP_SPACE'],\n",
    "                         tree_dict1['TIME']]\n",
    "        \n",
    "        tree_vector_2 = [tree_dict2['CARDINALITY'],\n",
    "                         tree_dict2['BYTES'],\n",
    "                         tree_dict2['PARTITION_DELTA'],\n",
    "                         tree_dict2['CPU_COST'],\n",
    "                         tree_dict2['IO_COST'],\n",
    "                         tree_dict2['TEMP_SPACE'],\n",
    "                         tree_dict2['TIME']]\n",
    "        \n",
    "        euc_distance = euclidean_distances([tree_vector_1],[tree_vector_2])\n",
    "        return euc_distance[0][0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def render_tree(tree, df):\n",
    "        \"\"\"\n",
    "        Renders Tree by printing to screen\n",
    "        \n",
    "        :param: tree - AnyTree object, representing tree modelled access plan\n",
    "        :param: df   - Pandas dataframe representatnt of the access plan about to be rendered\n",
    "        \n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        for pre, fill, node in RenderTree(tree):\n",
    "            \n",
    "            access_plan_dict = PlanTreeModeller.__retrieve_plan_details(df=df,\n",
    "                                                                        node_name = node.name)\n",
    "            \n",
    "            if access_plan_dict['OBJECT_NAME'] == '0':\n",
    "                print(\"%s%s > %s\" % (pre, node.name, access_plan_dict['OPERATION']))\n",
    "            else:\n",
    "                if access_plan_dict['OPTIONS'] == '0': \n",
    "                    print(\"%s%s > %s (%s)\" % (pre, node.name, access_plan_dict['OPERATION'], access_plan_dict['OBJECT_NAME']))\n",
    "                else:\n",
    "                    print(\"%s%s > %s | %s (%s)\" % (pre, node.name, access_plan_dict['OPERATION'], access_plan_dict['OPTIONS'], access_plan_dict['OBJECT_NAME']))\n",
    "    \n",
    "    @staticmethod\n",
    "    def __postorder(tree):\n",
    "        \"\"\"\n",
    "        Accepts a tree, and iterates in post order fashion (left,right,root)\n",
    "        \n",
    "        :param: tree - Dictionary consisting of AnyTree Nodes\n",
    "        \n",
    "        :return: List consisting of tree traversal order\n",
    "        \"\"\"\n",
    "        post_order_traversal = [node.name for node in PostOrderIter(tree[0])]\n",
    "        return post_order_traversal\n",
    "     \n",
    "    @staticmethod\n",
    "    def tree_compare(tree1, tree2, df1, df2):\n",
    "        \"\"\"\n",
    "        Accepts two trees of type 'AnyTree', along with respective dataframe denoting each respective access\n",
    "        path.\n",
    "        \n",
    "        :param: tree1 - Dictionary consisting of 'AnyTree' nodes, belonging to tree 1\n",
    "        :param: tree2 - Dictionary consisting of 'AnyTree' nodes, belonging to tree 2\n",
    "        :param: df1   - Pandas dataframe consisting of access plan instructions opted for by tree 1\n",
    "        :param: df2   - Pandas dataframe consisting of access plan instructions opted for by tree 2\n",
    "        \n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        \n",
    "        # Retrieves traversal order for both trees\n",
    "        post_order_traversal1 = PlanTreeModeller.__postorder(tree1)\n",
    "        post_order_traversal2 = PlanTreeModeller.__postorder(tree2)\n",
    "        \n",
    "        # Iterates over traversal order, until a change is encountered\n",
    "        max_range = max(len(post_order_traversal1),len(post_order_traversal2))\n",
    "        delta_flag = True\n",
    "        euclidean_measure = []\n",
    "        for i in range(0,max_range):\n",
    "            \n",
    "            # This check avoids a list IndexError for scebarious when one plan is bigger than the others,\n",
    "            # and consequently the number of node traversals is bigger than the other tree.\n",
    "            if i >= len(post_order_traversal1) or i >= len(post_order_traversal2):\n",
    "                break\n",
    "            \n",
    "            id_1 = post_order_traversal1[i]\n",
    "            id_2 = post_order_traversal2[i]\n",
    "            \n",
    "            pd_tree1 = PlanTreeModeller.__retrieve_plan_details(df=df1, node_name=id_1)\n",
    "            pd_tree2 = PlanTreeModeller.__retrieve_plan_details(df=df2, node_name=id_2)\n",
    "            \n",
    "            if (pd_tree1['OPERATION'] != pd_tree2['OPERATION'] or pd_tree1['OBJECT_NAME'] != pd_tree2['OBJECT_NAME'] or pd_tree1['OPTIONS'] != pd_tree2['OPTIONS']) and delta_flag:\n",
    "#                 print('Access Predicate Difference detected!')\n",
    "#                 print('Tree 1 difference at node [' + str(id_1) + '] operator > ' + pd_tree1['OPERATION'] + '(' + pd_tree1['OPTIONS'] + ') on object [' + pd_tree1['OBJECT_NAME'] + ']')\n",
    "#                 print('Tree 2 difference at node [' + str(id_2) + '] operator > ' + pd_tree2['OPERATION'] + '(' + pd_tree2['OPTIONS'] + ') on object [' + pd_tree2['OBJECT_NAME'] + ']')\n",
    "#                 print('-'*30)\n",
    "#                 PlanTreeModeller.render_tree(tree=tree1[0], df=df1) # Tree rendederer uses root node and traverses downwards\n",
    "#                 PlanTreeModeller.render_tree(tree=tree2[0], df=df2) # Tree rendederer uses root node and traverses downwards\n",
    "#                 print('-'*30)\n",
    "                delta_flag = False\n",
    "            \n",
    "            # Calculate Node Euclidean Measure\n",
    "            euclidean_vector = PlanTreeModeller.__tree_node_euclidean(tree_dict1=pd_tree1,\n",
    "                                                                      tree_dict2=pd_tree2)\n",
    "            euclidean_measure.append(euclidean_vector)\n",
    "        \n",
    "        if sum(euclidean_measure) > 10000 or delta_flag is False:\n",
    "            print('Access Predicate Difference detected with delta value [' + str(sum(euclidean_measure)) + ']')\n",
    "            print('Tree 1 difference at node [' + str(id_1) + '] operator > ' + pd_tree1['OPERATION'] + '(' + pd_tree1['OPTIONS'] + ') on object [' + pd_tree1['OBJECT_NAME'] + ']')\n",
    "            print('Tree 2 difference at node [' + str(id_2) + '] operator > ' + pd_tree2['OPERATION'] + '(' + pd_tree2['OPTIONS'] + ') on object [' + pd_tree2['OBJECT_NAME'] + ']')\n",
    "            #print('-'*30)\n",
    "            PlanTreeModeller.render_tree(tree=tree1[0], df=df1) # Tree rendederer uses root node and traverses downwards\n",
    "            PlanTreeModeller.render_tree(tree=tree2[0], df=df2) # Tree rendederer uses root node and traverses downwards\n",
    "        else:\n",
    "            print('No changes detected with delta value of [' + str(sum(euclidean_measure)) + ']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Testing Streams\n",
    "\n",
    "This cell builds a total of 4 lists, composed as follows:\n",
    "\n",
    "* Expected Stream, composed of SQL queries with which comparison will be made.\n",
    "* Variant Stream, with intermingled hint outliers\n",
    "* Variant Stream, with intermingled predicate outliers\n",
    "* Variant Stream, with intermingled rownum outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTUAL:\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167]\n",
      "<class 'list'>\n",
      "155\n",
      "----------------------------------------------------------------------------------------------------\n",
      "HINT_VARIANTS:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "<class 'numpy.ndarray'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "PREDICATE_VARIANTS:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "<class 'numpy.ndarray'>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ROWNUM_VARIANTS:\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "<class 'numpy.ndarray'>\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Retrieve Unique set of PLAN_HASH_VALUES\n",
    "np_sql_id = pd.unique(df['SQL_ID'])\n",
    "\n",
    "# Remove those which are not originating from TPC-DS\n",
    "filtered_sql = []\n",
    "for sql in np_sql_id:\n",
    "    \n",
    "    df_temp_plan = df[df['SQL_ID'] == sql]\n",
    "\n",
    "    # This step ensures that only TPC-DS related queries are displayed\n",
    "    tpc_check = df_temp_plan['OBJECT_OWNER'].tolist()\n",
    "    if tpcds not in tpc_check:\n",
    "        continue\n",
    "        \n",
    "    #\n",
    "    # Discards plans with double entries - Due to the parallel nature of the throughput test for \n",
    "    # TPC-DS, multiple threads may execute the same query at the same time, resulting in sql access\n",
    "    # plans with the same SQL_ID, same PLAN_HASH_VALUE, and same TIMESTAMP. Such occurances are skipped.\n",
    "    #     df_temp_count = df_temp_plan[df_temp_plan['ID'] == 0]\n",
    "    #     if df_temp_count.shape[0] != 1:\n",
    "    #         continue\n",
    "        \n",
    "    filtered_sql.append(sql)\n",
    "np_sql_id= filtered_sql \n",
    "\n",
    "print('ACTUAL:')\n",
    "print(np_sql_id)\n",
    "print(type(np_sql_id))\n",
    "print(len(np_sql_id))\n",
    "print('-'*100)\n",
    "\n",
    "# Retrieve Unique set of PLAN_IDs for hint outliers\n",
    "np_hint_outlier_plan_id = pd.unique(df_hints_outliers['PLAN_ID'])\n",
    "print('HINT_VARIANTS:')\n",
    "print(np_hint_outlier_plan_id)\n",
    "print(type(np_hint_outlier_plan_id))\n",
    "print('-'*100)\n",
    "\n",
    "# Retrieve Unique set of PLAN_IDs for predicate outliers\n",
    "np_predicate_outlier_plan_id = pd.unique(df_predicate_outliers['PLAN_ID'])\n",
    "print('PREDICATE_VARIANTS:')\n",
    "print(np_predicate_outlier_plan_id)\n",
    "print(type(np_predicate_outlier_plan_id))\n",
    "print('-'*100)\n",
    "\n",
    "# Retrieve Unique set of PLAN_IDs for rownum outliers\n",
    "np_rownum_outlier_plan_id = pd.unique(df_rownum_outliers['PLAN_ID'])\n",
    "print('ROWNUM_VARIANTS:')\n",
    "print(np_rownum_outlier_plan_id)\n",
    "print(type(np_rownum_outlier_plan_id))\n",
    "print('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Query Streams\n",
    "\n",
    "Create an expected stream vs an 'outlier' stream. Both streams will be composed of SQL identifiers, and will be matched by plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected:\n",
      "155\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167]\n",
      "HINT Variant:\n",
      "155\n",
      "[1, 2, 3, 4, 1, 6, 7, 8, 9, 2, 11, 12, 13, 3, 15, 16, 17, 4, 19, 20, 21, 5, 23, 24, 25, 26, 6, 28, 29, 30, 31, 32, 33, 34, 7, 8, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 9, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 10, 74, 75, 11, 77, 78, 79, 80, 81, 82, 12, 84, 85, 13, 87, 88, 89, 90, 91, 14, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167]\n",
      "------------------------------\n",
      "Expected:\n",
      "155\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167]\n",
      "PREDICATE Variant:\n",
      "155\n",
      "[1, 2, 3, 4, 1, 6, 7, 8, 9, 2, 11, 12, 13, 3, 15, 16, 17, 4, 19, 20, 21, 5, 23, 24, 25, 26, 6, 28, 29, 30, 31, 32, 33, 34, 7, 8, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 9, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 10, 74, 75, 11, 77, 78, 79, 80, 81, 82, 12, 84, 85, 13, 87, 88, 89, 90, 91, 14, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167]\n",
      "------------------------------\n",
      "Expected:\n",
      "155\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167]\n",
      "ROWNUM Variant:\n",
      "155\n",
      "[1, 2, 3, 4, 1, 6, 7, 8, 9, 2, 11, 12, 13, 3, 15, 16, 17, 4, 19, 20, 21, 5, 23, 24, 25, 26, 6, 28, 29, 30, 31, 32, 33, 34, 7, 8, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 9, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 10, 74, 75, 11, 77, 78, 79, 80, 81, 82, 12, 84, 85, 13, 87, 88, 89, 90, 91, 14, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167]\n",
      "------------------------------\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167]\n",
      "\n",
      "[1, 2, 3, 4, 1, 6, 7, 8, 9, 2, 11, 12, 13, 3, 15, 16, 17, 4, 19, 20, 21, 5, 23, 24, 25, 26, 6, 28, 29, 30, 31, 32, 33, 34, 7, 8, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 9, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 10, 74, 75, 11, 77, 78, 79, 80, 81, 82, 12, 84, 85, 13, 87, 88, 89, 90, 91, 14, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167]\n",
      "\n",
      "[1, 2, 3, 4, 1, 6, 7, 8, 9, 2, 11, 12, 13, 3, 15, 16, 17, 4, 19, 20, 21, 5, 23, 24, 25, 26, 6, 28, 29, 30, 31, 32, 33, 34, 7, 8, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 9, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 10, 74, 75, 11, 77, 78, 79, 80, 81, 82, 12, 84, 85, 13, 87, 88, 89, 90, 91, 14, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167]\n",
      "\n",
      "[1, 2, 3, 4, 1, 6, 7, 8, 9, 2, 11, 12, 13, 3, 15, 16, 17, 4, 19, 20, 21, 5, 23, 24, 25, 26, 6, 28, 29, 30, 31, 32, 33, 34, 7, 8, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 9, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 10, 74, 75, 11, 77, 78, 79, 80, 81, 82, 12, 84, 85, 13, 87, 88, 89, 90, 91, 14, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pad variation stream with SQL queries in expected stream\n",
    "variant_index = 0\n",
    "expected_stream, hint_variant_stream = [], []\n",
    "for i in range(1, len(np_sql_id)+1):\n",
    "    if i in variant_ids:\n",
    "        hint_variant_stream.append(np_hint_outlier_plan_id[variant_index])\n",
    "        variant_index += 1\n",
    "    else:\n",
    "        hint_variant_stream.append(np_sql_id[i-1])\n",
    "    expected_stream.append(np_sql_id[i-1])\n",
    "\n",
    "print('Expected:')        \n",
    "print(len(expected_stream))\n",
    "print(expected_stream)\n",
    "print('HINT Variant:')\n",
    "print(len(hint_variant_stream))\n",
    "print(hint_variant_stream)\n",
    "print('-'*30)\n",
    "\n",
    "# Pad variation stream with SQL queries in expected stream\n",
    "variant_index = 0\n",
    "expected_stream, predicate_variant_stream = [], []\n",
    "for i in range(1, len(np_sql_id)+1):\n",
    "    if i in variant_ids:\n",
    "        predicate_variant_stream.append(np_predicate_outlier_plan_id[variant_index])\n",
    "        variant_index += 1\n",
    "    else:\n",
    "        predicate_variant_stream.append(np_sql_id[i-1])\n",
    "    expected_stream.append(np_sql_id[i-1])\n",
    "\n",
    "print('Expected:')  \n",
    "print(len(expected_stream))\n",
    "print(expected_stream)\n",
    "print('PREDICATE Variant:')\n",
    "print(len(predicate_variant_stream))\n",
    "print(predicate_variant_stream)\n",
    "print('-'*30)\n",
    "\n",
    "# Pad variation stream with SQL queries in expected stream\n",
    "variant_index = 0\n",
    "expected_stream, rownum_variant_stream = [], []\n",
    "for i in range(1, len(np_sql_id)+1):\n",
    "    if i in variant_ids:\n",
    "        rownum_variant_stream.append(np_rownum_outlier_plan_id[variant_index])\n",
    "        variant_index += 1\n",
    "    else:\n",
    "        rownum_variant_stream.append(np_sql_id[i-1])\n",
    "    expected_stream.append(np_sql_id[i-1])\n",
    "\n",
    "print('Expected:') \n",
    "print(len(expected_stream))\n",
    "print(expected_stream)\n",
    "print('ROWNUM Variant:')\n",
    "print(len(rownum_variant_stream))\n",
    "print(rownum_variant_stream)\n",
    "print('-'*30)\n",
    "\n",
    "outlier_index, actual_sqls, hint_outlier_sqls, predicate_outlier_sqls, rownum_outlier_sqls = 0, [], [], [], []\n",
    "for i in range(1, len(np_sql_id)+1):\n",
    "    if i in variant_ids:\n",
    "        hint_outlier_sqls.append(np_hint_outlier_plan_id[outlier_index])\n",
    "        predicate_outlier_sqls.append(np_predicate_outlier_plan_id[outlier_index])\n",
    "        rownum_outlier_sqls.append(np_rownum_outlier_plan_id[outlier_index])\n",
    "        outlier_index += 1\n",
    "    else:\n",
    "        hint_outlier_sqls.append(np_sql_id[i-1])\n",
    "        predicate_outlier_sqls.append(np_sql_id[i-1])\n",
    "        rownum_outlier_sqls.append(np_sql_id[i-1])\n",
    "    actual_sqls.append(np_sql_id[i-1])\n",
    "\n",
    "print(str(actual_sqls) + \"\\n\")\n",
    "print(str(hint_outlier_sqls) + \"\\n\")\n",
    "print(str(predicate_outlier_sqls) + \"\\n\")\n",
    "print(str(rownum_outlier_sqls) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream Comparison with Hint Based Outliers\n",
    "\n",
    "Compares the expected stream with variation stream. Variations found here will be composed of SQL optimizer hint injections to purposely skew the plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL  [1]\n",
      "1\n",
      "1\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [2]\n",
      "2\n",
      "2\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [3]\n",
      "3\n",
      "3\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [4]\n",
      "4\n",
      "4\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [5]\n",
      "1\n",
      "5\n",
      "Access Predicate Difference detected with delta value [8767519808.098682]\n",
      "Tree 1 difference at node [7] operator > NESTED LOOPS(0) on object [0]\n",
      "Tree 2 difference at node [0] operator > SELECT STATEMENT(0) on object [0]\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > COUNT\n",
      "    └── 2 > VIEW\n",
      "        └── 3 > SORT\n",
      "            └── 4 > VIEW\n",
      "                └── 5 > UNION-ALL\n",
      "                    ├── 6 > HASH\n",
      "                    │   └── 7 > NESTED LOOPS\n",
      "                    │       ├── 8 > NESTED LOOPS\n",
      "                    │       │   ├── 9 > HASH JOIN\n",
      "                    │       │   │   ├── 10 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                    │       │   │   └── 11 > VIEW\n",
      "                    │       │   │       └── 12 > UNION-ALL\n",
      "                    │       │   │           ├── 13 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "                    │       │   │           └── 14 > TABLE ACCESS | FULL (STORE_RETURNS)\n",
      "                    │       │   └── 15 > INDEX | UNIQUE SCAN (SYS_C0021425)\n",
      "                    │       └── 16 > TABLE ACCESS | BY INDEX ROWID (STORE)\n",
      "                    ├── 17 > HASH\n",
      "                    │   └── 18 > HASH JOIN\n",
      "                    │       ├── 19 > NESTED LOOPS\n",
      "                    │       │   ├── 20 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                    │       │   └── 21 > VIEW\n",
      "                    │       │       └── 22 > UNION-ALL\n",
      "                    │       │           ├── 23 > TABLE ACCESS | BY INDEX ROWID BATCHED (CATALOG_SALES)\n",
      "                    │       │           │   └── 24 > INDEX | RANGE SCAN (CS_SOLD_DATE_SK_INDEX)\n",
      "                    │       │           └── 25 > TABLE ACCESS | BY INDEX ROWID BATCHED (CATALOG_RETURNS)\n",
      "                    │       │               └── 26 > INDEX | RANGE SCAN (CR_RETURNED_DATE_SK_INDEX)\n",
      "                    │       └── 27 > TABLE ACCESS | FULL (CATALOG_PAGE)\n",
      "                    └── 28 > HASH\n",
      "                        └── 29 > NESTED LOOPS\n",
      "                            ├── 30 > NESTED LOOPS\n",
      "                            │   ├── 31 > NESTED LOOPS\n",
      "                            │   │   ├── 32 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                            │   │   └── 33 > VIEW\n",
      "                            │   │       └── 34 > UNION-ALL\n",
      "                            │   │           ├── 35 > TABLE ACCESS | BY INDEX ROWID BATCHED (WEB_SALES)\n",
      "                            │   │           │   └── 36 > INDEX | RANGE SCAN (WS_SOLD_DATE_SK_INDEX)\n",
      "                            │   │           └── 37 > NESTED LOOPS\n",
      "                            │   │               ├── 38 > TABLE ACCESS | BY INDEX ROWID BATCHED (WEB_RETURNS)\n",
      "                            │   │               │   └── 39 > INDEX | RANGE SCAN (WR_RETURNED_DATE_SK_INDEX)\n",
      "                            │   │               └── 40 > TABLE ACCESS | BY INDEX ROWID (WEB_SALES)\n",
      "                            │   │                   └── 41 > INDEX | UNIQUE SCAN (SYS_C0021461)\n",
      "                            │   └── 42 > INDEX | UNIQUE SCAN (SYS_C0021434)\n",
      "                            └── 43 > TABLE ACCESS | BY INDEX ROWID (WEB_SITE)\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > SORT\n",
      "    └── 2 > PX COORDINATOR\n",
      "        └── 3 > PX SEND | QC (RANDOM) (:TQ10001)\n",
      "            └── 4 > SORT\n",
      "                └── 5 > PX RECEIVE\n",
      "                    └── 6 > PX SEND | HASH (:TQ10000)\n",
      "                        └── 7 > SORT\n",
      "                            └── 8 > PX BLOCK\n",
      "                                └── 9 > INDEX | FAST FULL SCAN (CS_BILL_CUSTOMER_SK_INDEX)\n",
      "SQL  [6]\n",
      "6\n",
      "6\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [7]\n",
      "7\n",
      "7\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [8]\n",
      "8\n",
      "8\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [9]\n",
      "9\n",
      "9\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [10]\n",
      "2\n",
      "10\n",
      "Access Predicate Difference detected with delta value [2100049110.8332195]\n",
      "Tree 1 difference at node [22] operator > TABLE ACCESS(FULL) on object [WEB_SALES]\n",
      "Tree 2 difference at node [0] operator > SELECT STATEMENT(0) on object [0]\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > COUNT\n",
      "    └── 2 > VIEW\n",
      "        └── 3 > SORT\n",
      "            └── 4 > HASH JOIN\n",
      "                ├── 5 > NESTED LOOPS\n",
      "                │   ├── 6 > NESTED LOOPS\n",
      "                │   │   ├── 7 > NESTED LOOPS\n",
      "                │   │   │   ├── 8 > NESTED LOOPS\n",
      "                │   │   │   │   ├── 9 > VIEW (VW_SQ_1)\n",
      "                │   │   │   │   │   └── 10 > HASH\n",
      "                │   │   │   │   │       └── 11 > UNION-ALL\n",
      "                │   │   │   │   │           ├── 12 > HASH JOIN\n",
      "                │   │   │   │   │           │   ├── 13 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                │   │   │   │   │           │   └── 14 > TABLE ACCESS | FULL (CATALOG_SALES)\n",
      "                │   │   │   │   │           └── 15 > HASH JOIN\n",
      "                │   │   │   │   │               ├── 16 > NESTED LOOPS\n",
      "                │   │   │   │   │               │   ├── 17 > NESTED LOOPS\n",
      "                │   │   │   │   │               │   │   ├── 18 > STATISTICS COLLECTOR\n",
      "                │   │   │   │   │               │   │   │   └── 19 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                │   │   │   │   │               │   │   └── 20 > INDEX | RANGE SCAN (WS_SOLD_DATE_SK_INDEX)\n",
      "                │   │   │   │   │               │   └── 21 > TABLE ACCESS | BY INDEX ROWID (WEB_SALES)\n",
      "                │   │   │   │   │               └── 22 > TABLE ACCESS | FULL (WEB_SALES)\n",
      "                │   │   │   │   └── 23 > TABLE ACCESS | BY INDEX ROWID (CUSTOMER)\n",
      "                │   │   │   │       └── 24 > INDEX | UNIQUE SCAN (SYS_C0021431)\n",
      "                │   │   │   └── 25 > TABLE ACCESS | BY INDEX ROWID (CUSTOMER_ADDRESS)\n",
      "                │   │   │       └── 26 > INDEX | UNIQUE SCAN (SYS_C0021400)\n",
      "                │   │   └── 27 > INDEX | UNIQUE SCAN (SYS_C0021402)\n",
      "                │   └── 28 > TABLE ACCESS | BY INDEX ROWID (CUSTOMER_DEMOGRAPHICS)\n",
      "                └── 29 > VIEW (VW_SQ_2)\n",
      "                    └── 30 > HASH JOIN\n",
      "                        ├── 31 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                        └── 32 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > SORT\n",
      "    └── 2 > PX COORDINATOR\n",
      "        └── 3 > PX SEND | QC (RANDOM) (:TQ10001)\n",
      "            └── 4 > SORT\n",
      "                └── 5 > PX RECEIVE\n",
      "                    └── 6 > PX SEND | HASH (:TQ10000)\n",
      "                        └── 7 > SORT\n",
      "                            └── 8 > PX BLOCK\n",
      "                                └── 9 > INDEX | FAST FULL SCAN (CS_SHIP_ADDR_SK_INDEX)\n",
      "SQL  [11]\n",
      "11\n",
      "11\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [12]\n",
      "12\n",
      "12\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [13]\n",
      "13\n",
      "13\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [14]\n",
      "3\n",
      "14\n",
      "Access Predicate Difference detected with delta value [1859541101.9690514]\n",
      "Tree 1 difference at node [18] operator > TABLE ACCESS(FULL) on object [ITEM]\n",
      "Tree 2 difference at node [0] operator > SELECT STATEMENT(0) on object [0]\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > TEMP TABLE TRANSFORMATION\n",
      "    ├── 2 > LOAD AS SELECT (SYS_TEMP_0FD9F16E1_141942F5)\n",
      "    │   └── 3 > HASH JOIN\n",
      "    │       ├── 4 > TABLE ACCESS | FULL (ITEM)\n",
      "    │       └── 5 > VIEW\n",
      "    │           └── 6 > INTERSECTION\n",
      "    │               ├── 7 > INTERSECTION\n",
      "    │               │   ├── 8 > SORT\n",
      "    │               │   │   └── 9 > HASH JOIN\n",
      "    │               │   │       ├── 10 > TABLE ACCESS | FULL (ITEM)\n",
      "    │               │   │       └── 11 > NESTED LOOPS\n",
      "    │               │   │           ├── 12 > NESTED LOOPS\n",
      "    │               │   │           │   ├── 13 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "    │               │   │           │   └── 14 > INDEX | RANGE SCAN (SS_SOLD_DATE_SK_INDEX)\n",
      "    │               │   │           └── 15 > TABLE ACCESS | BY INDEX ROWID (STORE_SALES)\n",
      "    │               │   └── 16 > SORT\n",
      "    │               │       └── 17 > HASH JOIN\n",
      "    │               │           ├── 18 > TABLE ACCESS | FULL (ITEM)\n",
      "    │               │           └── 19 > NESTED LOOPS\n",
      "    │               │               ├── 20 > NESTED LOOPS\n",
      "    │               │               │   ├── 21 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "    │               │               │   └── 22 > INDEX | RANGE SCAN (CS_SOLD_DATE_SK_INDEX)\n",
      "    │               │               └── 23 > TABLE ACCESS | BY INDEX ROWID (CATALOG_SALES)\n",
      "    │               └── 24 > SORT\n",
      "    │                   └── 25 > HASH JOIN\n",
      "    │                       ├── 26 > TABLE ACCESS | FULL (ITEM)\n",
      "    │                       └── 27 > NESTED LOOPS\n",
      "    │                           ├── 28 > NESTED LOOPS\n",
      "    │                           │   ├── 29 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "    │                           │   └── 30 > INDEX | RANGE SCAN (WS_SOLD_DATE_SK_INDEX)\n",
      "    │                           └── 31 > TABLE ACCESS | BY INDEX ROWID (WEB_SALES)\n",
      "    ├── 32 > LOAD AS SELECT (SYS_TEMP_0FD9F16E2_141942F5)\n",
      "    │   └── 33 > SORT\n",
      "    │       └── 34 > VIEW\n",
      "    │           └── 35 > UNION-ALL\n",
      "    │               ├── 36 > HASH JOIN\n",
      "    │               │   ├── 37 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "    │               │   └── 38 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "    │               ├── 39 > NESTED LOOPS\n",
      "    │               │   ├── 40 > NESTED LOOPS\n",
      "    │               │   │   ├── 41 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "    │               │   │   └── 42 > INDEX | RANGE SCAN (CS_SOLD_DATE_SK_INDEX)\n",
      "    │               │   └── 43 > TABLE ACCESS | BY INDEX ROWID (CATALOG_SALES)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    │               └── 44 > NESTED LOOPS\n",
      "    │                   ├── 45 > NESTED LOOPS\n",
      "    │                   │   ├── 46 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "    │                   │   └── 47 > INDEX | RANGE SCAN (WS_SOLD_DATE_SK_INDEX)\n",
      "    │                   └── 48 > TABLE ACCESS | BY INDEX ROWID (WEB_SALES)\n",
      "    └── 49 > COUNT\n",
      "        └── 50 > VIEW\n",
      "            └── 51 > SORT\n",
      "                └── 52 > VIEW\n",
      "                    └── 53 > UNION-ALL\n",
      "                        ├── 54 > FILTER\n",
      "                        │   ├── 55 > HASH\n",
      "                        │   │   └── 56 > HASH JOIN\n",
      "                        │   │       ├── 57 > VIEW (VW_NSO_1)\n",
      "                        │   │       │   └── 58 > VIEW\n",
      "                        │   │       │       └── 59 > TABLE ACCESS | FULL (SYS_TEMP_0FD9F16E1_141942F5)\n",
      "                        │   │       └── 60 > HASH JOIN\n",
      "                        │   │           ├── 61 > TABLE ACCESS | FULL (ITEM)\n",
      "                        │   │           └── 62 > HASH JOIN\n",
      "                        │   │               ├── 63 > NESTED LOOPS\n",
      "                        │   │               │   ├── 64 > NESTED LOOPS\n",
      "                        │   │               │   │   ├── 65 > STATISTICS COLLECTOR\n",
      "                        │   │               │   │   │   └── 66 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                        │   │               │   │   └── 67 > INDEX | RANGE SCAN (SS_SOLD_DATE_SK_INDEX)\n",
      "                        │   │               │   └── 68 > TABLE ACCESS | BY INDEX ROWID (STORE_SALES)\n",
      "                        │   │               └── 69 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "                        │   └── 70 > VIEW\n",
      "                        │       └── 71 > TABLE ACCESS | FULL (SYS_TEMP_0FD9F16E2_141942F5)\n",
      "                        ├── 72 > FILTER\n",
      "                        │   ├── 73 > HASH\n",
      "                        │   │   └── 74 > HASH JOIN\n",
      "                        │   │       ├── 75 > VIEW (VW_NSO_2)\n",
      "                        │   │       │   └── 76 > VIEW\n",
      "                        │   │       │       └── 77 > TABLE ACCESS | FULL (SYS_TEMP_0FD9F16E1_141942F5)\n",
      "                        │   │       └── 78 > HASH JOIN\n",
      "                        │   │           ├── 79 > TABLE ACCESS | FULL (ITEM)\n",
      "                        │   │           └── 80 > HASH JOIN\n",
      "                        │   │               ├── 81 > NESTED LOOPS\n",
      "                        │   │               │   ├── 82 > NESTED LOOPS\n",
      "                        │   │               │   │   ├── 83 > STATISTICS COLLECTOR\n",
      "                        │   │               │   │   │   └── 84 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                        │   │               │   │   └── 85 > INDEX | RANGE SCAN (CS_SOLD_DATE_SK_INDEX)\n",
      "                        │   │               │   └── 86 > TABLE ACCESS | BY INDEX ROWID (CATALOG_SALES)\n",
      "                        │   │               └── 87 > TABLE ACCESS | FULL (CATALOG_SALES)\n",
      "                        │   └── 88 > VIEW\n",
      "                        │       └── 89 > TABLE ACCESS | FULL (SYS_TEMP_0FD9F16E2_141942F5)\n",
      "                        └── 90 > FILTER\n",
      "                            ├── 91 > HASH\n",
      "                            │   └── 92 > HASH JOIN\n",
      "                            │       ├── 93 > VIEW (VW_NSO_3)\n",
      "                            │       │   └── 94 > VIEW\n",
      "                            │       │       └── 95 > TABLE ACCESS | FULL (SYS_TEMP_0FD9F16E1_141942F5)\n",
      "                            │       └── 96 > HASH JOIN\n",
      "                            │           ├── 97 > TABLE ACCESS | FULL (ITEM)\n",
      "                            │           └── 98 > HASH JOIN\n",
      "                            │               ├── 99 > NESTED LOOPS\n",
      "                            │               │   ├── 100 > NESTED LOOPS\n",
      "                            │               │   │   ├── 101 > STATISTICS COLLECTOR\n",
      "                            │               │   │   │   └── 102 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                            │               │   │   └── 103 > INDEX | RANGE SCAN (WS_SOLD_DATE_SK_INDEX)\n",
      "                            │               │   └── 104 > TABLE ACCESS | BY INDEX ROWID (WEB_SALES)\n",
      "                            │               └── 105 > TABLE ACCESS | FULL (WEB_SALES)\n",
      "                            └── 106 > VIEW\n",
      "                                └── 107 > TABLE ACCESS | FULL (SYS_TEMP_0FD9F16E2_141942F5)\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > SORT\n",
      "    └── 2 > PX COORDINATOR\n",
      "        └── 3 > PX SEND | QC (RANDOM) (:TQ10001)\n",
      "            └── 4 > SORT\n",
      "                └── 5 > PX RECEIVE\n",
      "                    └── 6 > PX SEND | HASH (:TQ10000)\n",
      "                        └── 7 > SORT\n",
      "                            └── 8 > PX BLOCK\n",
      "                                └── 9 > INDEX | FAST FULL SCAN (CS_ORDER_NUMBER_INDEX)\n",
      "SQL  [15]\n",
      "15\n",
      "15\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [16]\n",
      "16\n",
      "16\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [17]\n",
      "17\n",
      "17\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [18]\n",
      "4\n",
      "18\n",
      "Access Predicate Difference detected with delta value [6010978043.414719]\n",
      "Tree 1 difference at node [11] operator > HASH JOIN(0) on object [0]\n",
      "Tree 2 difference at node [0] operator > SELECT STATEMENT(0) on object [0]\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > COUNT\n",
      "    └── 2 > VIEW\n",
      "        └── 3 > SORT\n",
      "            └── 4 > SORT\n",
      "                └── 5 > HASH JOIN\n",
      "                    ├── 6 > TABLE ACCESS | FULL (ITEM)\n",
      "                    └── 7 > HASH JOIN\n",
      "                        ├── 8 > TABLE ACCESS | FULL (CUSTOMER_DEMOGRAPHICS)\n",
      "                        └── 9 > HASH JOIN\n",
      "                            ├── 10 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                            └── 11 > HASH JOIN\n",
      "                                ├── 12 > HASH JOIN\n",
      "                                │   ├── 13 > HASH JOIN\n",
      "                                │   │   ├── 14 > TABLE ACCESS | FULL (CUSTOMER_ADDRESS)\n",
      "                                │   │   └── 15 > TABLE ACCESS | FULL (CUSTOMER)\n",
      "                                │   └── 16 > INDEX | FAST FULL SCAN (SYS_C0021402)\n",
      "                                └── 17 > TABLE ACCESS | FULL (CATALOG_SALES)\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > SORT\n",
      "    └── 2 > PX COORDINATOR\n",
      "        └── 3 > PX SEND | QC (RANDOM) (:TQ10001)\n",
      "            └── 4 > SORT\n",
      "                └── 5 > PX RECEIVE\n",
      "                    └── 6 > PX SEND | HASH (:TQ10000)\n",
      "                        └── 7 > SORT\n",
      "                            └── 8 > PX BLOCK\n",
      "                                └── 9 > INDEX | SAMPLE FAST FULL SCAN (INV_ITEM_SK_INDEX)\n",
      "SQL  [19]\n",
      "19\n",
      "19\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [20]\n",
      "20\n",
      "20\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [21]\n",
      "21\n",
      "21\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [22]\n",
      "5\n",
      "22\n",
      "Access Predicate Difference detected with delta value [262761361774.9174]\n",
      "Tree 1 difference at node [0] operator > SELECT STATEMENT(0) on object [0]\n",
      "Tree 2 difference at node [0] operator > SELECT STATEMENT(0) on object [0]\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > COUNT\n",
      "    └── 2 > VIEW\n",
      "        └── 3 > SORT\n",
      "            └── 4 > SORT\n",
      "                └── 5 > HASH JOIN\n",
      "                    ├── 6 > TABLE ACCESS | FULL (INVENTORY)\n",
      "                    └── 7 > NESTED LOOPS\n",
      "                        ├── 8 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                        └── 9 > TABLE ACCESS | FULL (ITEM)\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > SORT\n",
      "    └── 2 > PX COORDINATOR\n",
      "        └── 3 > PX SEND | QC (RANDOM) (:TQ10001)\n",
      "            └── 4 > SORT\n",
      "                └── 5 > PX RECEIVE\n",
      "                    └── 6 > PX SEND | HASH (:TQ10000)\n",
      "                        └── 7 > SORT\n",
      "                            └── 8 > PX BLOCK\n",
      "                                └── 9 > INDEX | SAMPLE FAST FULL SCAN (SS_CDEMO_SK_INDEX)\n",
      "SQL  [23]\n",
      "23\n",
      "23\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [24]\n",
      "24\n",
      "24\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [25]\n",
      "25\n",
      "25\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [26]\n",
      "26\n",
      "26\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [27]\n",
      "6\n",
      "27\n",
      "Access Predicate Difference detected with delta value [19325057429.816135]\n",
      "Tree 1 difference at node [3] operator > SORT(GROUP BY ROLLUP) on object [0]\n",
      "Tree 2 difference at node [0] operator > SELECT STATEMENT(0) on object [0]\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > COUNT\n",
      "    └── 2 > VIEW\n",
      "        └── 3 > SORT\n",
      "            └── 4 > HASH JOIN\n",
      "                ├── 5 > TABLE ACCESS | FULL (ITEM)\n",
      "                └── 6 > HASH JOIN\n",
      "                    ├── 7 > TABLE ACCESS | FULL (STORE)\n",
      "                    └── 8 > HASH JOIN\n",
      "                        ├── 9 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                        └── 10 > HASH JOIN\n",
      "                            ├── 11 > TABLE ACCESS | FULL (CUSTOMER_DEMOGRAPHICS)\n",
      "                            └── 12 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > SORT\n",
      "    └── 2 > PX COORDINATOR\n",
      "        └── 3 > PX SEND | QC (RANDOM) (:TQ10001)\n",
      "            └── 4 > SORT\n",
      "                └── 5 > PX RECEIVE\n",
      "                    └── 6 > PX SEND | HASH (:TQ10000)\n",
      "                        └── 7 > SORT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            └── 8 > PX BLOCK\n",
      "                                └── 9 > INDEX | FAST FULL SCAN (WS_SHIP_DATE_SK_INDEX)\n",
      "SQL  [28]\n",
      "28\n",
      "28\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [29]\n",
      "29\n",
      "29\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [30]\n",
      "30\n",
      "30\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [31]\n",
      "31\n",
      "31\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [32]\n",
      "32\n",
      "32\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [33]\n",
      "33\n",
      "33\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [34]\n",
      "34\n",
      "34\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [35]\n",
      "7\n",
      "35\n",
      "Access Predicate Difference detected with delta value [2146172847.4319715]\n",
      "Tree 1 difference at node [21] operator > TABLE ACCESS(FULL) on object [WEB_SALES]\n",
      "Tree 2 difference at node [0] operator > SELECT STATEMENT(0) on object [0]\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > COUNT\n",
      "    └── 2 > VIEW\n",
      "        └── 3 > SORT\n",
      "            └── 4 > NESTED LOOPS\n",
      "                ├── 5 > NESTED LOOPS\n",
      "                │   ├── 6 > NESTED LOOPS\n",
      "                │   │   ├── 7 > NESTED LOOPS\n",
      "                │   │   │   ├── 8 > VIEW (VW_SQ_1)\n",
      "                │   │   │   │   └── 9 > HASH\n",
      "                │   │   │   │       └── 10 > UNION-ALL\n",
      "                │   │   │   │           ├── 11 > HASH JOIN\n",
      "                │   │   │   │           │   ├── 12 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                │   │   │   │           │   └── 13 > TABLE ACCESS | FULL (CATALOG_SALES)\n",
      "                │   │   │   │           └── 14 > HASH JOIN\n",
      "                │   │   │   │               ├── 15 > NESTED LOOPS\n",
      "                │   │   │   │               │   ├── 16 > NESTED LOOPS\n",
      "                │   │   │   │               │   │   ├── 17 > STATISTICS COLLECTOR\n",
      "                │   │   │   │               │   │   │   └── 18 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                │   │   │   │               │   │   └── 19 > INDEX | RANGE SCAN (WS_SOLD_DATE_SK_INDEX)\n",
      "                │   │   │   │               │   └── 20 > TABLE ACCESS | BY INDEX ROWID (WEB_SALES)\n",
      "                │   │   │   │               └── 21 > TABLE ACCESS | FULL (WEB_SALES)\n",
      "                │   │   │   └── 22 > TABLE ACCESS | BY INDEX ROWID (CUSTOMER)\n",
      "                │   │   │       └── 23 > INDEX | UNIQUE SCAN (SYS_C0021431)\n",
      "                │   │   └── 24 > TABLE ACCESS | BY INDEX ROWID (CUSTOMER_ADDRESS)\n",
      "                │   │       └── 25 > INDEX | UNIQUE SCAN (SYS_C0021400)\n",
      "                │   └── 26 > TABLE ACCESS | BY INDEX ROWID (CUSTOMER_DEMOGRAPHICS)\n",
      "                │       └── 27 > INDEX | UNIQUE SCAN (SYS_C0021402)\n",
      "                └── 28 > VIEW PUSHED PREDICATE (VW_SQ_2)\n",
      "                    └── 29 > NESTED LOOPS\n",
      "                        ├── 30 > TABLE ACCESS | BY INDEX ROWID BATCHED (STORE_SALES)\n",
      "                        │   └── 31 > INDEX | RANGE SCAN (SS_CUSTOMER_SK_INDEX)\n",
      "                        └── 32 > TABLE ACCESS | BY INDEX ROWID (DATE_DIM)\n",
      "                            └── 33 > INDEX | UNIQUE SCAN (SYS_C0021405)\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > SORT\n",
      "    └── 2 > PX COORDINATOR\n",
      "        └── 3 > PX SEND | QC (RANDOM) (:TQ10001)\n",
      "            └── 4 > SORT\n",
      "                └── 5 > PX RECEIVE\n",
      "                    └── 6 > PX SEND | HASH (:TQ10000)\n",
      "                        └── 7 > SORT\n",
      "                            └── 8 > PX BLOCK\n",
      "                                └── 9 > INDEX | FAST FULL SCAN (WS_ITEM_SK_INDEX)\n",
      "SQL  [36]\n",
      "8\n",
      "36\n",
      "Access Predicate Difference detected with delta value [22173524150.556408]\n",
      "Tree 1 difference at node [3] operator > SORT(ORDER BY STOPKEY) on object [0]\n",
      "Tree 2 difference at node [0] operator > SELECT STATEMENT(0) on object [0]\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > COUNT\n",
      "    └── 2 > VIEW\n",
      "        └── 3 > SORT\n",
      "            └── 4 > WINDOW\n",
      "                └── 5 > SORT\n",
      "                    └── 6 > HASH JOIN\n",
      "                        ├── 7 > TABLE ACCESS | FULL (ITEM)\n",
      "                        └── 8 > HASH JOIN\n",
      "                            ├── 9 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                            └── 10 > HASH JOIN\n",
      "                                ├── 11 > TABLE ACCESS | FULL (STORE)\n",
      "                                └── 12 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > SORT\n",
      "    └── 2 > PX COORDINATOR\n",
      "        └── 3 > PX SEND | QC (RANDOM) (:TQ10001)\n",
      "            └── 4 > SORT\n",
      "                └── 5 > PX RECEIVE\n",
      "                    └── 6 > PX SEND | HASH (:TQ10000)\n",
      "                        └── 7 > SORT\n",
      "                            └── 8 > PX BLOCK\n",
      "                                └── 9 > INDEX | FAST FULL SCAN (WS_WEB_SITE_SK_INDEX)\n",
      "SQL  [37]\n",
      "37\n",
      "37\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [38]\n",
      "38\n",
      "38\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [39]\n",
      "39\n",
      "39\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [40]\n",
      "40\n",
      "40\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [41]\n",
      "41\n",
      "41\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [42]\n",
      "42\n",
      "42\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [43]\n",
      "43\n",
      "43\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [44]\n",
      "44\n",
      "44\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [45]\n",
      "45\n",
      "45\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [46]\n",
      "46\n",
      "46\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [47]\n",
      "47\n",
      "47\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [48]\n",
      "48\n",
      "48\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [49]\n",
      "49\n",
      "49\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [50]\n",
      "50\n",
      "50\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [51]\n",
      "9\n",
      "51\n",
      "Access Predicate Difference detected with delta value [35795003126.86023]\n",
      "Tree 1 difference at node [0] operator > SELECT STATEMENT(0) on object [0]\n",
      "Tree 2 difference at node [7] operator > TABLE ACCESS(FULL) on object [CUSTOMER_ADDRESS]\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > COUNT\n",
      "    └── 2 > VIEW\n",
      "        └── 3 > SORT\n",
      "            └── 4 > VIEW\n",
      "                └── 5 > WINDOW\n",
      "                    └── 6 > VIEW (VW_FOJ_0)\n",
      "                        └── 7 > HASH JOIN\n",
      "                            ├── 8 > VIEW\n",
      "                            │   └── 9 > WINDOW\n",
      "                            │       └── 10 > SORT\n",
      "                            │           └── 11 > HASH JOIN\n",
      "                            │               ├── 12 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                            │               └── 13 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "                            └── 14 > VIEW\n",
      "                                └── 15 > WINDOW\n",
      "                                    └── 16 > SORT\n",
      "                                        └── 17 > NESTED LOOPS\n",
      "                                            ├── 18 > NESTED LOOPS\n",
      "                                            │   ├── 19 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                                            │   └── 20 > INDEX | RANGE SCAN (WS_SOLD_DATE_SK_INDEX)\n",
      "                                            └── 21 > TABLE ACCESS | BY INDEX ROWID (WEB_SALES)\n",
      "0 > SELECT STATEMENT\n",
      "├── 1 > COUNT\n",
      "├── 1 > COUNT\n",
      "├── 1 > COUNT\n",
      "└── 1 > COUNT\n",
      "    ├── 2 > VIEW\n",
      "    ├── 2 > VIEW\n",
      "    ├── 2 > VIEW\n",
      "    └── 2 > VIEW\n",
      "        ├── 3 > SORT\n",
      "        ├── 3 > SORT\n",
      "        ├── 3 > SORT\n",
      "        └── 3 > SORT\n",
      "            ├── 4 > NESTED LOOPS\n",
      "            ├── 4 > NESTED LOOPS\n",
      "            ├── 4 > NESTED LOOPS\n",
      "            └── 4 > NESTED LOOPS\n",
      "                ├── 5 > NESTED LOOPS\n",
      "                ├── 5 > NESTED LOOPS\n",
      "                ├── 5 > NESTED LOOPS\n",
      "                ├── 5 > NESTED LOOPS\n",
      "                │   ├── 6 > HASH JOIN\n",
      "                │   ├── 6 > HASH JOIN\n",
      "                │   ├── 6 > HASH JOIN\n",
      "                │   ├── 6 > HASH JOIN\n",
      "                │   │   ├── 7 > TABLE ACCESS | FULL (CUSTOMER_ADDRESS)\n",
      "                │   │   ├── 7 > TABLE ACCESS | FULL (CUSTOMER_ADDRESS)\n",
      "                │   │   ├── 7 > TABLE ACCESS | FULL (CUSTOMER_ADDRESS)\n",
      "                │   │   ├── 7 > TABLE ACCESS | FULL (CUSTOMER_ADDRESS)\n",
      "                │   │   ├── 8 > NESTED LOOPS\n",
      "                │   │   ├── 8 > NESTED LOOPS\n",
      "                │   │   ├── 8 > NESTED LOOPS\n",
      "                │   │   └── 8 > NESTED LOOPS\n",
      "                │   │       ├── 9 > NESTED LOOPS\n",
      "                │   │       ├── 9 > NESTED LOOPS\n",
      "                │   │       ├── 9 > NESTED LOOPS\n",
      "                │   │       ├── 9 > NESTED LOOPS\n",
      "                │   │       │   ├── 10 > VIEW (VW_SQ_1)\n",
      "                │   │       │   ├── 10 > VIEW (VW_SQ_1)\n",
      "                │   │       │   ├── 10 > VIEW (VW_SQ_1)\n",
      "                │   │       │   ├── 10 > VIEW (VW_SQ_1)\n",
      "                │   │       │   │   ├── 11 > HASH\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                │   │       │   │   ├── 11 > HASH\n",
      "                │   │       │   │   ├── 11 > HASH\n",
      "                │   │       │   │   └── 11 > HASH\n",
      "                │   │       │   │       ├── 12 > UNION-ALL\n",
      "                │   │       │   │       ├── 12 > UNION-ALL\n",
      "                │   │       │   │       ├── 12 > UNION-ALL\n",
      "                │   │       │   │       └── 12 > UNION-ALL\n",
      "                │   │       │   │           ├── 13 > HASH JOIN\n",
      "                │   │       │   │           ├── 13 > HASH JOIN\n",
      "                │   │       │   │           ├── 13 > HASH JOIN\n",
      "                │   │       │   │           ├── 13 > HASH JOIN\n",
      "                │   │       │   │           │   ├── 14 > NESTED LOOPS\n",
      "                │   │       │   │           │   ├── 14 > NESTED LOOPS\n",
      "                │   │       │   │           │   ├── 14 > NESTED LOOPS\n",
      "                │   │       │   │           │   ├── 14 > NESTED LOOPS\n",
      "                │   │       │   │           │   │   ├── 15 > NESTED LOOPS\n",
      "                │   │       │   │           │   │   ├── 15 > NESTED LOOPS\n",
      "                │   │       │   │           │   │   ├── 15 > NESTED LOOPS\n",
      "                │   │       │   │           │   │   ├── 15 > NESTED LOOPS\n",
      "                │   │       │   │           │   │   │   ├── 16 > STATISTICS COLLECTOR\n",
      "                │   │       │   │           │   │   │   ├── 16 > STATISTICS COLLECTOR\n",
      "                │   │       │   │           │   │   │   ├── 16 > STATISTICS COLLECTOR\n",
      "                │   │       │   │           │   │   │   ├── 16 > STATISTICS COLLECTOR\n",
      "                │   │       │   │           │   │   │   │   ├── 17 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                │   │       │   │           │   │   │   │   ├── 17 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                │   │       │   │           │   │   │   │   ├── 17 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                │   │       │   │           │   │   │   │   └── 17 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                │   │       │   │           │   │   │   ├── 18 > INDEX | RANGE SCAN (CS_SOLD_DATE_SK_INDEX)\n",
      "                │   │       │   │           │   │   │   ├── 18 > INDEX | RANGE SCAN (CS_SOLD_DATE_SK_INDEX)\n",
      "                │   │       │   │           │   │   │   ├── 18 > INDEX | RANGE SCAN (CS_SOLD_DATE_SK_INDEX)\n",
      "                │   │       │   │           │   │   │   └── 18 > INDEX | RANGE SCAN (CS_SOLD_DATE_SK_INDEX)\n",
      "                │   │       │   │           │   │   ├── 19 > TABLE ACCESS | BY INDEX ROWID (CATALOG_SALES)\n",
      "                │   │       │   │           │   │   ├── 19 > TABLE ACCESS | BY INDEX ROWID (CATALOG_SALES)\n",
      "                │   │       │   │           │   │   ├── 19 > TABLE ACCESS | BY INDEX ROWID (CATALOG_SALES)\n",
      "                │   │       │   │           │   │   └── 19 > TABLE ACCESS | BY INDEX ROWID (CATALOG_SALES)\n",
      "                │   │       │   │           │   ├── 20 > TABLE ACCESS | FULL (CATALOG_SALES)\n",
      "                │   │       │   │           │   ├── 20 > TABLE ACCESS | FULL (CATALOG_SALES)\n",
      "                │   │       │   │           │   ├── 20 > TABLE ACCESS | FULL (CATALOG_SALES)\n",
      "                │   │       │   │           │   └── 20 > TABLE ACCESS | FULL (CATALOG_SALES)\n",
      "                │   │       │   │           ├── 21 > HASH JOIN\n",
      "                │   │       │   │           ├── 21 > HASH JOIN\n",
      "                │   │       │   │           ├── 21 > HASH JOIN\n",
      "                │   │       │   │           └── 21 > HASH JOIN\n",
      "                │   │       │   │               ├── 22 > NESTED LOOPS\n",
      "                │   │       │   │               ├── 22 > NESTED LOOPS\n",
      "                │   │       │   │               ├── 22 > NESTED LOOPS\n",
      "                │   │       │   │               ├── 22 > NESTED LOOPS\n",
      "                │   │       │   │               │   ├── 23 > NESTED LOOPS\n",
      "                │   │       │   │               │   ├── 23 > NESTED LOOPS\n",
      "                │   │       │   │               │   ├── 23 > NESTED LOOPS\n",
      "                │   │       │   │               │   ├── 23 > NESTED LOOPS\n",
      "                │   │       │   │               │   │   ├── 24 > STATISTICS COLLECTOR\n",
      "                │   │       │   │               │   │   ├── 24 > STATISTICS COLLECTOR\n",
      "                │   │       │   │               │   │   ├── 24 > STATISTICS COLLECTOR\n",
      "                │   │       │   │               │   │   ├── 24 > STATISTICS COLLECTOR\n",
      "                │   │       │   │               │   │   │   ├── 25 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                │   │       │   │               │   │   │   ├── 25 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                │   │       │   │               │   │   │   ├── 25 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                │   │       │   │               │   │   │   └── 25 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                │   │       │   │               │   │   ├── 26 > INDEX | RANGE SCAN (WS_SOLD_DATE_SK_INDEX)\n",
      "                │   │       │   │               │   │   ├── 26 > INDEX | RANGE SCAN (WS_SOLD_DATE_SK_INDEX)\n",
      "                │   │       │   │               │   │   ├── 26 > INDEX | RANGE SCAN (WS_SOLD_DATE_SK_INDEX)\n",
      "                │   │       │   │               │   │   └── 26 > INDEX | RANGE SCAN (WS_SOLD_DATE_SK_INDEX)\n",
      "                │   │       │   │               │   ├── 27 > TABLE ACCESS | BY INDEX ROWID (WEB_SALES)\n",
      "                │   │       │   │               │   ├── 27 > TABLE ACCESS | BY INDEX ROWID (WEB_SALES)\n",
      "                │   │       │   │               │   ├── 27 > TABLE ACCESS | BY INDEX ROWID (WEB_SALES)\n",
      "                │   │       │   │               │   └── 27 > TABLE ACCESS | BY INDEX ROWID (WEB_SALES)\n",
      "                │   │       │   │               ├── 28 > TABLE ACCESS | FULL (WEB_SALES)\n",
      "                │   │       │   │               ├── 28 > TABLE ACCESS | FULL (WEB_SALES)\n",
      "                │   │       │   │               ├── 28 > TABLE ACCESS | FULL (WEB_SALES)\n",
      "                │   │       │   │               └── 28 > TABLE ACCESS | FULL (WEB_SALES)\n",
      "                │   │       │   ├── 29 > INDEX | UNIQUE SCAN (SYS_C0021431)\n",
      "                │   │       │   ├── 29 > INDEX | UNIQUE SCAN (SYS_C0021431)\n",
      "                │   │       │   ├── 29 > INDEX | UNIQUE SCAN (SYS_C0021431)\n",
      "                │   │       │   └── 29 > INDEX | UNIQUE SCAN (SYS_C0021431)\n",
      "                │   │       ├── 30 > TABLE ACCESS | BY INDEX ROWID (CUSTOMER)\n",
      "                │   │       ├── 30 > TABLE ACCESS | BY INDEX ROWID (CUSTOMER)\n",
      "                │   │       ├── 30 > TABLE ACCESS | BY INDEX ROWID (CUSTOMER)\n",
      "                │   │       └── 30 > TABLE ACCESS | BY INDEX ROWID (CUSTOMER)\n",
      "                │   ├── 31 > TABLE ACCESS | BY INDEX ROWID (CUSTOMER_DEMOGRAPHICS)\n",
      "                │   ├── 31 > TABLE ACCESS | BY INDEX ROWID (CUSTOMER_DEMOGRAPHICS)\n",
      "                │   ├── 31 > TABLE ACCESS | BY INDEX ROWID (CUSTOMER_DEMOGRAPHICS)\n",
      "                │   └── 31 > TABLE ACCESS | BY INDEX ROWID (CUSTOMER_DEMOGRAPHICS)\n",
      "                │       ├── 32 > INDEX | UNIQUE SCAN (SYS_C0021402)\n",
      "                │       ├── 32 > INDEX | UNIQUE SCAN (SYS_C0021402)\n",
      "                │       ├── 32 > INDEX | UNIQUE SCAN (SYS_C0021402)\n",
      "                │       └── 32 > INDEX | UNIQUE SCAN (SYS_C0021402)\n",
      "                ├── 33 > VIEW PUSHED PREDICATE (VW_SQ_2)\n",
      "                ├── 33 > VIEW PUSHED PREDICATE (VW_SQ_2)\n",
      "                ├── 33 > VIEW PUSHED PREDICATE (VW_SQ_2)\n",
      "                └── 33 > VIEW PUSHED PREDICATE (VW_SQ_2)\n",
      "                    ├── 34 > NESTED LOOPS\n",
      "                    ├── 34 > NESTED LOOPS\n",
      "                    ├── 34 > NESTED LOOPS\n",
      "                    └── 34 > NESTED LOOPS\n",
      "                        ├── 35 > TABLE ACCESS | BY INDEX ROWID BATCHED (STORE_SALES)\n",
      "                        ├── 35 > TABLE ACCESS | BY INDEX ROWID BATCHED (STORE_SALES)\n",
      "                        ├── 35 > TABLE ACCESS | BY INDEX ROWID BATCHED (STORE_SALES)\n",
      "                        ├── 35 > TABLE ACCESS | BY INDEX ROWID BATCHED (STORE_SALES)\n",
      "                        │   ├── 36 > INDEX | RANGE SCAN (SS_CUSTOMER_SK_INDEX)\n",
      "                        │   ├── 36 > INDEX | RANGE SCAN (SS_CUSTOMER_SK_INDEX)\n",
      "                        │   ├── 36 > INDEX | RANGE SCAN (SS_CUSTOMER_SK_INDEX)\n",
      "                        │   └── 36 > INDEX | RANGE SCAN (SS_CUSTOMER_SK_INDEX)\n",
      "                        ├── 37 > TABLE ACCESS | BY INDEX ROWID (DATE_DIM)\n",
      "                        ├── 37 > TABLE ACCESS | BY INDEX ROWID (DATE_DIM)\n",
      "                        ├── 37 > TABLE ACCESS | BY INDEX ROWID (DATE_DIM)\n",
      "                        └── 37 > TABLE ACCESS | BY INDEX ROWID (DATE_DIM)\n",
      "                            ├── 38 > INDEX | UNIQUE SCAN (SYS_C0021405)\n",
      "                            ├── 38 > INDEX | UNIQUE SCAN (SYS_C0021405)\n",
      "                            ├── 38 > INDEX | UNIQUE SCAN (SYS_C0021405)\n",
      "                            └── 38 > INDEX | UNIQUE SCAN (SYS_C0021405)\n",
      "SQL  [52]\n",
      "52\n",
      "52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No changes detected with delta value of [0.0]\n",
      "SQL  [53]\n",
      "53\n",
      "53\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [54]\n",
      "54\n",
      "54\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [55]\n",
      "55\n",
      "55\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [56]\n",
      "56\n",
      "56\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [57]\n",
      "57\n",
      "57\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [58]\n",
      "58\n",
      "58\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [59]\n",
      "59\n",
      "59\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [60]\n",
      "60\n",
      "60\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [61]\n",
      "61\n",
      "61\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [62]\n",
      "62\n",
      "62\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [63]\n",
      "63\n",
      "63\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [64]\n",
      "64\n",
      "64\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [65]\n",
      "65\n",
      "65\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [66]\n",
      "66\n",
      "66\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [67]\n",
      "10\n",
      "73\n",
      "Access Predicate Difference detected with delta value [40958222349.868454]\n",
      "Tree 1 difference at node [0] operator > SELECT STATEMENT(0) on object [0]\n",
      "Tree 2 difference at node [11] operator > NESTED LOOPS(0) on object [0]\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > COUNT\n",
      "    └── 2 > VIEW\n",
      "        └── 3 > SORT\n",
      "            └── 4 > VIEW\n",
      "                └── 5 > WINDOW\n",
      "                    └── 6 > VIEW\n",
      "                        └── 7 > SORT\n",
      "                            └── 8 > HASH JOIN\n",
      "                                ├── 9 > TABLE ACCESS | FULL (STORE)\n",
      "                                └── 10 > HASH JOIN\n",
      "                                    ├── 11 > TABLE ACCESS | FULL (ITEM)\n",
      "                                    └── 12 > HASH JOIN\n",
      "                                        ├── 13 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                                        └── 14 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > TEMP TABLE TRANSFORMATION\n",
      "    ├── 2 > LOAD AS SELECT\n",
      "    │   └── 3 > HASH JOIN\n",
      "    │       ├── 4 > TABLE ACCESS | FULL (WEB_SALES)\n",
      "    │       └── 5 > TABLE ACCESS | FULL (WEB_SALES)\n",
      "    └── 6 > COUNT\n",
      "        └── 7 > VIEW\n",
      "            └── 8 > SORT\n",
      "                └── 9 > FILTER\n",
      "                    ├── 10 > FILTER\n",
      "                    │   └── 11 > NESTED LOOPS\n",
      "                    │       ├── 12 > NESTED LOOPS\n",
      "                    │       │   ├── 13 > NESTED LOOPS\n",
      "                    │       │   │   ├── 14 > MERGE JOIN\n",
      "                    │       │   │   │   ├── 15 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                    │       │   │   │   └── 16 > BUFFER\n",
      "                    │       │   │   │       └── 17 > TABLE ACCESS | FULL (CUSTOMER_ADDRESS)\n",
      "                    │       │   │   └── 18 > TABLE ACCESS | BY INDEX ROWID BATCHED (WEB_SALES)\n",
      "                    │       │   │       └── 19 > INDEX | RANGE SCAN (WS_SHIP_ADDR_SK_INDEX)\n",
      "                    │       │   └── 20 > INDEX | UNIQUE SCAN (SYS_C0021434)\n",
      "                    │       └── 21 > TABLE ACCESS | BY INDEX ROWID (WEB_SITE)\n",
      "                    ├── 22 > VIEW\n",
      "                    │   └── 23 > TABLE ACCESS | FULL (SYS_TEMP_0FD9D69ED_141942F5)\n",
      "                    └── 24 > MERGE JOIN\n",
      "                        ├── 25 > VIEW\n",
      "                        │   └── 26 > TABLE ACCESS | FULL (SYS_TEMP_0FD9D69ED_141942F5)\n",
      "                        └── 27 > SORT\n",
      "                            └── 28 > INDEX | RANGE SCAN (WR_ORDER_NUMBER_INDEX)\n",
      "SQL  [68]\n",
      "74\n",
      "74\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [69]\n",
      "75\n",
      "75\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [70]\n",
      "11\n",
      "76\n",
      "Access Predicate Difference detected with delta value [37844157715.55654]\n",
      "Tree 1 difference at node [0] operator > SELECT STATEMENT(0) on object [0]\n",
      "Tree 2 difference at node [24] operator > TABLE ACCESS(FULL) on object [STORE_SALES]\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > COUNT\n",
      "    └── 2 > VIEW\n",
      "        └── 3 > SORT\n",
      "            └── 4 > WINDOW\n",
      "                └── 5 > SORT\n",
      "                    └── 6 > HASH JOIN\n",
      "                        ├── 7 > VIEW (VW_NSO_1)\n",
      "                        │   └── 8 > VIEW\n",
      "                        │       └── 9 > WINDOW\n",
      "                        │           └── 10 > HASH\n",
      "                        │               └── 11 > HASH JOIN\n",
      "                        │                   ├── 12 > TABLE ACCESS | FULL (STORE)\n",
      "                        │                   └── 13 > NESTED LOOPS\n",
      "                        │                       ├── 14 > NESTED LOOPS\n",
      "                        │                       │   ├── 15 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                        │                       │   └── 16 > INDEX | RANGE SCAN (SS_SOLD_DATE_SK_INDEX)\n",
      "                        │                       └── 17 > TABLE ACCESS | BY INDEX ROWID (STORE_SALES)\n",
      "                        └── 18 > HASH JOIN\n",
      "                            ├── 19 > TABLE ACCESS | FULL (STORE)\n",
      "                            └── 20 > HASH JOIN\n",
      "                                ├── 21 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                                └── 22 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "0 > SELECT STATEMENT\n",
      "├── 1 > SORT\n",
      "│   └── 2 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "├── 3 > SORT\n",
      "│   └── 4 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "├── 5 > SORT\n",
      "│   └── 6 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "├── 7 > SORT\n",
      "│   └── 8 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "├── 9 > SORT\n",
      "│   └── 10 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "├── 11 > SORT\n",
      "│   └── 12 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "├── 13 > SORT\n",
      "│   └── 14 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "├── 15 > SORT\n",
      "│   └── 16 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "├── 17 > SORT\n",
      "│   └── 18 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "├── 19 > SORT\n",
      "│   └── 20 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "├── 21 > SORT\n",
      "│   └── 22 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "├── 23 > SORT\n",
      "│   └── 24 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "├── 25 > SORT\n",
      "│   └── 26 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "├── 27 > SORT\n",
      "│   └── 28 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "├── 29 > SORT\n",
      "│   └── 30 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "└── 31 > INDEX | UNIQUE SCAN (SYS_C0021417)\n",
      "SQL  [71]\n",
      "77\n",
      "77\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [72]\n",
      "78\n",
      "78\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [73]\n",
      "79\n",
      "79\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [74]\n",
      "80\n",
      "80\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [75]\n",
      "81\n",
      "81\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [76]\n",
      "82\n",
      "82\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [77]\n",
      "12\n",
      "83\n",
      "Access Predicate Difference detected with delta value [12694880475.90292]\n",
      "Tree 1 difference at node [39] operator > HASH(GROUP BY) on object [0]\n",
      "Tree 2 difference at node [0] operator > SELECT STATEMENT(0) on object [0]\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > COUNT\n",
      "    └── 2 > VIEW\n",
      "        └── 3 > SORT\n",
      "            └── 4 > VIEW\n",
      "                └── 5 > UNION-ALL\n",
      "                    ├── 6 > HASH JOIN\n",
      "                    │   ├── 7 > VIEW\n",
      "                    │   │   └── 8 > HASH\n",
      "                    │   │       └── 9 > HASH JOIN\n",
      "                    │   │           ├── 10 > INDEX | FULL SCAN (SYS_C0021425)\n",
      "                    │   │           └── 11 > NESTED LOOPS\n",
      "                    │   │               ├── 12 > NESTED LOOPS\n",
      "                    │   │               │   ├── 13 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                    │   │               │   └── 14 > INDEX | RANGE SCAN (SS_SOLD_DATE_SK_INDEX)\n",
      "                    │   │               └── 15 > TABLE ACCESS | BY INDEX ROWID (STORE_SALES)\n",
      "                    │   └── 16 > VIEW\n",
      "                    │       └── 17 > HASH\n",
      "                    │           └── 18 > NESTED LOOPS\n",
      "                    │               ├── 19 > HASH JOIN\n",
      "                    │               │   ├── 20 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                    │               │   └── 21 > TABLE ACCESS | FULL (STORE_RETURNS)\n",
      "                    │               └── 22 > INDEX | UNIQUE SCAN (SYS_C0021425)\n",
      "                    ├── 23 > MERGE JOIN\n",
      "                    │   ├── 24 > VIEW\n",
      "                    │   │   └── 25 > HASH\n",
      "                    │   │       └── 26 > HASH JOIN\n",
      "                    │   │           ├── 27 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                    │   │           └── 28 > TABLE ACCESS | FULL (CATALOG_SALES)\n",
      "                    │   └── 29 > BUFFER\n",
      "                    │       └── 30 > VIEW\n",
      "                    │           └── 31 > HASH\n",
      "                    │               └── 32 > NESTED LOOPS\n",
      "                    │                   ├── 33 > NESTED LOOPS\n",
      "                    │                   │   ├── 34 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                    │                   │   └── 35 > INDEX | RANGE SCAN (CR_RETURNED_DATE_SK_INDEX)\n",
      "                    │                   └── 36 > TABLE ACCESS | BY INDEX ROWID (CATALOG_RETURNS)\n",
      "                    └── 37 > HASH JOIN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        ├── 38 > VIEW\n",
      "                        │   └── 39 > HASH\n",
      "                        │       └── 40 > NESTED LOOPS\n",
      "                        │           ├── 41 > NESTED LOOPS\n",
      "                        │           │   ├── 42 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                        │           │   └── 43 > TABLE ACCESS | BY INDEX ROWID BATCHED (WEB_SALES)\n",
      "                        │           │       └── 44 > INDEX | RANGE SCAN (WS_SOLD_DATE_SK_INDEX)\n",
      "                        │           └── 45 > INDEX | UNIQUE SCAN (SYS_C0021442)\n",
      "                        └── 46 > VIEW\n",
      "                            └── 47 > HASH\n",
      "                                └── 48 > NESTED LOOPS\n",
      "                                    ├── 49 > NESTED LOOPS\n",
      "                                    │   ├── 50 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                                    │   └── 51 > TABLE ACCESS | BY INDEX ROWID BATCHED (WEB_RETURNS)\n",
      "                                    │       └── 52 > INDEX | RANGE SCAN (WR_RETURNED_DATE_SK_INDEX)\n",
      "                                    └── 53 > INDEX | UNIQUE SCAN (SYS_C0021442)\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > TEMP TABLE TRANSFORMATION\n",
      "    ├── 2 > LOAD AS SELECT\n",
      "    │   └── 3 > UNION-ALL\n",
      "    │       ├── 4 > HASH\n",
      "    │       │   └── 5 > HASH JOIN\n",
      "    │       │       ├── 6 > VIEW (VW_GBC_10)\n",
      "    │       │       │   └── 7 > HASH\n",
      "    │       │       │       └── 8 > NESTED LOOPS\n",
      "    │       │       │           ├── 9 > NESTED LOOPS\n",
      "    │       │       │           │   ├── 10 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "    │       │       │           │   └── 11 > INDEX | RANGE SCAN (SS_SOLD_DATE_SK_INDEX)\n",
      "    │       │       │           └── 12 > TABLE ACCESS | BY INDEX ROWID (STORE_SALES)\n",
      "    │       │       └── 13 > TABLE ACCESS | FULL (CUSTOMER)\n",
      "    │       └── 14 > HASH\n",
      "    │           └── 15 > HASH JOIN\n",
      "    │               ├── 16 > VIEW (VW_GBC_20)\n",
      "    │               │   └── 17 > HASH\n",
      "    │               │       └── 18 > NESTED LOOPS\n",
      "    │               │           ├── 19 > NESTED LOOPS\n",
      "    │               │           │   ├── 20 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "    │               │           │   └── 21 > INDEX | RANGE SCAN (WS_SOLD_DATE_SK_INDEX)\n",
      "    │               │           └── 22 > TABLE ACCESS | BY INDEX ROWID (WEB_SALES)\n",
      "    │               └── 23 > TABLE ACCESS | FULL (CUSTOMER)\n",
      "    └── 24 > COUNT\n",
      "        └── 25 > VIEW\n",
      "            └── 26 > SORT\n",
      "                └── 27 > HASH JOIN\n",
      "                    ├── 28 > HASH JOIN\n",
      "                    │   ├── 29 > HASH JOIN\n",
      "                    │   │   ├── 30 > VIEW\n",
      "                    │   │   │   └── 31 > TABLE ACCESS | FULL (SYS_TEMP_0FD9D69FF_141942F5)\n",
      "                    │   │   └── 32 > VIEW\n",
      "                    │   │       └── 33 > TABLE ACCESS | FULL (SYS_TEMP_0FD9D69FF_141942F5)\n",
      "                    │   └── 34 > VIEW\n",
      "                    │       └── 35 > TABLE ACCESS | FULL (SYS_TEMP_0FD9D69FF_141942F5)\n",
      "                    └── 36 > VIEW\n",
      "                        └── 37 > TABLE ACCESS | FULL (SYS_TEMP_0FD9D69FF_141942F5)\n",
      "SQL  [78]\n",
      "84\n",
      "84\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [79]\n",
      "85\n",
      "85\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [80]\n",
      "13\n",
      "86\n",
      "Access Predicate Difference detected with delta value [2566601260.6064596]\n",
      "Tree 1 difference at node [57] operator > NESTED LOOPS(0) on object [0]\n",
      "Tree 2 difference at node [0] operator > SELECT STATEMENT(0) on object [0]\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > COUNT\n",
      "    └── 2 > VIEW\n",
      "        └── 3 > SORT\n",
      "            └── 4 > VIEW\n",
      "                └── 5 > UNION-ALL\n",
      "                    ├── 6 > HASH\n",
      "                    │   └── 7 > HASH JOIN\n",
      "                    │       ├── 8 > NESTED LOOPS\n",
      "                    │       │   ├── 9 > NESTED LOOPS\n",
      "                    │       │   │   ├── 10 > HASH JOIN\n",
      "                    │       │   │   │   ├── 11 > TABLE ACCESS | FULL (PROMOTION)\n",
      "                    │       │   │   │   └── 12 > HASH JOIN\n",
      "                    │       │   │   │       ├── 13 > TABLE ACCESS | FULL (ITEM)\n",
      "                    │       │   │   │       └── 14 > HASH JOIN\n",
      "                    │       │   │   │           ├── 15 > NESTED LOOPS\n",
      "                    │       │   │   │           │   ├── 16 > NESTED LOOPS\n",
      "                    │       │   │   │           │   │   ├── 17 > STATISTICS COLLECTOR\n",
      "                    │       │   │   │           │   │   │   └── 18 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                    │       │   │   │           │   │   └── 19 > INDEX | RANGE SCAN (SS_SOLD_DATE_SK_INDEX)\n",
      "                    │       │   │   │           │   └── 20 > TABLE ACCESS | BY INDEX ROWID (STORE_SALES)\n",
      "                    │       │   │   │           └── 21 > TABLE ACCESS | FULL (STORE_SALES)\n",
      "                    │       │   │   └── 22 > INDEX | UNIQUE SCAN (SYS_C0021425)\n",
      "                    │       │   └── 23 > TABLE ACCESS | BY INDEX ROWID (STORE)\n",
      "                    │       └── 24 > TABLE ACCESS | FULL (STORE_RETURNS)\n",
      "                    ├── 25 > HASH\n",
      "                    │   └── 26 > HASH JOIN\n",
      "                    │       ├── 27 > NESTED LOOPS\n",
      "                    │       │   ├── 28 > STATISTICS COLLECTOR\n",
      "                    │       │   │   └── 29 > HASH JOIN\n",
      "                    │       │   │       ├── 30 > HASH JOIN\n",
      "                    │       │   │       │   ├── 31 > TABLE ACCESS | FULL (PROMOTION)\n",
      "                    │       │   │       │   └── 32 > HASH JOIN\n",
      "                    │       │   │       │       ├── 33 > TABLE ACCESS | FULL (ITEM)\n",
      "                    │       │   │       │       └── 34 > HASH JOIN\n",
      "                    │       │   │       │           ├── 35 > NESTED LOOPS\n",
      "                    │       │   │       │           │   ├── 36 > NESTED LOOPS\n",
      "                    │       │   │       │           │   │   ├── 37 > STATISTICS COLLECTOR\n",
      "                    │       │   │       │           │   │   │   └── 38 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                    │       │   │       │           │   │   └── 39 > INDEX | RANGE SCAN (CS_SOLD_DATE_SK_INDEX)\n",
      "                    │       │   │       │           │   └── 40 > TABLE ACCESS | BY INDEX ROWID (CATALOG_SALES)\n",
      "                    │       │   │       │           └── 41 > TABLE ACCESS | FULL (CATALOG_SALES)\n",
      "                    │       │   │       └── 42 > TABLE ACCESS | FULL (CATALOG_PAGE)\n",
      "                    │       │   └── 43 > TABLE ACCESS | BY INDEX ROWID (CATALOG_RETURNS)\n",
      "                    │       │       └── 44 > INDEX | UNIQUE SCAN (SYS_C0021455)\n",
      "                    │       └── 45 > TABLE ACCESS | FULL (CATALOG_RETURNS)\n",
      "                    └── 46 > HASH\n",
      "                        └── 47 > HASH JOIN\n",
      "                            ├── 48 > NESTED LOOPS\n",
      "                            │   ├── 49 > STATISTICS COLLECTOR\n",
      "                            │   │   └── 50 > HASH JOIN\n",
      "                            │   │       ├── 51 > TABLE ACCESS | FULL (WEB_SITE)\n",
      "                            │   │       └── 52 > HASH JOIN\n",
      "                            │   │           ├── 53 > TABLE ACCESS | FULL (PROMOTION)\n",
      "                            │   │           └── 54 > HASH JOIN\n",
      "                            │   │               ├── 55 > TABLE ACCESS | FULL (ITEM)\n",
      "                            │   │               └── 56 > HASH JOIN\n",
      "                            │   │                   ├── 57 > NESTED LOOPS\n",
      "                            │   │                   │   ├── 58 > NESTED LOOPS\n",
      "                            │   │                   │   │   ├── 59 > STATISTICS COLLECTOR\n",
      "                            │   │                   │   │   │   └── 60 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                            │   │                   │   │   └── 61 > INDEX | RANGE SCAN (WS_SOLD_DATE_SK_INDEX)\n",
      "                            │   │                   │   └── 62 > TABLE ACCESS | BY INDEX ROWID (WEB_SALES)\n",
      "                            │   │                   └── 63 > TABLE ACCESS | FULL (WEB_SALES)\n",
      "                            │   └── 64 > TABLE ACCESS | BY INDEX ROWID (WEB_RETURNS)\n",
      "                            │       └── 65 > INDEX | UNIQUE SCAN (SYS_C0021458)\n",
      "                            └── 66 > TABLE ACCESS | FULL (WEB_RETURNS)\n",
      "0 > SELECT STATEMENT\n",
      "├── 1 > COUNT\n",
      "└── 1 > COUNT\n",
      "    ├── 2 > VIEW\n",
      "    └── 2 > VIEW\n",
      "        ├── 3 > SORT\n",
      "        └── 3 > SORT\n",
      "            ├── 4 > NESTED LOOPS\n",
      "            └── 4 > NESTED LOOPS\n",
      "                ├── 5 > NESTED LOOPS\n",
      "                ├── 5 > NESTED LOOPS\n",
      "                │   ├── 6 > HASH JOIN\n",
      "                │   ├── 6 > HASH JOIN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                │   │   ├── 7 > TABLE ACCESS | FULL (STORE)\n",
      "                │   │   ├── 7 > TABLE ACCESS | FULL (STORE)\n",
      "                │   │   ├── 8 > HASH JOIN\n",
      "                │   │   └── 8 > HASH JOIN\n",
      "                │   │       ├── 9 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                │   │       ├── 9 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                │   │       ├── 10 > NESTED LOOPS\n",
      "                │   │       └── 10 > NESTED LOOPS\n",
      "                │   │           ├── 11 > NESTED LOOPS\n",
      "                │   │           ├── 11 > NESTED LOOPS\n",
      "                │   │           │   ├── 12 > HASH JOIN\n",
      "                │   │           │   ├── 12 > HASH JOIN\n",
      "                │   │           │   │   ├── 13 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                │   │           │   │   ├── 13 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                │   │           │   │   ├── 14 > HASH JOIN\n",
      "                │   │           │   │   └── 14 > HASH JOIN\n",
      "                │   │           │   │       ├── 15 > NESTED LOOPS\n",
      "                │   │           │   │       ├── 15 > NESTED LOOPS\n",
      "                │   │           │   │       │   ├── 16 > NESTED LOOPS\n",
      "                │   │           │   │       │   ├── 16 > NESTED LOOPS\n",
      "                │   │           │   │       │   │   ├── 17 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                │   │           │   │       │   │   ├── 17 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                │   │           │   │       │   │   ├── 18 > INDEX | RANGE SCAN (SS_SOLD_DATE_SK_INDEX)\n",
      "                │   │           │   │       │   │   └── 18 > INDEX | RANGE SCAN (SS_SOLD_DATE_SK_INDEX)\n",
      "                │   │           │   │       │   ├── 19 > TABLE ACCESS | BY INDEX ROWID (STORE_SALES)\n",
      "                │   │           │   │       │   └── 19 > TABLE ACCESS | BY INDEX ROWID (STORE_SALES)\n",
      "                │   │           │   │       ├── 20 > TABLE ACCESS | FULL (STORE_RETURNS)\n",
      "                │   │           │   │       └── 20 > TABLE ACCESS | FULL (STORE_RETURNS)\n",
      "                │   │           │   ├── 21 > INDEX | RANGE SCAN (CS_BILL_CUSTOMER_SK_INDEX)\n",
      "                │   │           │   └── 21 > INDEX | RANGE SCAN (CS_BILL_CUSTOMER_SK_INDEX)\n",
      "                │   │           ├── 22 > TABLE ACCESS | BY INDEX ROWID (CATALOG_SALES)\n",
      "                │   │           └── 22 > TABLE ACCESS | BY INDEX ROWID (CATALOG_SALES)\n",
      "                │   ├── 23 > INDEX | UNIQUE SCAN (SYS_C0021422)\n",
      "                │   └── 23 > INDEX | UNIQUE SCAN (SYS_C0021422)\n",
      "                ├── 24 > TABLE ACCESS | BY INDEX ROWID (ITEM)\n",
      "                └── 24 > TABLE ACCESS | BY INDEX ROWID (ITEM)\n",
      "SQL  [81]\n",
      "87\n",
      "87\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [82]\n",
      "88\n",
      "88\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [83]\n",
      "89\n",
      "89\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [84]\n",
      "90\n",
      "90\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [85]\n",
      "91\n",
      "91\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [86]\n",
      "14\n",
      "92\n",
      "Access Predicate Difference detected with delta value [8387530011.5873375]\n",
      "Tree 1 difference at node [0] operator > SELECT STATEMENT(0) on object [0]\n",
      "Tree 2 difference at node [13] operator > HASH JOIN(0) on object [0]\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > COUNT\n",
      "    └── 2 > VIEW\n",
      "        └── 3 > SORT\n",
      "            └── 4 > WINDOW\n",
      "                └── 5 > SORT\n",
      "                    └── 6 > HASH JOIN\n",
      "                        ├── 7 > TABLE ACCESS | FULL (ITEM)\n",
      "                        └── 8 > HASH JOIN\n",
      "                            ├── 9 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                            └── 10 > TABLE ACCESS | FULL (WEB_SALES)\n",
      "0 > SELECT STATEMENT\n",
      "└── 1 > COUNT\n",
      "    └── 2 > VIEW\n",
      "        └── 3 > SORT\n",
      "            └── 4 > VIEW\n",
      "                └── 5 > UNION-ALL\n",
      "                    ├── 6 > HASH\n",
      "                    │   └── 7 > HASH JOIN\n",
      "                    │       ├── 8 > TABLE ACCESS | FULL (WAREHOUSE)\n",
      "                    │       └── 9 > HASH JOIN\n",
      "                    │           ├── 10 > TABLE ACCESS | FULL (TIME_DIM)\n",
      "                    │           └── 11 > HASH JOIN\n",
      "                    │               ├── 12 > TABLE ACCESS | FULL (SHIP_MODE)\n",
      "                    │               └── 13 > HASH JOIN\n",
      "                    │                   ├── 14 > NESTED LOOPS\n",
      "                    │                   │   ├── 15 > NESTED LOOPS\n",
      "                    │                   │   │   ├── 16 > STATISTICS COLLECTOR\n",
      "                    │                   │   │   │   └── 17 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                    │                   │   │   └── 18 > INDEX | RANGE SCAN (WS_SOLD_DATE_SK_INDEX)\n",
      "                    │                   │   └── 19 > TABLE ACCESS | BY INDEX ROWID (WEB_SALES)\n",
      "                    │                   └── 20 > TABLE ACCESS | FULL (WEB_SALES)\n",
      "                    └── 21 > HASH\n",
      "                        └── 22 > HASH JOIN\n",
      "                            ├── 23 > TABLE ACCESS | FULL (WAREHOUSE)\n",
      "                            └── 24 > HASH JOIN\n",
      "                                ├── 25 > TABLE ACCESS | FULL (TIME_DIM)\n",
      "                                └── 26 > HASH JOIN\n",
      "                                    ├── 27 > TABLE ACCESS | FULL (SHIP_MODE)\n",
      "                                    └── 28 > HASH JOIN\n",
      "                                        ├── 29 > NESTED LOOPS\n",
      "                                        │   ├── 30 > NESTED LOOPS\n",
      "                                        │   │   ├── 31 > STATISTICS COLLECTOR\n",
      "                                        │   │   │   └── 32 > TABLE ACCESS | FULL (DATE_DIM)\n",
      "                                        │   │   └── 33 > INDEX | RANGE SCAN (CS_SOLD_DATE_SK_INDEX)\n",
      "                                        │   └── 34 > TABLE ACCESS | BY INDEX ROWID (CATALOG_SALES)\n",
      "                                        └── 35 > TABLE ACCESS | FULL (CATALOG_SALES)\n",
      "SQL  [87]\n",
      "93\n",
      "93\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [88]\n",
      "94\n",
      "94\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [89]\n",
      "95\n",
      "95\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [90]\n",
      "96\n",
      "96\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [91]\n",
      "97\n",
      "97\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [92]\n",
      "98\n",
      "98\n",
      "No changes detected with delta value of [0.0]\n",
      "SQL  [93]\n",
      "99\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "for i, idx in enumerate(hint_outlier_sqls):\n",
    "    print('SQL  [' + str(i+1) + ']')\n",
    "    if i+1 in variant_ids:\n",
    "        print(idx)\n",
    "        df_temp_plan = df_hints_outliers[df_hints_outliers['PLAN_ID'] == idx]\n",
    "        df_temp_plan = df_temp_plan.sort_values(by='ID', ascending=True)\n",
    "    else:\n",
    "        print(idx)\n",
    "        df_temp_plan = df[df['SQL_ID'] == idx]\n",
    "        df_temp_plan = df_temp_plan.sort_values(by='ID', ascending=True)\n",
    "    \n",
    "    print(actual_sqls[i])\n",
    "    df_plan = df[df['SQL_ID'] == actual_sqls[i]]\n",
    "    df_plan = df_plan.sort_values(by='ID', ascending=True)\n",
    "    \n",
    "    # Builds Trees\n",
    "    tree_temp_plan = PlanTreeModeller.build_tree(df=df_temp_plan)\n",
    "    tree_plan = PlanTreeModeller.build_tree(df=df_plan)\n",
    "    \n",
    "    PlanTreeModeller.tree_compare(tree1=tree_temp_plan, \n",
    "                                  tree2=tree_plan, \n",
    "                                  df1=df_temp_plan, \n",
    "                                  df2=df_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream Comparison with Predicate Based Outliers\n",
    "\n",
    "Compares the expected stream with variation stream. Variations found here will be composed of SQL optimizer hint injections to purposely skew the plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, idx in enumerate(predicate_outlier_sqls):\n",
    "    print('SQL  [' + str(i+1) + ']')\n",
    "    if i+1 in variant_ids:\n",
    "        print(idx)\n",
    "        df_temp_plan = df_predicate_outliers[df_predicate_outliers['PLAN_ID'] == idx]\n",
    "        df_temp_plan = df_temp_plan.sort_values(by='ID', ascending=True)\n",
    "    else:\n",
    "        print(idx)\n",
    "        df_temp_plan = df[df['SQL_ID'] == idx]\n",
    "        df_temp_plan = df_temp_plan.sort_values(by='ID', ascending=True)\n",
    "    \n",
    "    print(actual_sqls[i])\n",
    "    df_plan = df[df['SQL_ID'] == actual_sqls[i]]\n",
    "    df_plan = df_plan.sort_values(by='ID', ascending=True)\n",
    "    \n",
    "    # Builds Trees\n",
    "    tree_temp_plan = PlanTreeModeller.build_tree(df=df_temp_plan)\n",
    "    tree_plan = PlanTreeModeller.build_tree(df=df_plan)\n",
    "    \n",
    "    PlanTreeModeller.tree_compare(tree1=tree_temp_plan, \n",
    "                                  tree2=tree_plan, \n",
    "                                  df1=df_temp_plan, \n",
    "                                  df2=df_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream Comparison with Rownum Based Outliers\n",
    "\n",
    "Compares the expected stream with variation stream. Variations found here will be composed of SQL optimizer hint injections to purposely skew the plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, idx in enumerate(rownum_outlier_sqls):\n",
    "    print('SQL  [' + str(i+1) + ']')\n",
    "    if i+1 in variant_ids:\n",
    "        print(idx)\n",
    "        df_temp_plan = df_rownum_outliers[df_rownum_outliers['PLAN_ID'] == idx]\n",
    "        df_temp_plan = df_temp_plan.sort_values(by='ID', ascending=True)\n",
    "    else:\n",
    "        print(idx)\n",
    "        df_temp_plan = df[df['SQL_ID'] == idx]\n",
    "        df_temp_plan = df_temp_plan.sort_values(by='ID', ascending=True)\n",
    "    \n",
    "    print(actual_sqls[i])\n",
    "    df_plan = df[df['SQL_ID'] == actual_sqls[i]]\n",
    "    df_plan = df_plan.sort_values(by='ID', ascending=True)\n",
    "    \n",
    "    # Builds Trees\n",
    "    tree_temp_plan = PlanTreeModeller.build_tree(df=df_temp_plan)\n",
    "    tree_plan = PlanTreeModeller.build_tree(df=df_plan)\n",
    "    \n",
    "    PlanTreeModeller.tree_compare(tree1=tree_temp_plan, \n",
    "                                  tree2=tree_plan, \n",
    "                                  df1=df_temp_plan, \n",
    "                                  df2=df_plan)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
