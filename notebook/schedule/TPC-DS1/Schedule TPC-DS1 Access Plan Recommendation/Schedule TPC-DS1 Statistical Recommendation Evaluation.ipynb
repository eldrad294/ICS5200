{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schedule TPC-DS1 Statistical Recommendation Evaluation\n",
    "\n",
    "This experiment is intended at quantifying the statistical recommendation technique, through comparison of two query streams. The query streams are denoted as follows:\n",
    "\n",
    "* Prior Stream - Denotes a sequence of baseline query plans, against which comparison will be made.\n",
    "* Upcoming Stream - Denotes a sequence of upcoming query plans. Queries found within the upcoming stream mirror those established in the Prior Stream, with a number of exceptions. These exceptions are considered as query variants, and contain a degree of change from the original queries taken from the prior stream.\n",
    "\n",
    "Query variants are denoted below, and are therefore eligable to be flagged during the evaluation phase:\n",
    "\n",
    "* Query 5  \n",
    "* Query 10\n",
    "* Query 14\n",
    "* Query 18\n",
    "* Query 22\n",
    "* Query 27\n",
    "* Query 35\n",
    "* Query 36\n",
    "* Query 51\n",
    "* Query 67\n",
    "* Query 70\n",
    "* Query 77\n",
    "* Query 80\n",
    "* Query 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "print('pandas: %s' % pd.__version__)\n",
    "# numpy\n",
    "import numpy as np\n",
    "print('numpy: %s' % np.__version__)\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# sklearn\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "#\n",
    "# AnyTree\n",
    "from anytree import Node, RenderTree, PostOrderIter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Cell\n",
    "\n",
    "Tweak parametric changes from this cell to influence outcome of experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Config\n",
    "tpcds='TPCDS1' # Schema upon which to operate test\n",
    "test_split=.2\n",
    "y_labels = ['COST',\n",
    "            'CARDINALITY',\n",
    "            'BYTES',\n",
    "            'CPU_COST',\n",
    "            'IO_COST',\n",
    "            'TEMP_SPACE',\n",
    "            'TIME']\n",
    "black_list = ['TIMESTAMP',\n",
    "              'SQL_ID',\n",
    "              'OPERATION',\n",
    "              'OPTIONS',\n",
    "              'OBJECT_NAME',\n",
    "              'OBJECT_OWNER',\n",
    "              'PARTITION_STOP',\n",
    "              'PARTITION_START'] # Columns which will be ignored during type conversion, and later used for aggregation\n",
    "nrows = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from file into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root path\n",
    "base_dir = 'C:/Users/gabriel.sammut/University/'\n",
    "#base_dir = 'D:/Projects/ICS5200/'\n",
    "root_dir = base_dir + 'Data_ICS5200/Schedule/' + tpcds\n",
    "src_dir = base_dir + 'ICS5200/src/sql/Runtime/TPC-DS/' + tpcds + '/Variants/'\n",
    "\n",
    "rep_vsql_plan_path = root_dir + '/rep_vsql_plan.csv'\n",
    "#rep_vsql_plan_path = root_dir + '/rep_vsql_plan.csv'\n",
    "\n",
    "dtype={'COST':'int64',\n",
    "       'CARDINALITY':'int64',\n",
    "       'BYTES':'int64',\n",
    "       'CPU_COST':'int64',\n",
    "       'IO_COST':'int64',\n",
    "       'TEMP_SPACE':'int64',\n",
    "       'TIME':'int64',\n",
    "       'OPERATION':'str',\n",
    "       'OBJECT_NAME':'str'}\n",
    "rep_vsql_plan_df = pd.read_csv(rep_vsql_plan_path, nrows=nrows, dtype=dtype)\n",
    "print(rep_vsql_plan_df.head())\n",
    "#\n",
    "def prettify_header(headers):\n",
    "    \"\"\"\n",
    "    Cleans header list from unwated character strings\n",
    "    \"\"\"\n",
    "    header_list = []\n",
    "    [header_list.append(header.replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"\").replace(\",\",\"\")) for header in headers]\n",
    "    return header_list\n",
    "#\n",
    "rep_vsql_plan_df.columns = prettify_header(rep_vsql_plan_df.columns.values)\n",
    "print('------------------------------------------')\n",
    "print(rep_vsql_plan_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read outlier data from file into pandas dataframes and concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# CSV Outlier Paths\n",
    "outlier_hints_q5_path = src_dir + 'hints/output/query_5.csv'\n",
    "outlier_hints_q10_path = src_dir + 'hints/output/query_10.csv'\n",
    "outlier_hints_q14_path = src_dir + 'hints/output/query_14.csv'\n",
    "outlier_hints_q18_path = src_dir + 'hints/output/query_18.csv'\n",
    "outlier_hints_q22_path = src_dir + 'hints/output/query_22.csv'\n",
    "outlier_hints_q27_path = src_dir + 'hints/output/query_27.csv'\n",
    "outlier_hints_q35_path = src_dir + 'hints/output/query_35.csv'\n",
    "outlier_hints_q36_path = src_dir + 'hints/output/query_36.csv'\n",
    "outlier_hints_q51_path = src_dir + 'hints/output/query_51.csv'\n",
    "outlier_hints_q67_path = src_dir + 'hints/output/query_67.csv'\n",
    "outlier_hints_q70_path = src_dir + 'hints/output/query_70.csv'\n",
    "outlier_hints_q77_path = src_dir + 'hints/output/query_77.csv'\n",
    "outlier_hints_q80_path = src_dir + 'hints/output/query_80.csv'\n",
    "outlier_hints_q86_path = src_dir + 'hints/output/query_86.csv'\n",
    "#\n",
    "outlier_predicates_q5_path = src_dir + 'predicates/output/query_5.csv'\n",
    "outlier_predicates_q10_path = src_dir + 'predicates/output/query_10.csv'\n",
    "outlier_predicates_q14_path = src_dir + 'predicates/output/query_14.csv'\n",
    "outlier_predicates_q18_path = src_dir + 'predicates/output/query_18.csv'\n",
    "outlier_predicates_q22_path = src_dir + 'predicates/output/query_22.csv'\n",
    "outlier_predicates_q27_path = src_dir + 'predicates/output/query_27.csv'\n",
    "outlier_predicates_q35_path = src_dir + 'predicates/output/query_35.csv'\n",
    "outlier_predicates_q36_path = src_dir + 'predicates/output/query_36.csv'\n",
    "outlier_predicates_q51_path = src_dir + 'predicates/output/query_51.csv'\n",
    "outlier_predicates_q67_path = src_dir + 'predicates/output/query_67.csv'\n",
    "outlier_predicates_q70_path = src_dir + 'predicates/output/query_70.csv'\n",
    "outlier_predicates_q77_path = src_dir + 'predicates/output/query_77.csv'\n",
    "outlier_predicates_q80_path = src_dir + 'predicates/output/query_80.csv'\n",
    "outlier_predicates_q86_path = src_dir + 'predicates/output/query_86.csv'\n",
    "#\n",
    "outlier_rownum_q5_path = src_dir + 'rownum/output/query_5.csv'\n",
    "outlier_rownum_q10_path = src_dir + 'rownum/output/query_10.csv'\n",
    "outlier_rownum_q14_path = src_dir + 'rownum/output/query_14.csv'\n",
    "outlier_rownum_q18_path = src_dir + 'rownum/output/query_18.csv'\n",
    "outlier_rownum_q22_path = src_dir + 'rownum/output/query_22.csv'\n",
    "outlier_rownum_q27_path = src_dir + 'rownum/output/query_27.csv'\n",
    "outlier_rownum_q35_path = src_dir + 'rownum/output/query_35.csv'\n",
    "outlier_rownum_q36_path = src_dir + 'rownum/output/query_36.csv'\n",
    "outlier_rownum_q51_path = src_dir + 'rownum/output/query_51.csv'\n",
    "outlier_rownum_q67_path = src_dir + 'rownum/output/query_67.csv'\n",
    "outlier_rownum_q70_path = src_dir + 'rownum/output/query_70.csv'\n",
    "outlier_rownum_q77_path = src_dir + 'rownum/output/query_77.csv'\n",
    "outlier_rownum_q80_path = src_dir + 'rownum/output/query_80.csv'\n",
    "outlier_rownum_q86_path = src_dir + 'rownum/output/query_86.csv'\n",
    "#\n",
    "# Read CSV Paths\n",
    "outlier_hints_q5_df = pd.read_csv(outlier_hints_q5_path,dtype=str)\n",
    "outlier_hints_q10_df = pd.read_csv(outlier_hints_q10_path,dtype=str)\n",
    "outlier_hints_q14_df = pd.read_csv(outlier_hints_q14_path,dtype=str)\n",
    "outlier_hints_q18_df = pd.read_csv(outlier_hints_q18_path,dtype=str)\n",
    "outlier_hints_q22_df = pd.read_csv(outlier_hints_q22_path,dtype=str)\n",
    "outlier_hints_q27_df = pd.read_csv(outlier_hints_q27_path,dtype=str)\n",
    "outlier_hints_q35_df = pd.read_csv(outlier_hints_q35_path,dtype=str)\n",
    "outlier_hints_q36_df = pd.read_csv(outlier_hints_q36_path,dtype=str)\n",
    "outlier_hints_q51_df = pd.read_csv(outlier_hints_q51_path,dtype=str)\n",
    "outlier_hints_q67_df = pd.read_csv(outlier_hints_q67_path,dtype=str)\n",
    "outlier_hints_q70_df = pd.read_csv(outlier_hints_q70_path,dtype=str)\n",
    "outlier_hints_q77_df = pd.read_csv(outlier_hints_q77_path,dtype=str)\n",
    "outlier_hints_q80_df = pd.read_csv(outlier_hints_q80_path,dtype=str)\n",
    "outlier_hints_q86_df = pd.read_csv(outlier_hints_q86_path,dtype=str)\n",
    "#\n",
    "outlier_predicates_q5_df = pd.read_csv(outlier_predicates_q5_path,dtype=str)\n",
    "outlier_predicates_q10_df = pd.read_csv(outlier_predicates_q10_path,dtype=str)\n",
    "outlier_predicates_q14_df = pd.read_csv(outlier_predicates_q14_path,dtype=str)\n",
    "outlier_predicates_q18_df = pd.read_csv(outlier_predicates_q18_path,dtype=str)\n",
    "outlier_predicates_q22_df = pd.read_csv(outlier_predicates_q22_path,dtype=str)\n",
    "outlier_predicates_q27_df = pd.read_csv(outlier_predicates_q27_path,dtype=str)\n",
    "outlier_predicates_q35_df = pd.read_csv(outlier_predicates_q35_path,dtype=str)\n",
    "outlier_predicates_q36_df = pd.read_csv(outlier_predicates_q36_path,dtype=str)\n",
    "outlier_predicates_q51_df = pd.read_csv(outlier_predicates_q51_path,dtype=str)\n",
    "outlier_predicates_q67_df = pd.read_csv(outlier_predicates_q67_path,dtype=str)\n",
    "outlier_predicates_q70_df = pd.read_csv(outlier_predicates_q70_path,dtype=str)\n",
    "outlier_predicates_q77_df = pd.read_csv(outlier_predicates_q77_path,dtype=str)\n",
    "outlier_predicates_q80_df = pd.read_csv(outlier_predicates_q80_path,dtype=str)\n",
    "outlier_predicates_q86_df = pd.read_csv(outlier_predicates_q86_path,dtype=str)\n",
    "#\n",
    "outlier_rownum_q5_df = pd.read_csv(outlier_rownum_q5_path,dtype=str)\n",
    "outlier_rownum_q10_df = pd.read_csv(outlier_rownum_q10_path,dtype=str)\n",
    "outlier_rownum_q14_df = pd.read_csv(outlier_rownum_q14_path,dtype=str)\n",
    "outlier_rownum_q18_df = pd.read_csv(outlier_rownum_q18_path,dtype=str)\n",
    "outlier_rownum_q22_df = pd.read_csv(outlier_rownum_q22_path,dtype=str)\n",
    "outlier_rownum_q27_df = pd.read_csv(outlier_rownum_q27_path,dtype=str)\n",
    "outlier_rownum_q35_df = pd.read_csv(outlier_rownum_q35_path,dtype=str)\n",
    "outlier_rownum_q36_df = pd.read_csv(outlier_rownum_q36_path,dtype=str)\n",
    "outlier_rownum_q51_df = pd.read_csv(outlier_rownum_q51_path,dtype=str)\n",
    "outlier_rownum_q67_df = pd.read_csv(outlier_rownum_q67_path,dtype=str)\n",
    "outlier_rownum_q70_df = pd.read_csv(outlier_rownum_q70_path,dtype=str)\n",
    "outlier_rownum_q77_df = pd.read_csv(outlier_rownum_q77_path,dtype=str)\n",
    "outlier_rownum_q80_df = pd.read_csv(outlier_rownum_q80_path,dtype=str)\n",
    "outlier_rownum_q86_df = pd.read_csv(outlier_rownum_q86_path,dtype=str)\n",
    "#\n",
    "# Merge dataframes into a single pandas matrix\n",
    "df_hints_outliers = pd.concat([outlier_hints_q5_df, outlier_hints_q10_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q14_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q18_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q22_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q27_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q35_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q36_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q51_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q67_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q70_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q77_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q80_df], sort=False)\n",
    "df_hints_outliers = pd.concat([df_hints_outliers, outlier_hints_q86_df], sort=False)\n",
    "#\n",
    "df_predicate_outliers = pd.concat([outlier_predicate_q5_df, outlier_predicate_q10_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q14_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q18_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q22_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q27_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q35_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q36_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q51_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q67_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q70_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q77_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q80_df], sort=False)\n",
    "df_predicate_outliers = pd.concat([df_predicate_outliers, outlier_predicates_q86_df], sort=False)\n",
    "#\n",
    "df_rownum_outliers = pd.concat([outlier_rownum_q5_df, outlier_rownum_q10_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q14_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q18_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q22_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q27_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q35_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q36_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q51_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q67_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q70_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q77_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q80_df], sort=False)\n",
    "df_rownum_outliers = pd.concat([df_rownum_outliers, outlier_rownum_q86_df], sort=False)\n",
    "#\n",
    "print(df_hints_outliers.shape)\n",
    "print(df_hints_outliers.head())\n",
    "print('------------------------------------------')\n",
    "print(df_predicate_outliers.shape)\n",
    "print(df_predicate_outliers.head())\n",
    "print('------------------------------------------')\n",
    "print(df_rownum_outliers.shape)\n",
    "print(df_rownum_outliers.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
