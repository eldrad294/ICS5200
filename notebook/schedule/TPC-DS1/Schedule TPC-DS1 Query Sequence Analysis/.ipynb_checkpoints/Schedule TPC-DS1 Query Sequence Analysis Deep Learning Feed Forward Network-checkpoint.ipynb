{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Sequence Analysis (Deep Learning Feed Forward Network)\n",
    "\n",
    "This notebook focuses on sequence analysis, when presented with a workload schedule / sequence of queries. In an average day to day work activity, particular query patterns can be discerned. This pattern distinction allows us to discern which queries will be susceptible to execution over time, allowing us to know ahead of time which queries will be executed against the database.\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "### Module Installation and Importing Libraries\n",
    "\n",
    "* https://machinelearningmastery.com/setup-python-environment-machine-learning-deep-learning-anaconda/\n",
    "* https://vertexai-plaidml.readthedocs-hosted.com/en/latest/installing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy: 1.1.0\n",
      "numpy: 1.15.4\n",
      "pandas: 0.23.4\n",
      "sklearn: 0.20.2\n",
      "theano: 1.0.3\n",
      "tensorflow: 1.11.0\n",
      "keras: 2.2.4\n"
     ]
    }
   ],
   "source": [
    "# scipy\n",
    "import scipy as sc\n",
    "print('scipy: %s' % sc.__version__)\n",
    "# numpy\n",
    "import numpy as np\n",
    "print('numpy: %s' % np.__version__)\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "# pandas\n",
    "import pandas as pd\n",
    "print('pandas: %s' % pd.__version__)\n",
    "# scikit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import sklearn as sk\n",
    "print('sklearn: %s' % sk.__version__)\n",
    "# theano\n",
    "import theano\n",
    "print('theano: %s' % theano.__version__)\n",
    "# tensorflow\n",
    "import tensorflow\n",
    "print('tensorflow: %s' % tensorflow.__version__)\n",
    "# plaidml keras\n",
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "# keras\n",
    "import keras as ke\n",
    "print('keras: %s' % ke.__version__)\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Cell\n",
    "\n",
    "Tweak parametric changes from this cell to influence outcome of experiment. \n",
    "NB: This experiment demonstrates at time  step = 1 (1 minute in advance). Further down in experiment, other timestep results are also featured and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Experiment Config\n",
    "tpcds='TPCDS1' # Schema upon which to operate test\n",
    "lag=13 # Time Series shift / Lag Step. Each lag value equates to 1 minute. Cannot be less than 1\n",
    "if lag < 1:\n",
    "    raise ValueError('Lag value must be greater than 1!')\n",
    "\n",
    "nrows=20000\n",
    "test_split=.2 # Denotes which Data Split to operate under when it comes to training / validation\n",
    "\n",
    "# Net Config\n",
    "epochs=10\n",
    "batch_size=32\n",
    "activation='selu'\n",
    "dropout=.2\n",
    "layers=2\n",
    "initializer='zero'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from file into Pandas Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SNAP_ID' 'DBID' 'INSTANCE_NUMBER' 'SQL_ID' 'PLAN_HASH_VALUE'\n",
      " 'OPTIMIZER_COST' 'OPTIMIZER_MODE' 'OPTIMIZER_ENV_HASH_VALUE'\n",
      " 'SHARABLE_MEM' 'LOADED_VERSIONS' 'VERSION_COUNT' 'MODULE' 'ACTION'\n",
      " 'SQL_PROFILE' 'FORCE_MATCHING_SIGNATURE' 'PARSING_SCHEMA_ID'\n",
      " 'PARSING_SCHEMA_NAME' 'PARSING_USER_ID' 'FETCHES_TOTAL' 'FETCHES_DELTA'\n",
      " 'END_OF_FETCH_COUNT_TOTAL' 'END_OF_FETCH_COUNT_DELTA' 'SORTS_TOTAL'\n",
      " 'SORTS_DELTA' 'EXECUTIONS_TOTAL' 'EXECUTIONS_DELTA'\n",
      " 'PX_SERVERS_EXECS_TOTAL' 'PX_SERVERS_EXECS_DELTA' 'LOADS_TOTAL'\n",
      " 'LOADS_DELTA' 'INVALIDATIONS_TOTAL' 'INVALIDATIONS_DELTA'\n",
      " 'PARSE_CALLS_TOTAL' 'PARSE_CALLS_DELTA' 'DISK_READS_TOTAL'\n",
      " 'DISK_READS_DELTA' 'BUFFER_GETS_TOTAL' 'BUFFER_GETS_DELTA'\n",
      " 'ROWS_PROCESSED_TOTAL' 'ROWS_PROCESSED_DELTA' 'CPU_TIME_TOTAL'\n",
      " 'CPU_TIME_DELTA' 'ELAPSED_TIME_TOTAL' 'ELAPSED_TIME_DELTA' 'IOWAIT_TOTAL'\n",
      " 'IOWAIT_DELTA' 'CLWAIT_TOTAL' 'CLWAIT_DELTA' 'APWAIT_TOTAL'\n",
      " 'APWAIT_DELTA' 'CCWAIT_TOTAL' 'CCWAIT_DELTA' 'DIRECT_WRITES_TOTAL'\n",
      " 'DIRECT_WRITES_DELTA' 'PLSEXEC_TIME_TOTAL' 'PLSEXEC_TIME_DELTA'\n",
      " 'JAVEXEC_TIME_TOTAL' 'JAVEXEC_TIME_DELTA' 'IO_OFFLOAD_ELIG_BYTES_TOTAL'\n",
      " 'IO_OFFLOAD_ELIG_BYTES_DELTA' 'IO_INTERCONNECT_BYTES_TOTAL'\n",
      " 'IO_INTERCONNECT_BYTES_DELTA' 'PHYSICAL_READ_REQUESTS_TOTAL'\n",
      " 'PHYSICAL_READ_REQUESTS_DELTA' 'PHYSICAL_READ_BYTES_TOTAL'\n",
      " 'PHYSICAL_READ_BYTES_DELTA' 'PHYSICAL_WRITE_REQUESTS_TOTAL'\n",
      " 'PHYSICAL_WRITE_REQUESTS_DELTA' 'PHYSICAL_WRITE_BYTES_TOTAL'\n",
      " 'PHYSICAL_WRITE_BYTES_DELTA' 'OPTIMIZED_PHYSICAL_READS_TOTAL'\n",
      " 'OPTIMIZED_PHYSICAL_READS_DELTA' 'CELL_UNCOMPRESSED_BYTES_TOTAL'\n",
      " 'CELL_UNCOMPRESSED_BYTES_DELTA' 'IO_OFFLOAD_RETURN_BYTES_TOTAL'\n",
      " 'IO_OFFLOAD_RETURN_BYTES_DELTA' 'BIND_DATA' 'FLAG' 'CON_DBID' 'CON_ID'\n",
      " 'SQL_TEXT' 'COMMAND_TYPE' 'STARTUP_TIME' 'BEGIN_INTERVAL_TIME'\n",
      " 'END_INTERVAL_TIME' 'FLUSH_ELAPSED' 'SNAP_LEVEL' 'ERROR_COUNT'\n",
      " 'SNAP_FLAG' 'SNAP_TIMEZONE']\n"
     ]
    }
   ],
   "source": [
    "# Root path\n",
    "#root_dir = 'C:/Users/gabriel.sammut/University/Data_ICS5200/Schedule/' + tpcds\n",
    "root_dir = 'D:/Projects/Datagenerated_ICS5200/Schedule/' + tpcds\n",
    "\n",
    "# Open Data\n",
    "#rep_hist_snapshot_path = root_dir + '/rep_hist_snapshot.csv'\n",
    "rep_hist_snapshot_path = root_dir + '/rep_hist_snapshot.csv'\n",
    "\n",
    "rep_hist_snapshot_df = pd.read_csv(rep_hist_snapshot_path, nrows=nrows)\n",
    "\n",
    "def prettify_header(headers):\n",
    "    \"\"\"\n",
    "    Cleans header list from unwated character strings\n",
    "    \"\"\"\n",
    "    header_list = []\n",
    "    [header_list.append(header.replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"\").replace(\",\",\"\")) for header in headers]\n",
    "    return header_list\n",
    "\n",
    "rep_hist_snapshot_df.columns = prettify_header(rep_hist_snapshot_df.columns.values)\n",
    "\n",
    "print(rep_hist_snapshot_df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Matrix Shapes\n",
    "\n",
    "Changes dataframe shape, in an attempt to drop all numeric data. Below's aggregated data is done so on:\n",
    "* SNAP_ID\n",
    "* INSTANCE_NUMBER\n",
    "* DBID\n",
    "* SQL_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Before Aggregation: (20000, 90)\n",
      "Shape After Aggregation: (241, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "    SNAP_ID                                             SQL_ID\n",
      "0     43414  [03ggjrmy0wa1w, 06dymzb481vnd, 0aq14dznn91rg, ...\n",
      "1     43415  [0w26sk6t6gq98, 0y080mnfaqk3u, 0y080mnfaqk3u, ...\n",
      "2     43416  [01tp87bk1t2zv, 06dymzb481vnd, 0jj0ct4x4gy27, ...\n",
      "3     43417  [01tp87bk1t2zv, 06dymzb481vnd, 0a08ug2qc1j82, ...\n",
      "4     43418  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "5     43419  [0kcbwucxmazcp, 0kkhhb2w93cx0, 0w26sk6t6gq98, ...\n",
      "6     43420  [0a4un42k35fzy, 0a7q9v9nd2qc1, 0hhmdwwgxbw0r, ...\n",
      "7     43421  [01tp87bk1t2zv, 06dymzb481vnd, 0jj0ct4x4gy27, ...\n",
      "8     43422  [01tp87bk1t2zv, 06dymzb481vnd, 0a08ug2qc1j82, ...\n",
      "9     43423  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "10    43424  [0kcbwucxmazcp, 0kkhhb2w93cx0, 1hxfbnas8xr2j, ...\n",
      "11    43425  [09vrdx888wvvb, 0a7q9v9nd2qc1, 0hhmdwwgxbw0r, ...\n",
      "12    43426  [03ggjrmy0wa1w, 06dymzb481vnd, 0aq14dznn91rg, ...\n",
      "13    43427  [01tp87bk1t2zv, 0w26sk6t6gq98, 130r442w3nfny, ...\n",
      "14    43428  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "15    43429  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "16    43430  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "17    43431  [0kcbwucxmazcp, 0w26sk6t6gq98, 130r442w3nfny, ...\n",
      "18    43432  [0kcbwucxmazcp, 0kkhhb2w93cx0, 0t9xqgg9n3yws, ...\n",
      "19    43433  [01tp87bk1t2zv, 06dymzb481vnd, 0kkhhb2w93cx0, ...\n",
      "20    43434  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "21    43435  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "22    43436  [01tp87bk1t2zv, 0jj0ct4x4gy27, 0kcbwucxmazcp, ...\n",
      "23    43437  [0kcbwucxmazcp, 0kkhhb2w93cx0, 0v3dvmc22qnam, ...\n",
      "24    43438  [03ggjrmy0wa1w, 0aq14dznn91rg, 0f60bzgt9127c, ...\n",
      "25    43439  [01tp87bk1t2zv, 06dymzb481vnd, 130r442w3nfny, ...\n",
      "26    43440  [06dymzb481vnd, 0y080mnfaqk3u, 0y080mnfaqk3u, ...\n",
      "27    43441  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "28    43442  [01tp87bk1t2zv, 06dymzb481vnd, 0a08ug2qc1j82, ...\n",
      "29    43443  [01tp87bk1t2zv, 06dymzb481vnd, 0kcbwucxmazcp, ...\n",
      "..      ...                                                ...\n",
      "70    43484  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "71    43485  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "72    43486  [01tp87bk1t2zv, 0kcbwucxmazcp, 0kkhhb2w93cx0, ...\n",
      "73    43487  [0kcbwucxmazcp, 0kkhhb2w93cx0, 0w26sk6t6gq98, ...\n",
      "74    43488  [03ggjrmy0wa1w, 0aq14dznn91rg, 0f60bzgt9127c, ...\n",
      "75    43489  [01tp87bk1t2zv, 06dymzb481vnd, 130r442w3nfny, ...\n",
      "76    43490  [06dymzb481vnd, 0y080mnfaqk3u, 0y080mnfaqk3u, ...\n",
      "77    43491  [01tp87bk1t2zv, 06dymzb481vnd, 0jj0ct4x4gy27, ...\n",
      "78    43492  [01tp87bk1t2zv, 06dymzb481vnd, 0a08ug2qc1j82, ...\n",
      "79    43493  [01tp87bk1t2zv, 06dymzb481vnd, 0kcbwucxmazcp, ...\n",
      "80    43494  [0kcbwucxmazcp, 0kkhhb2w93cx0, 0w26sk6t6gq98, ...\n",
      "81    43495  [06dymzb481vnd, 0kkhhb2w93cx0, 130r442w3nfny, ...\n",
      "82    43496  [01tp87bk1t2zv, 06dymzb481vnd, 0v3dvmc22qnam, ...\n",
      "83    43497  [01tp87bk1t2zv, 06dymzb481vnd, 0a08ug2qc1j82, ...\n",
      "84    43498  [01tp87bk1t2zv, 06dymzb481vnd, 0kcbwucxmazcp, ...\n",
      "85    43499  [0kcbwucxmazcp, 0kkhhb2w93cx0, 0w26sk6t6gq98, ...\n",
      "86    43500  [03ggjrmy0wa1w, 0aq14dznn91rg, 0f60bzgt9127c, ...\n",
      "87    43501  [06dymzb481vnd, 0ga8vk4nftz45, 13a9r2xkx1bxb, ...\n",
      "88    43502  [062savj8zgzut, 0jj0ct4x4gy27, 0jj0ct4x4gy27, ...\n",
      "89    43503  [01tp87bk1t2zv, 06dymzb481vnd, 0jj0ct4x4gy27, ...\n",
      "90    43504  [01tp87bk1t2zv, 06dymzb481vnd, 0a08ug2qc1j82, ...\n",
      "91    43505  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "92    43506  [0kcbwucxmazcp, 0kkhhb2w93cx0, 0t9xqgg9n3yws, ...\n",
      "93    43507  [01fpx3aqyq6wp, 0a7q9v9nd2qc1, 0hhmdwwgxbw0r, ...\n",
      "94    43508  [01tp87bk1t2zv, 06dymzb481vnd, 0jj0ct4x4gy27, ...\n",
      "95    43509  [01tp87bk1t2zv, 06dymzb481vnd, 0a08ug2qc1j82, ...\n",
      "96    43510  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "97    43511  [0kcbwucxmazcp, 0kkhhb2w93cx0, 0v3dvmc22qnam, ...\n",
      "98    43512  [0a7q9v9nd2qc1, 0hhmdwwgxbw0r, 0kkhhb2w93cx0, ...\n",
      "99    43513  [03ggjrmy0wa1w, 06dymzb481vnd, 0aq14dznn91rg, ...\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape Before Aggregation: \" + str(rep_hist_snapshot_df.shape))\n",
    "#\n",
    "# Group By Values by SNAP_ID , sum all metrics (for table REP_HIST_SNAPSHOT) and drop all numeric\n",
    "df = rep_hist_snapshot_df.groupby(['SNAP_ID'])['SQL_ID'].apply(list).reset_index()\n",
    "#\n",
    "print(\"Shape After Aggregation: \" + str(df.shape))\n",
    "print(type(df))\n",
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ordering\n",
    "\n",
    "Sorting of datasets in order of SNAP_ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241, 2)\n",
      "    SNAP_ID                                             SQL_ID\n",
      "0     43414  [03ggjrmy0wa1w, 06dymzb481vnd, 0aq14dznn91rg, ...\n",
      "1     43415  [0w26sk6t6gq98, 0y080mnfaqk3u, 0y080mnfaqk3u, ...\n",
      "2     43416  [01tp87bk1t2zv, 06dymzb481vnd, 0jj0ct4x4gy27, ...\n",
      "3     43417  [01tp87bk1t2zv, 06dymzb481vnd, 0a08ug2qc1j82, ...\n",
      "4     43418  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "5     43419  [0kcbwucxmazcp, 0kkhhb2w93cx0, 0w26sk6t6gq98, ...\n",
      "6     43420  [0a4un42k35fzy, 0a7q9v9nd2qc1, 0hhmdwwgxbw0r, ...\n",
      "7     43421  [01tp87bk1t2zv, 06dymzb481vnd, 0jj0ct4x4gy27, ...\n",
      "8     43422  [01tp87bk1t2zv, 06dymzb481vnd, 0a08ug2qc1j82, ...\n",
      "9     43423  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "10    43424  [0kcbwucxmazcp, 0kkhhb2w93cx0, 1hxfbnas8xr2j, ...\n",
      "11    43425  [09vrdx888wvvb, 0a7q9v9nd2qc1, 0hhmdwwgxbw0r, ...\n",
      "12    43426  [03ggjrmy0wa1w, 06dymzb481vnd, 0aq14dznn91rg, ...\n",
      "13    43427  [01tp87bk1t2zv, 0w26sk6t6gq98, 130r442w3nfny, ...\n",
      "14    43428  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "15    43429  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "16    43430  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "17    43431  [0kcbwucxmazcp, 0w26sk6t6gq98, 130r442w3nfny, ...\n",
      "18    43432  [0kcbwucxmazcp, 0kkhhb2w93cx0, 0t9xqgg9n3yws, ...\n",
      "19    43433  [01tp87bk1t2zv, 06dymzb481vnd, 0kkhhb2w93cx0, ...\n",
      "20    43434  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "21    43435  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "22    43436  [01tp87bk1t2zv, 0jj0ct4x4gy27, 0kcbwucxmazcp, ...\n",
      "23    43437  [0kcbwucxmazcp, 0kkhhb2w93cx0, 0v3dvmc22qnam, ...\n",
      "24    43438  [03ggjrmy0wa1w, 0aq14dznn91rg, 0f60bzgt9127c, ...\n",
      "25    43439  [01tp87bk1t2zv, 06dymzb481vnd, 130r442w3nfny, ...\n",
      "26    43440  [06dymzb481vnd, 0y080mnfaqk3u, 0y080mnfaqk3u, ...\n",
      "27    43441  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "28    43442  [01tp87bk1t2zv, 06dymzb481vnd, 0a08ug2qc1j82, ...\n",
      "29    43443  [01tp87bk1t2zv, 06dymzb481vnd, 0kcbwucxmazcp, ...\n",
      "..      ...                                                ...\n",
      "70    43484  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "71    43485  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "72    43486  [01tp87bk1t2zv, 0kcbwucxmazcp, 0kkhhb2w93cx0, ...\n",
      "73    43487  [0kcbwucxmazcp, 0kkhhb2w93cx0, 0w26sk6t6gq98, ...\n",
      "74    43488  [03ggjrmy0wa1w, 0aq14dznn91rg, 0f60bzgt9127c, ...\n",
      "75    43489  [01tp87bk1t2zv, 06dymzb481vnd, 130r442w3nfny, ...\n",
      "76    43490  [06dymzb481vnd, 0y080mnfaqk3u, 0y080mnfaqk3u, ...\n",
      "77    43491  [01tp87bk1t2zv, 06dymzb481vnd, 0jj0ct4x4gy27, ...\n",
      "78    43492  [01tp87bk1t2zv, 06dymzb481vnd, 0a08ug2qc1j82, ...\n",
      "79    43493  [01tp87bk1t2zv, 06dymzb481vnd, 0kcbwucxmazcp, ...\n",
      "80    43494  [0kcbwucxmazcp, 0kkhhb2w93cx0, 0w26sk6t6gq98, ...\n",
      "81    43495  [06dymzb481vnd, 0kkhhb2w93cx0, 130r442w3nfny, ...\n",
      "82    43496  [01tp87bk1t2zv, 06dymzb481vnd, 0v3dvmc22qnam, ...\n",
      "83    43497  [01tp87bk1t2zv, 06dymzb481vnd, 0a08ug2qc1j82, ...\n",
      "84    43498  [01tp87bk1t2zv, 06dymzb481vnd, 0kcbwucxmazcp, ...\n",
      "85    43499  [0kcbwucxmazcp, 0kkhhb2w93cx0, 0w26sk6t6gq98, ...\n",
      "86    43500  [03ggjrmy0wa1w, 0aq14dznn91rg, 0f60bzgt9127c, ...\n",
      "87    43501  [06dymzb481vnd, 0ga8vk4nftz45, 13a9r2xkx1bxb, ...\n",
      "88    43502  [062savj8zgzut, 0jj0ct4x4gy27, 0jj0ct4x4gy27, ...\n",
      "89    43503  [01tp87bk1t2zv, 06dymzb481vnd, 0jj0ct4x4gy27, ...\n",
      "90    43504  [01tp87bk1t2zv, 06dymzb481vnd, 0a08ug2qc1j82, ...\n",
      "91    43505  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "92    43506  [0kcbwucxmazcp, 0kkhhb2w93cx0, 0t9xqgg9n3yws, ...\n",
      "93    43507  [01fpx3aqyq6wp, 0a7q9v9nd2qc1, 0hhmdwwgxbw0r, ...\n",
      "94    43508  [01tp87bk1t2zv, 06dymzb481vnd, 0jj0ct4x4gy27, ...\n",
      "95    43509  [01tp87bk1t2zv, 06dymzb481vnd, 0a08ug2qc1j82, ...\n",
      "96    43510  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "97    43511  [0kcbwucxmazcp, 0kkhhb2w93cx0, 0v3dvmc22qnam, ...\n",
      "98    43512  [0a7q9v9nd2qc1, 0hhmdwwgxbw0r, 0kkhhb2w93cx0, ...\n",
      "99    43513  [03ggjrmy0wa1w, 06dymzb481vnd, 0aq14dznn91rg, ...\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df.sort_index(ascending=True,inplace=True)\n",
    "print(df.shape)\n",
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Selection\n",
    "\n",
    "This sextion treats the dataset as a univariate dataset. Therefore the SNAP_ID pertaining to each set of SQL_IDs is removed, with the intent of future classifiers training solely on past SQL executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241, 2)\n",
      "(241, 1)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "del df['SNAP_ID']\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding\n",
    "\n",
    "Since this experiment deals with prediction of upcoming SQL_IDs, respectice SQL_ID strings need to labelled as a numeric representation. Label Encoder will be used here to convert SQL_ID's into a numeric format, which are in turn used for training. Evaluation (achieved predictions) is done so also in numeric format, at which point the label encoder is eventually used to decode back the labels into the original, respetive SQL_ID representation.\n",
    "\n",
    "This section of the experiment additionally converts the targetted label into a binarized version of the previous achieved categorical numeric values.\n",
    "\n",
    "* https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder:\n",
    "    \"\"\"\n",
    "    Scikit Label Encoder was acting up with the following error whilst using the transform function, even though I tripled \n",
    "    checked that the passed data was exactly the same as the one used for training:\n",
    "    \n",
    "    * https://stackoverflow.com/questions/46288517/getting-valueerror-y-contains-new-labels-when-using-scikit-learns-labelencoder\n",
    "    \n",
    "    So I have rebuilt a similar functionality to categorize my data into numeric digits, as the LabelEncoder is supposed to do.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.__class_map = {}\n",
    "        self.__integer_counter = 0\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        :param - X: python list\n",
    "        \"\"\"\n",
    "        for val in X:\n",
    "            if val not in self.__class_map:\n",
    "                self.__class_map[val] = self.__integer_counter\n",
    "                self.__integer_counter += 1\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        param - X: python list\n",
    "        \"\"\"\n",
    "        encoded_map = []\n",
    "        for val in X:\n",
    "            if val in self.__class_map:\n",
    "                value = self.__class_map[val]\n",
    "                encoded_map.append(value)\n",
    "            else:\n",
    "                raise ValueError('Label Mismatch - Encountered a label which was not trained on.')\n",
    "        return encoded_map\n",
    "    \n",
    "    def get_class_map(self):\n",
    "        \"\"\"\n",
    "        Returns original classes as a list\n",
    "        \"\"\"\n",
    "        class_map = []\n",
    "        for key, value in self.__class_map.items():\n",
    "            class_map.append(key)\n",
    "        return class_map\n",
    "    \n",
    "    def get_encoded_map(self):\n",
    "        \"\"\"\n",
    "        Returns class encodings as a list\n",
    "        \"\"\"\n",
    "        encoded_map = []\n",
    "        for key, value in self.__class_map.items():\n",
    "            encoded_map.append(value)\n",
    "        return encoded_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241, 1)\n",
      "                                              SQL_ID\n",
      "0  [03ggjrmy0wa1w, 06dymzb481vnd, 0aq14dznn91rg, ...\n",
      "1  [0w26sk6t6gq98, 0y080mnfaqk3u, 0y080mnfaqk3u, ...\n",
      "2  [01tp87bk1t2zv, 06dymzb481vnd, 0jj0ct4x4gy27, ...\n",
      "3  [01tp87bk1t2zv, 06dymzb481vnd, 0a08ug2qc1j82, ...\n",
      "4  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "5  [0kcbwucxmazcp, 0kkhhb2w93cx0, 0w26sk6t6gq98, ...\n",
      "6  [0a4un42k35fzy, 0a7q9v9nd2qc1, 0hhmdwwgxbw0r, ...\n",
      "7  [01tp87bk1t2zv, 06dymzb481vnd, 0jj0ct4x4gy27, ...\n",
      "8  [01tp87bk1t2zv, 06dymzb481vnd, 0a08ug2qc1j82, ...\n",
      "9  [01tp87bk1t2zv, 06dymzb481vnd, 0y080mnfaqk3u, ...\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Available Classes:\n",
      "Total SQL_ID Classes: 428\n",
      "['03ggjrmy0wa1w', '06dymzb481vnd', '0aq14dznn91rg', '0f60bzgt9127c', '0ga8vk4nftz45', '13a9r2xkx1bxb', '13ys8ux8xvrbm', '14f5ngrj3cc5h', '1jhyrdp21f2q6', '1pv23p59mjs0v']\n",
      "(241, 1)\n",
      "                                              SQL_ID\n",
      "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...\n",
      "1  [67, 68, 68, 68, 69, 70, 71, 72, 73, 74, 74, 7...\n",
      "2  [127, 1, 128, 68, 68, 68, 69, 70, 71, 72, 74, ...\n",
      "3  [127, 1, 141, 141, 68, 68, 68, 69, 142, 70, 71...\n",
      "4  [127, 1, 68, 68, 68, 69, 70, 71, 148, 72, 149,...\n",
      "5  [164, 165, 67, 166, 148, 167, 168, 169, 170, 1...\n",
      "6  [209, 210, 211, 165, 67, 212, 166, 148, 168, 2...\n",
      "7  [127, 1, 128, 68, 68, 68, 69, 70, 71, 72, 74, ...\n",
      "8  [127, 1, 141, 141, 240, 68, 68, 68, 69, 70, 71...\n",
      "9  [127, 1, 68, 68, 68, 69, 70, 71, 72, 149, 74, ...\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.head(10))\n",
    "le = LabelEncoder()\n",
    "for index, row in df.iterrows():\n",
    "    sql_id_list = row['SQL_ID']\n",
    "    le.fit(sql_id_list)\n",
    "for index, row in df.iterrows():\n",
    "    sql_id_list = row['SQL_ID']\n",
    "    transformed_list = le.transform(sql_id_list)\n",
    "    df['SQL_ID'].iloc[index] = transformed_list \n",
    "\n",
    "print(\"\\n----------------------------------\\n\\nAvailable Classes:\")\n",
    "print('Total SQL_ID Classes: ' + str(len(le.get_class_map())))\n",
    "print(le.get_class_map()[:10])\n",
    "print(df.shape)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization\n",
    "\n",
    "A note regarding normalization. Normalization for this experiment was purposely skipped, since training & testing data will be one-hot encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Padding\n",
    "\n",
    "Since there isn't a fixed number of SQL_ID's per SNAP_ID, each set of SQL_IDs need to be padded so as to assume an equal number if SQL_IDs for the purpose of model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length at index 0: 82\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 38, 38, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 50, 50, 51, 52, 53, 53, 53, 53, 54, 54, 54, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 63, 63, 63, 64, 65, 66]\n",
      "Length at index 1: 74\n",
      "[67, 68, 68, 68, 69, 70, 71, 72, 73, 74, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 83, 84, 85, 86, 87, 88, 88, 89, 90, 90, 91, 92, 93, 93, 94, 95, 32, 96, 97, 98, 99, 100, 39, 101, 102, 103, 104, 105, 105, 106, 107, 48, 108, 109, 110, 111, 111, 112, 113, 114, 55, 115, 116, 117, 118, 119, 120, 120, 121, 122, 123, 124, 125, 126]\n",
      "Length at index 2: 91\n",
      "[127, 1, 128, 68, 68, 68, 69, 70, 71, 72, 74, 74, 75, 79, 81, 83, 83, 84, 86, 87, 88, 88, 89, 90, 90, 91, 92, 94, 95, 129, 28, 28, 130, 131, 32, 97, 98, 132, 133, 99, 134, 38, 38, 38, 38, 39, 135, 136, 137, 104, 105, 105, 106, 48, 108, 109, 50, 50, 50, 138, 111, 111, 112, 139, 113, 53, 53, 53, 53, 114, 54, 54, 54, 54, 55, 140, 140, 140, 115, 116, 58, 119, 120, 120, 123, 124, 125, 63, 63, 63, 63]\n",
      "\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "\n",
      "Length at index 0: 108\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 28 29 30 31 32 33 34 35 36 37 38 38 38 38 39 40 41 42 43\n",
      " 44 45 46 47 48 49 50 50 50 51 52 53 53 53 53 54 54 54 54 55 56 57 58 59\n",
      " 60 61 62 63 63 63 63 64 65 66 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Length at index 1: 108\n",
      "[ 67  68  68  68  69  70  71  72  73  74  74  75  76  77  78  79  80  81\n",
      "  82  83  83  84  85  86  87  88  88  89  90  90  91  92  93  93  94  95\n",
      "  32  96  97  98  99 100  39 101 102 103 104 105 105 106 107  48 108 109\n",
      " 110 111 111 112 113 114  55 115 116 117 118 119 120 120 121 122 123 124\n",
      " 125 126  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1\n",
      "  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1]\n",
      "Length at index 2: 108\n",
      "[127   1 128  68  68  68  69  70  71  72  74  74  75  79  81  83  83  84\n",
      "  86  87  88  88  89  90  90  91  92  94  95 129  28  28 130 131  32  97\n",
      "  98 132 133  99 134  38  38  38  38  39 135 136 137 104 105 105 106  48\n",
      " 108 109  50  50  50 138 111 111 112 139 113  53  53  53  53 114  54  54\n",
      "  54  54  55 140 140 140 115 116  58 119 120 120 123 124 125  63  63  63\n",
      "  63  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Length at index 0: \" + str(len(df['SQL_ID'].iloc[0])))\n",
    "print(df['SQL_ID'].iloc[0])\n",
    "print(\"Length at index 1: \" + str(len(df['SQL_ID'].iloc[1])))\n",
    "print(df['SQL_ID'].iloc[1])\n",
    "print(\"Length at index 2: \" + str(len(df['SQL_ID'].iloc[2])))\n",
    "print(df['SQL_ID'].iloc[2])\n",
    "\n",
    "# Retrieve largest length\n",
    "def pad_datamatrix(df):\n",
    "    \"\"\"\n",
    "    Iterates over dataframe and pads SQL_ID lists accordingly with -1 values, denoting empty SQL_ID slots.\n",
    "    \"\"\"\n",
    "    row_sizes = []\n",
    "    for index, row in df.iterrows():\n",
    "        row_sizes.append(len(row['SQL_ID']))\n",
    "    max_row_size = max(row_sizes)\n",
    "    \n",
    "    # Pad Dataframe Values\n",
    "    i = 0\n",
    "    for index, row in df.iterrows():\n",
    "        length = len(row['SQL_ID'])\n",
    "        diff = max_row_size - length\n",
    "        if diff != 0:\n",
    "            for j in range(length, max_row_size):\n",
    "                df['SQL_ID'].iloc[i] = np.append(df['SQL_ID'].iloc[i], -1) # Appends -1 to padded values\n",
    "        # print(\"Length at index \" + str(i) + \": \" + str(df['SQL_ID'].iloc[i].size))\n",
    "        i += 1\n",
    "    return df\n",
    "\n",
    "df = pad_datamatrix(df)\n",
    "\n",
    "print('\\n\\n------------------------------------------\\n\\n')\n",
    "print(\"Length at index 0: \" + str(len(df['SQL_ID'].iloc[0])))\n",
    "print(df['SQL_ID'].iloc[0])\n",
    "print(\"Length at index 1: \" + str(len(df['SQL_ID'].iloc[1])))\n",
    "print(df['SQL_ID'].iloc[1])\n",
    "print(\"Length at index 2: \" + str(len(df['SQL_ID'].iloc[2])))\n",
    "print(df['SQL_ID'].iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand Feature Lists\n",
    "\n",
    "Expand Feature Lists, where in each list element is represented as it's own features. Total feature count here equates as follows:\n",
    "\n",
    "* Features = (lag * SQL_ID per SNAP_ID count) + SQL_ID per SNAP_ID count\n",
    "* Labels = lag * SQL_ID per SNAP_ID count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features\n",
      "Before: (241, 1)\n",
      "After: (241, 108)\n"
     ]
    }
   ],
   "source": [
    "def sequence2features(df):\n",
    "    \"\"\"\n",
    "    Converts pandas sequences into full fledged columns/features\n",
    "    \"\"\"\n",
    "    feature_count = len(df[df.columns[0]].iloc[0])\n",
    "    for column_name in df.columns:\n",
    "        data_matrix = []\n",
    "        new_values = df[column_name].values\n",
    "        \n",
    "        new_values = np.stack(new_values, axis=0 )\n",
    "        \n",
    "        for i in range(1,feature_count+1):\n",
    "            new_column_name = column_name + \"_\"+str(i)\n",
    "            df[new_column_name] = new_values[:,i-1]\n",
    "        \n",
    "        # Drop original list columns\n",
    "        df.drop(column_name, inplace=True, axis=1)\n",
    "    return df\n",
    "\n",
    "print('Features')\n",
    "print('Before: ' + str(df.shape))\n",
    "df = sequence2features(df=df)\n",
    "print('After: ' + str(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "\n",
    "One hot encoding target labels for deep learning application\n",
    "\n",
    "* https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEncoder:\n",
    "    \n",
    "    def __init__(self, classes):\n",
    "        self.__mapper = pd.DataFrame(columns=classes)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        class_types = self.__mapper.columns\n",
    "        for row in X:\n",
    "            temp_row = []\n",
    "            for i in range(len(class_types)):\n",
    "                if class_types[i] in row:\n",
    "                    temp_row.append(float(1))\n",
    "                else:\n",
    "                    temp_row.append(float(0))\n",
    "            self.__mapper.loc[len(self.__mapper)] = temp_row\n",
    "        return self.__mapper\n",
    "    \n",
    "    def get_classes(self):\n",
    "        return self.__mapper.columns\n",
    "    \n",
    "    def get_unique_values(self):\n",
    "        return np.unique(self.__mapper.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "Before One Hot Encoding: (241, 108)\n",
      "After One Hot Encoding: (241, 428)\n",
      "     0    1    2    3    4    5    6    7    8    9   ...   418  419  420  \\\n",
      "0    1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0 ...   0.0  0.0  0.0   \n",
      "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "2    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "3    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "4    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "5    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "6    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "7    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "8    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "9    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "10   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "11   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "12   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0 ...   0.0  0.0  0.0   \n",
      "13   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "14   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "15   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "16   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "17   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "18   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "19   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "20   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "21   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "22   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "23   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "24   1.0  0.0  1.0  1.0  1.0  1.0  1.0  0.0  1.0  1.0 ...   0.0  0.0  0.0   \n",
      "25   0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "26   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "27   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "28   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "29   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ... ...   ...  ...  ...   \n",
      "211  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   1.0  0.0  0.0   \n",
      "212  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "213  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "214  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "215  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  1.0  1.0   \n",
      "216  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "217  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "218  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "219  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "220  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "221  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "222  1.0  1.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  0.0 ...   0.0  0.0  0.0   \n",
      "223  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "224  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "225  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "226  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "227  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "228  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "229  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "230  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "231  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "232  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "233  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "234  1.0  0.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  0.0 ...   0.0  0.0  0.0   \n",
      "235  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "236  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "237  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "238  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "239  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "240  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0   \n",
      "\n",
      "     421  422  423  424  425  426  427  \n",
      "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "5    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "6    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "8    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "9    0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "10   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "11   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "12   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "13   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "14   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "15   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "16   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "17   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "18   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "19   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "20   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "21   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "22   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "23   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "24   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "25   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "26   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "27   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "28   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "29   0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "..   ...  ...  ...  ...  ...  ...  ...  \n",
      "211  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "212  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "213  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "214  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "215  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "216  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "217  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "218  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "219  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "220  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "221  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "222  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "223  0.0  1.0  1.0  0.0  0.0  0.0  0.0  \n",
      "224  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "225  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "226  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "227  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "228  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "229  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "230  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "231  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "232  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
      "233  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
      "234  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "235  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "236  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "237  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "238  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "239  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "240  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[241 rows x 428 columns]\n",
      "Value type: [0. 1.]\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# One Hot Encoding train data\n",
    "ohe = OneHotEncoder(classes=le.get_encoded_map())\n",
    "print('Training Data:')\n",
    "print(\"Before One Hot Encoding: \" + str(df.shape))\n",
    "df = ohe.fit_transform(X=df.values)\n",
    "print(\"After One Hot Encoding: \" + str(df.shape))\n",
    "print(df)\n",
    "print('Value type: ' + str(ohe.get_unique_values()))\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Shifting\n",
    "\n",
    "Shifting the datasets N lag minutes, in order to transform the problem into a supervised dataset. Each Lag Shift equates to 60 seconds (due to the way design of the data capturing tool). For each denoted lag amount, the same number of feature vectors will be stripped away at the beginning.\n",
    "\n",
    "Features and Labels are separated into seperate dataframes at this point.\n",
    "\n",
    "https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------\n",
      "Features\n",
      "Index(['var1(t-13)', 'var2(t-13)', 'var3(t-13)', 'var4(t-13)', 'var5(t-13)',\n",
      "       'var6(t-13)', 'var7(t-13)', 'var8(t-13)', 'var9(t-13)', 'var10(t-13)',\n",
      "       ...\n",
      "       'var419(t)', 'var420(t)', 'var421(t)', 'var422(t)', 'var423(t)',\n",
      "       'var424(t)', 'var425(t)', 'var426(t)', 'var427(t)', 'var428(t)'],\n",
      "      dtype='object', length=5992)\n",
      "(215, 5992)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "-------------\n",
      "Labels\n",
      "Index(['var1(t+1)', 'var2(t+1)', 'var3(t+1)', 'var4(t+1)', 'var5(t+1)',\n",
      "       'var6(t+1)', 'var7(t+1)', 'var8(t+1)', 'var9(t+1)', 'var10(t+1)',\n",
      "       ...\n",
      "       'var419(t+13)', 'var420(t+13)', 'var421(t+13)', 'var422(t+13)',\n",
      "       'var423(t+13)', 'var424(t+13)', 'var425(t+13)', 'var426(t+13)',\n",
      "       'var427(t+13)', 'var428(t+13)'],\n",
      "      dtype='object', length=5564)\n",
      "(215, 5564)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = data\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    if n_in != 0:\n",
    "        for i in range(n_in, 0, -1):\n",
    "            cols.append(df.shift(i))\n",
    "            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    n_out += 1\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "def remove_n_time_steps(data, n=1):\n",
    "    if n == 0:\n",
    "        return data\n",
    "    df = data\n",
    "    headers = df.columns\n",
    "    dropped_headers = []\n",
    "    #\n",
    "    for i in range(1,n+1):\n",
    "        for header in headers:\n",
    "            if \"(t+\"+str(i)+\")\" in header:\n",
    "                dropped_headers.append(str(header))\n",
    "    #\n",
    "    return df.drop(dropped_headers, axis=1) \n",
    "\n",
    "# Frame as supervised learning set\n",
    "shifted_df = series_to_supervised(df, lag, lag)\n",
    "\n",
    "# Seperate labels from features\n",
    "x_columns, y_columns = [], []\n",
    "for col in shifted_df.columns:\n",
    "    if '+' in col:\n",
    "        y_columns.append(col)\n",
    "    else:\n",
    "        x_columns.append(col)\n",
    "\n",
    "y_df = shifted_df[y_columns]\n",
    "X_df = shifted_df[x_columns]\n",
    "print('\\n-------------\\nFeatures')\n",
    "print(X_df.columns)\n",
    "print(X_df.shape)\n",
    "print(type(X_df))\n",
    "print('\\n-------------\\nLabels')\n",
    "print(y_df.columns)\n",
    "print(y_df.shape)\n",
    "print(type(y_df))\n",
    "\n",
    "# # Delete middle timesteps\n",
    "# X_df = remove_n_time_steps(data=X_df, n=lag)\n",
    "# print('\\n-------------\\nFeatures After Time Shift')\n",
    "# print(X_df.columns)\n",
    "# print(X_df.shape)\n",
    "# print(type(X_df))\n",
    "# # y_df = remove_n_time_steps(data=y_df, n=lag)\n",
    "# print('\\n-------------\\nLabels After Time Shift')\n",
    "# print(y_df.columns)\n",
    "# print(y_df.shape)\n",
    "# print(type(y_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model\n",
    "\n",
    "### Designing the network\n",
    "\n",
    "The Keras library provides wrapper classes to allow you to use neural network models developed with Keras in scikit-learn.\n",
    "\n",
    "There is a KerasClassifier class in Keras that can be used as an Estimator in scikit-learn, the base type of model in the library. The KerasClassifier takes the name of a function as an argument. This function must return the constructed neural network model, ready for training.\n",
    "\n",
    "The hidden layer uses a rectifier activation function which is a good practice. Because we used a one-hot encoding for our SQL_ID dataset, the output layer must create n output values, one for each SQL_ID class. The output value with the largest value will be taken as the class predicted by the model.\n",
    "\n",
    "The network topology of this simple one-layer neural network can be summarized as:\n",
    "\n",
    "* n_inputs = Number of input neurons dependent on SQL_ID Features (Vector Width)\n",
    "* n_hidden = Number of hidden layer neurons (This will almost be the same as n_inputs, pending testing)\n",
    "* n_output = Number of output neurons dependent on SQL_ID Classes.\n",
    "\n",
    "n_inputs -> [n_hidden] -> n_output\n",
    "\n",
    "### Relavent Links\n",
    "\n",
    "Network structure pointers [https://www.heatonresearch.com/2017/06/01/hidden-layers.html]. Rough heuristics to start with:\n",
    "\n",
    "* The number of hidden neurons should be between the size of the input layer and the size of the output layer.\n",
    "* The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer.\n",
    "* The number of hidden neurons should be less than twice the size of the input layer.\n",
    "\n",
    "--------------------------------------------------------------------------------------------\n",
    "\n",
    "* https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n",
    "* https://arxiv.org/pdf/1312.6026.pdf\n",
    "* https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8141873"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeuralNet Class\n",
    "class NeuralNet:\n",
    "    \"\"\"\n",
    "    NeuralNet Class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, y, lag, loss_func, activation, optimizer='sgd', layers=1, dropout=.0,\n",
    "                 initializer='uniform'):\n",
    "        \"\"\"\n",
    "        Initiating the class creates a net with the established parameters\n",
    "        :param X             - (Numpy 2D Array) Training data used to train the model (Features).\n",
    "        :param y             - (Numpy 2D Array) Test data used to test the model (Labels\n",
    "        :param lag           - (Integer) Denotes lag step value\n",
    "        :param loss_function - (String)  Denotes mode of measure fitting of model (Fitting function).\n",
    "        :param activation    - (String)  Neuron activation function used to activate/trigger neurons.\n",
    "        :param optimizer     - (String)  Denotes which function to us to optimize the model build (eg: Gradient Descent).\n",
    "        :param layers        - (Integer) Denotes the number of Neuron layers to be included in the model build.\n",
    "        :param dropout       - (Float)   Denotes amount of dropout for model. This parameter must be a value between 0 and 1.\n",
    "        :param: initializer  - (String)  String initializer which denotes starting weights.\n",
    "        \"\"\"\n",
    "        self.__lag = lag\n",
    "        self.__model = ke.models.Sequential()\n",
    "\n",
    "        if dropout > 1 and dropout < 0:\n",
    "            raise ValueError('Dropout parameter exceeded! Must be a value between 0 and 1.')\n",
    "\n",
    "        for i in range(0, layers-1):\n",
    "            self.__model.add(ke.layers.Dense(X.shape[1],\n",
    "                                             kernel_initializer=initializer,\n",
    "                                             activation=activation,\n",
    "                                             input_shape=(X.shape[1],)))\n",
    "            self.__model.add(ke.layers.Dropout(dropout))\n",
    "        self.__model.add(ke.layers.Dense(X.shape[1],\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation=activation,\n",
    "                                         input_shape=(X.shape[1],)))\n",
    "        self.__model.add(ke.layers.Dropout(dropout))\n",
    "        self.__model.add(ke.layers.Dense(y.shape[1],\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation=activation))\n",
    "        self.__model.compile(loss=loss_func, \n",
    "                             optimizer=optimizer, \n",
    "                             metrics=['acc'])\n",
    "        print(self.__model.summary())\n",
    "\n",
    "    def fit_model(self, X_train=None, X_test=None, y_train=None, y_test=None, epochs=50, batch_size=50, verbose=2,\n",
    "                  shuffle=False, plot=False):\n",
    "        \"\"\"\n",
    "        Fit data to model & validate. Trains a number of epochs.\n",
    "\n",
    "        :param: X_train    - (Numpy 2D Array) Numpy matrix consisting of input training features\n",
    "        :param: X_test     - (Numpy 2D Array) Numpy matrix consisting of input validation/testing features\n",
    "        :param: y_train    - (Numpy 2D Array) Numpy matrix consisting of output training labels\n",
    "        :param: y_test     - (Numpy 2D Array) Numpy matrix consisting of output validation/testing labels\n",
    "        :param: epochs     - (Integer) Integer value denoting number of trained epochs\n",
    "        :param: verbose    - (Integer) Integer value denoting net verbosity (Amount of information shown to user during NeuralNet training)\n",
    "        :param: shuffle    - (Bool) Boolean value denoting whether or not to shuffle data. This parameter must always remain 'False' for time series datasets.\n",
    "        :param: plot       - (Bool) Boolean value denoting whether this function should plot out it's evaluation\n",
    "\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if X_test is not None and y_test is not None:\n",
    "            history = self.__model.fit(x=X_train,\n",
    "                                       y=y_train,\n",
    "                                       epochs=epochs,\n",
    "                                       batch_size=batch_size,\n",
    "                                       validation_data=(X_test, y_test),\n",
    "                                       verbose=verbose,\n",
    "                                       shuffle=shuffle)\n",
    "        else:\n",
    "            history = self.__model.fit(x=X_train,\n",
    "                                       y=y_train,\n",
    "                                       epochs=epochs,\n",
    "                                       batch_size=batch_size,\n",
    "                                       verbose=verbose,\n",
    "                                       shuffle=shuffle)\n",
    "\n",
    "        if plot:\n",
    "            plt.rcParams['figure.figsize'] = [20, 15]\n",
    "            plt.plot(history.history['acc'], label='train')\n",
    "            plt.plot(history.history['val_acc'], label='validation')\n",
    "            plt.ylabel('loss')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend(['train', 'validation'], loc='upper left')\n",
    "            plt.show()\n",
    "\n",
    "    def predict(self, X, batch_size):\n",
    "        \"\"\"\n",
    "        Predicts label/s from input feature 'X'\n",
    "        :param: X - Numpy matrix consisting of a single feature vector\n",
    "        :param: batch_size - (Integer) Denotes prediction batch size\n",
    "        :return: Numpy matrix of predicted label output\n",
    "        \"\"\"\n",
    "        yhat = self.__model.predict(X, batch_size=batch_size)\n",
    "        return yhat\n",
    "\n",
    "    def evaluate(self, y, yhat, plot=False):\n",
    "        \"\"\"\n",
    "        Receives 2D matrix of input features and 2D matrix of output labels, and evaluates input data and target predictions.\n",
    "        :param: y    - Numpy array consisting of output label vectors (Test Set)\n",
    "        :param: yhat - Numpy array consisting of output label vectors (Prediction Set)\n",
    "        :param: plot     - (Bool) Boolean value denoting whether this function should plot out it's evaluation\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        y = y.flatten()\n",
    "        yhat = yhat.flatten()\n",
    "\n",
    "        # F1-Score Evaluation\n",
    "        print(y)\n",
    "        print(yhat)\n",
    "        accuracy = accuracy_score(y, yhat)\n",
    "        f1 = f1_score(y,\n",
    "                      yhat,\n",
    "                      average='macro')  # Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "        print('Accuracy [' + str(accuracy) + ']')\n",
    "        print('FScore [' + str(f1) + ']')\n",
    "\n",
    "        if plot:\n",
    "            plt.rcParams['figure.figsize'] = [20, 15]\n",
    "            plt.plot(y, label='actual')\n",
    "            plt.plot(yhat, label='predicted')\n",
    "            plt.legend(['actual', 'predicted'], loc='upper left')\n",
    "            plt.title('Actual vs Predicted')\n",
    "            plt.show()\n",
    "        else:\n",
    "            return accuracy, f1\n",
    "\n",
    "    @staticmethod\n",
    "    def write_results_to_disk(path, iteration, lag, test_split, batch, dropout, epoch, layer, activation, initializer,\n",
    "                              rmse, accuracy, f_score, time_train):\n",
    "        \"\"\"\n",
    "        Static method which is used for test harness utilities. This method attempts a grid search across many\n",
    "        trained NeuralNet models, each denoted with different configurations.\n",
    "\n",
    "        Attempted configurations:\n",
    "        * Varied data test split\n",
    "        * Varied batch sizes\n",
    "        * Varied epoch counts\n",
    "\n",
    "        Each configuration is denoted with a score, and used to identify the most optimal configuration.\n",
    "\n",
    "        :param: path       - (String) String denoting result csv output.\n",
    "        :param: iteration  - (Integer) Integer denoting test iteration (Unique per test configuration).\n",
    "        :param: lag        - (Integer) Denotes lag time shift\n",
    "        :param: test_split - (Float) Float denoting data sample sizes.\n",
    "        :param: epoch      - (Integer) Integer denoting number of NeuralNet training iterations.\n",
    "        :param: layer      - (Integer) Integer denoting number of NeuralNet layers.\n",
    "        :param: activation - (String) String denoting activation for NeuralNet layers.\n",
    "        :param: initializer- (String) String denoting NeuralNet initializing weights.\n",
    "        :param: dropout    - (Float) Float denoting model dropout layer.\n",
    "        :param: rmse       - (Float) Float denoting experiment configuration RSME score.\n",
    "        :param: accuracy   - (Float) Float denoting experiment accuracy score.\n",
    "        :param: fscore     - (Float) Float denoting experiment fscore score.\n",
    "        :param: time_train - (Integer) Integer denoting number of seconds taken by NeuralNet training iteration.\n",
    "\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        file_exists = os.path.isfile(path)\n",
    "        with open(path, 'a+') as csvfile:\n",
    "            headers = ['iteration', 'test_split', 'batch', 'epoch', 'layer', 'dropout', 'activation', 'initializer',\n",
    "                       'rmse', 'accuracy', 'f_score', 'time_train', 'lag']\n",
    "            writer = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=headers)\n",
    "            if not file_exists:\n",
    "                writer.writeheader()  # file doesn't exist yet, write a header\n",
    "            writer.writerow({'iteration': iteration,\n",
    "                             'test_split': test_split,\n",
    "                             'batch': batch,\n",
    "                             'epoch': epoch,\n",
    "                             'layer': layer,\n",
    "                             'dropout': dropout,\n",
    "                             'activation': activation,\n",
    "                             'initializer': initializer,\n",
    "                             'rmse': rmse,\n",
    "                             'accuracy': accuracy,\n",
    "                             'f_score': f_score,\n",
    "                             'time_train': time_train,\n",
    "                             'lag': lag})\n",
    "\n",
    "    @staticmethod\n",
    "    def lag_multiple(X, lag):\n",
    "        \"\"\"\n",
    "        Divides the total number of rows by the lag value, until a perfect multiple amount is retrieved.\n",
    "        :param X: (Numpy) 2D array consisting of input.\n",
    "        :param lag: (Integer) Denotes time shift value.\n",
    "        :return: (Numpy) 2D array consisting of a perfect lag multiple rows.\n",
    "        \"\"\"\n",
    "        n_rows = X.shape[0]\n",
    "        multiple = int(n_rows/lag)\n",
    "        max_new_rows = multiple * lag\n",
    "        return X[0:max_new_rows,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reshaping Training Frames\n",
      "X_train shape [(172, 5992)] Type - <class 'numpy.ndarray'>\n",
      "X_validate shape [(21, 5992)] Type - <class 'numpy.ndarray'>\n",
      "X_test shape [(22, 5992)] Type - <class 'numpy.ndarray'>\n",
      "y_train shape [(172, 5564)] Type - <class 'numpy.ndarray'>\n",
      "y_validate shape [(21, 5564)] Type - <class 'numpy.ndarray'>\n",
      "y_test shape [(22, 5564)] Type - <class 'numpy.ndarray'>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 5992)              35910056  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5992)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5992)              35910056  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5992)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5564)              33345052  \n",
      "=================================================================\n",
      "Total params: 105,165,164\n",
      "Trainable params: 105,165,164\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 172 samples, validate on 21 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 2.5273 - acc: 0.8432 - val_loss: 2.5066 - val_acc: 0.8445\n",
      "Epoch 2/10\n",
      " - 8s - loss: 2.5273 - acc: 0.8432 - val_loss: 2.5066 - val_acc: 0.8445\n",
      "Epoch 3/10\n",
      " - 8s - loss: 2.5273 - acc: 0.8432 - val_loss: 2.5066 - val_acc: 0.8445\n",
      "Epoch 4/10\n",
      " - 6s - loss: 2.5273 - acc: 0.8432 - val_loss: 2.5066 - val_acc: 0.8445\n",
      "Epoch 5/10\n",
      " - 7s - loss: 2.5273 - acc: 0.8432 - val_loss: 2.5066 - val_acc: 0.8445\n",
      "Epoch 6/10\n",
      " - 8s - loss: 2.5273 - acc: 0.8432 - val_loss: 2.5066 - val_acc: 0.8445\n",
      "Epoch 7/10\n",
      " - 8s - loss: 2.5273 - acc: 0.8432 - val_loss: 2.5066 - val_acc: 0.8445\n",
      "Epoch 8/10\n",
      " - 8s - loss: 2.5273 - acc: 0.8432 - val_loss: 2.5066 - val_acc: 0.8445\n",
      "Epoch 9/10\n",
      " - 8s - loss: 2.5273 - acc: 0.8432 - val_loss: 2.5066 - val_acc: 0.8445\n",
      "Epoch 10/10\n",
      " - 7s - loss: 2.5273 - acc: 0.8432 - val_loss: 2.5066 - val_acc: 0.8445\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 1s 509ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 982ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 985ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 747ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 656ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 1s 535ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 734ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 728ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "Accuracy [0.8444849542980384]\n",
      "FScore [0.4578432327844207]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 762ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 619ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "Accuracy [0.8446016600222208]\n",
      "FScore [0.4578775343897535]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAANeCAYAAABj0NXxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzs3XmYXnV9///XZzKTPSGEgEoRk2+lBRewCIqVWvmhFa3b1brvtULd6lZadxusturXooIoRlEUw46sshkJexJISAIJSSD7TiaZLJM9kzm/P2b0izFKlECQz+NxXXNdc9/nc5/zvm9Hr/i8zjl3aZomAAAAANSjZV8PAAAAAMDjSxACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAwJNCKeWlpZSl+3qOR6OUsrCU8rLe3z9TSvnB43DMP/nPDQD4wwlCAMBeUUq5uZSytpTSbw/XjyylNKWU1sd6tr2llHJuKWV7KWVjKaWjlPKLUsrhj8Wxmqb576Zp3reHM33psZgBAHjyEoQAgEetlDIyyd8kaZK8dp8O89j7WtM0g5MckmRVknN3t+hPKXQBAPURhACAveFdSSamJ468++EbSikDSin/W0pZVEpZX0q5vZQyIMmtvUvW9Z5x86JSyuhSyk8f9trfOIuolPJPpZRZpZTOUsr8Usq/7MlwpZSzSylf3+W5K0spn+j9/ZOllGW9+51TSjnxkfbZNM3mJOcneU7vPkaXUi4tpfy0lLIhyXtKKS2llE+VUuaVUtaUUi4upQx/2Azv7P1c1pRSPrvLfLt+FseXUu4spawrpSwppbynlHJKkrcn+Y/ez/Dq3rUHl1IuK6W0l1IWlFI+sst/Huf2ns11f5Jj9+QzBACeXAQhAGBveFeSsb0/ryilPOVh276e5PlJ/jrJ8CT/kaQ7yUt6tw9rmmZw0zQT9uA4q5K8OsnQJP+U5BullKP34HXnJ3lzKaUkSSll/yR/l+TCUspfJvlwkmObphmS5BVJFj7SDkspg9MTY6Y+7OnXJbk0ybD0fBYfSfL6JH+b5OAka5Oc1fv6ZyX5bpJ39m47ID1nHe3uWIcmuS7JmUkOTPK8JNOaphnTe5yv9X6GrymltCS5Osn0JH+W5MQkHyulvKJ3d/+Z5M97f16RXQIeAFAHQQgAeFRKKccneUaSi5ummZJkXpK39W5rSfLeJB9tmmZZ0zQ7m6a5s2mabX/MsZqm+XnTNPOaHrckuTE9l6o9ktvScznbr9a+IcmEpmmWJ9mZpF+SZ5VS2pqmWdg0zbzfs69TSynrksxNMjjJex62bULTNFc0TdPdNM2WJP+S5LNN0yztfc+jk7yh94ynNyS5pmmaW3u3fT49oWx33p5kXNM0FzRNs6NpmjVN00z7HWuPTXJg0zRfbJpme9M085N8P8lbere/KcmXm6bpaJpmSZIzfs97BQCepAQhAODReneSG5umWd37+Pz8v7NORiTpn55I9KiVUl5ZSpnYe0PndUle1XuM36tpmibJhUne2vvU29JzZk2appmb5GPpiTWrSikXllIO/j27+3rTNMOapnlq0zSv3SUeLdll7TOSXN57mde6JLPSE6Cekp6zgn69vmmaTUnW/I5jPj17/hk+I8nBvzpm73E/03vM7HrcJIv2cL8AwJOIIAQA/NF67wX0piR/W0pZWUpZmeTjSY4qpRyVZHWSrem5PGlXzW6e25Rk4MMeP/Vhx+qX5LL0XIL2lKZphiW5NknZw3EvSM/ZOc9I8sLeffUM0jTnN03zqzOdmiRf3cN97mrX97QkySt7A9Kvfvo3TbMsyYr0hJ4kSSllYHouG9udJdn9Z/i7jrlgl2MOaZrmVb3bf+O4SQ7dg/cFADzJCEIAwKPx+vSc8fKs9NzX5nlJjkjPJVrvapqmO8kPk5zee6PjPr03j+6XpD09l0j9n4ftb1qSl5RSDi2l7Jfk0w/b1jc9l3a1J+kqpbwyPfcB2iNN00ztfe0PktzQNM26JCml/GUp5f/rnWlrki2972lvODvJl3sjVEopB5ZSXte77dIkr+69WXTfJF/M7/632dgkLyulvKmU0lpKOaCU8rzebQ/lNz/Du5Js6L1R9oDez/w5pZRf3Tz64iSfLqXsX0o5JMm/7qX3CgD8CRGEAIBH491JftQ0zeKmaVb+6ifJt5O8vfdeOacmuS/J3Uk60nP2TUvvt3R9OckdvZc2Hdc0zS+SXJTk3iRTklzzqwM1TdOZnps0X5yemzO/LclVf+C8FyR5WXoua/uVfkm+kp6zmVYmOSg9l1jtDd9Kz4w3llI60/NNbC9MkqZpZib5UO8sK9LznpbubidN0yxOz+Vx/5aez3BakqN6N5+TnvsfrSulXNE0zc4kr0lPnFvQ+75+kGS/3vWnpecysQXpuQfTeXvpvQIAf0JKzyX1AAAAANTCGUIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqEzrvjrwiBEjmpEjR+6rwwMAAAA86UyZMmV10zQHPtK6fRaERo4cmcmTJ++rwwMAAAA86ZRSFu3JOpeMAQAAAFRGEAIAAACojCAEAAAAUJl9dg+h3dmxY0eWLl2arVu37utR/uT1798/hxxySNra2vb1KAAAAMATzBMqCC1dujRDhgzJyJEjU0rZ1+P8yWqaJmvWrMnSpUszatSofT0OAAAA8ATzhLpkbOvWrTnggAPEoEeplJIDDjjAmVYAAADAbj2hglASMWgv8TkCAAAAv8sTLggBAAAA8NgShB6Fm2++OXfeeeej2sfgwYP30jQAAAAAe0YQehT2RhACAAAAeLwJQrvx+te/Ps9//vPz7Gc/O2PGjEmSXH/99Tn66KNz1FFH5cQTT8zChQtz9tln5xvf+Eae97zn5bbbbst73vOeXHrppb/ez6/O/tm4cWNOPPHEHH300Xnuc5+bK6+8cp+8LwAAAIDkCfa18w932tUzc//yDXt1n886eGj+8zXPfsR1P/zhDzN8+PBs2bIlxx57bF73utfl5JNPzq233ppRo0alo6Mjw4cPz/vf//4MHjw4p556apLknHPO2e3++vfvn8svvzxDhw7N6tWrc9xxx+W1r32tGz8DAAAA+8QTNgjtS2eccUYuv/zyJMmSJUsyZsyYvOQlL8moUaOSJMOHD/+D9tc0TT7zmc/k1ltvTUtLS5YtW5aHHnooT33qU/f67AAAAACP5AkbhPbkTJ7Hws0335xx48ZlwoQJGThwYF760pfmqKOOypw5cx7xta2trenu7k7SE4G2b9+eJBk7dmza29szZcqUtLW1ZeTIkdm6detj+j4AAAAAfhf3ENrF+vXrs//++2fgwIGZPXt2Jk6cmG3btuWWW27JggULkiQdHR1JkiFDhqSzs/PXrx05cmSmTJmSJLnyyiuzY8eOX+/zoIMOSltbW8aPH59FixY9zu8KAAAA4P8RhHZx0kknpaurK0ceeWQ+//nP57jjjsuBBx6YMWPG5B/+4R9y1FFH5c1vfnOS5DWveU0uv/zyX99U+uSTT84tt9ySF7zgBZk0aVIGDRqUJHn729+eyZMn55hjjsnYsWNz+OGH78u3CAAAAFSuNE2zTw58zDHHNJMnT/6N52bNmpUjjjhin8zzZOTzBAAAgLqUUqY0TXPMI61zhhAAAABAZQQhAAAAgMoIQgAAAACVEYQAAAAAKiMIAQAAAFRGEAIAAACojCD0GBs8eHCSZPny5XnDG97we9d+85vfzObNm/+g/d9888159atf/UfPBwAAANRHEPoj7Ny58w9+zcEHH5xLL7309675Y4IQAAAAwB9KENrFwoULc/jhh+fd7353jjzyyLzhDW/I5s2bM3LkyHzxi1/M8ccfn0suuSTz5s3LSSedlOc///n5m7/5m8yePTtJsmDBgrzoRS/Ksccem89//vO/sd/nPOc5SXqC0qmnnprnPve5OfLII3PmmWfmjDPOyPLly3PCCSfkhBNOSJLceOONedGLXpSjjz46b3zjG7Nx48YkyfXXX5/DDz88xx9/fH72s589zp8QAAAA8KeudV8P8Dtd96lk5X17d59PfW7yyq884rI5c+bknHPOyYtf/OK8973vzXe+850kSf/+/XP77bcnSU488cScffbZOeywwzJp0qR88IMfzE033ZSPfvSj+cAHPpB3vetdOeuss3a7/zFjxmTBggWZOnVqWltb09HRkeHDh+f000/P+PHjM2LEiKxevTpf+tKXMm7cuAwaNChf/epXc/rpp+c//uM/cvLJJ+emm27KM5/5zLz5zW/ee58PAAAAUIUnbhDah57+9KfnxS9+cZLkHe94R84444wk+XV82bhxY+6888688Y1v/PVrtm3bliS54447ctlllyVJ3vnOd+aTn/zkb+1/3Lhxef/735/W1p6Pf/jw4b+1ZuLEibn//vt/Pcf27dvzohe9KLNnz86oUaNy2GGH/Xq+MWPG7JX3DQAAANThiRuE9uBMnsdKKWW3jwcNGpQk6e7uzrBhwzJt2rQ9ev2umqbZozUvf/nLc8EFF/zG89OmTXvE1wIAAAD8Pu4htBuLFy/OhAkTkiQXXHBBjj/++N/YPnTo0IwaNSqXXHJJkp54M3369CTJi1/84lx44YVJkrFjx+52/3/3d3+Xs88+O11dXUmSjo6OJMmQIUPS2dmZJDnuuONyxx13ZO7cuUmSzZs354EHHsjhhx+eBQsWZN68eb+eDwAAAOAPIQjtxhFHHJEf//jHOfLII9PR0ZEPfOADv7Vm7NixOeecc3LUUUfl2c9+dq688sokybe+9a2cddZZOfbYY7N+/frd7v9973tfDj300Bx55JE56qijcv755ydJTjnllLzyla/MCSeckAMPPDDnnntu3vrWt+bII4/Mcccdl9mzZ6d///4ZM2ZM/v7v/z7HH398nvGMZzx2HwQAAADwpFSaptknBz7mmGOayZMn/8Zzs2bNyhFHHLFP5vmVhQsX5tWvfnVmzJixT+fYG54InycAAADw+CmlTGma5phHWveIZwiVUn5YSllVStltISk9ziilzC2l3FtKOfqPGRgAAACAx8eeXDJ2bpKTfs/2VyY5rPfnlCTfffRj7TsjR458UpwdBAAAAPC79Bk9evTvXTB69OhFp512Wr8kbxs9evR3dt1+2mmnnZrkyqZp7hs9evTS00477d9PO+20y0aPHr3x9+13zJgxo0855ZTfeG716tUZMWLEn9S3aO3Y2Z2FqzelvXNb2vq0pL1zW7q7m2ze3pWmSZat25K2Pi1Zs2lbunY2WdSxKW19WlKS3L9iQ5Kem1Jv2LIjizs2Z1C/Ptne1Z157RuzeuO2DOrXJ107m8xv35TOrV1paylZs2l7Vm3Ylu1d3dnZ3Z0HV23M4H49Xxi3dO3mbN6+M60tJavaV+e4b9yd62eszIFD+uWexWvz8YumZeridRnUrzUv+b/jM2vFhjRJlnRszteun5M75q3OM4YPzJhb5+fHdy5Kv7aWTJi3OgtWb8ovZ6/KwL598oUrZ2bWyg1ZtnZLNm3fmQ+df09mr+zMLQ+05zvj5+Xn963Ijp3d6dzalTd/b2JGDO6bjk3b8+Wfz8q3x8/NwtWbMqhfa97/0ym5fe7q/OVThuS2B9vziYum5455q7Oqc1ve9cO78sDKzowcMSgX3rU4X7ludp4+fGBKSV51xm3Z2d2kvXNr7lqwNh+7aGqG9G9Ne+e2vPl7E3Ph3UuydtOO9G/rk385b3Kunr48wwf3zeVTl+W0q2dm5vINaZrkTWdPyLCBbZm8sCNfu2FOfjxhYfq3tWTuqo15xTdvzfJ1W9K3tU+un7Ey/3nVzAzu15rtXd059ZLp+fZNc9Pap+Ss8XPTp6XkimnL0qel5Os3zMn1M1Zm6IC2TJi/Jh+/qOdb4aYtWZcrpi3LTycuzqyVG7KkY3OmLOzItq7u3DynPVdMXZ67F3Zk4ZrNWdW5Na8647b81aH7Z/zsVbnwrsW5bsbK/J8Rg9KxaXue/6VxaZpk/0FtmbJobd51zqRMW7o+o0YMyheunJFrpq/I9p3dGXf/Q/ng2Huyras7O5smJ/9kctZv2ZGhA1pz24PteeW3bkvHpu152rD++cmdC/OjOxZmfvum7D+wb/7n2tm5YcbK7D+ob74x7oF0bu3KVdOXZ0j/1rz06+Nz8LABKSX5ynWz828XT8/zn7F/lq/bmr/9v+Nz+FOHZNm6Lbl48pK8/QeTctCQ/hl14KB87KKp+fqND6RrZ3e2dXXnwxdMze1zV2do/9a850d3Z/3mHTloSL/cMW913nvu3XnxM0dkx87uvOOcu/Lpn92X1paSwf3acsp5k3Pp5KUZNrAt4+esyrfHz82URWuzefvOXDZlaf5s2ICce+fCXDV9WW6YsTJXTV+epwztn7d+f2KSZPqSdZm6ZF2+dv2c7D+wLV+7fk4+c/l9aevTklWd2zJx/pp84uLpGdyv52/qjWdPyMWTl2Td5h3p19Ynp/T+TR0wuG8uu2dpTrvq/sxeuSE7u5u86XsTst+Anr+pr1w/O+dNXJx+rS154KHOnPTN27Jy/da0tbbk2vtWZHTv39S2Hd3590un58yb5qZfa0uuuXd5PnrhtCzq2JxhA9vyhStn5pIpS3L3wo78/N4V2bB1R26e056Bffvk5J9MzvUzVua8CQtz14Ke/363lJLr7luZL197f+Y81JlZKzqzcduOnPD1W7Jw9aYM6Nuab980Nx+9cFoG9euTp+03IB8YOyVfuW52kuTGmSvz8YumZe3mHRk2oC0v/8atmde+MRu2duW2B9vzhrMnZOPWrqzZtC0fv2hafjnroazdvD2tLS055bwpWdyxOU8Z0i//dc39GTawb7417sEs7tics8bPzeqN27Nu8/b8/N4VuWr68qzeuD1XTV+ej104LcMGtmXLjp351rgH8tXr52Ro/7bs2Nnkhf/9yyzu2Jwh/Vpzz+K1+dzlM/KTiQuTlLzjnEm5ZPKSdGzanimLOvJf18zKtq6dmbZkXT5x8fTc/mB75jzUmQce6sw7z7krrX1K9hvQlu/dOv/Xx2zv3JaPXDA1o6+amf0GtuXMm+Zm4oI1GTdrVUqSt31/UlpbSi64a0nmrtqY7948LwcPG5AZy9bn1Wfelu07mxx6wMCcc9uCfPGa+3PgkH5Zt3l7Xnb6LfnRHQsypH9bNm7tyinnTcnUxevSubUr501clB/dsSAHDemXcbNW5S3fm5hDDxiY/Qa05cPnT820xWuzras789s35sTTb8ltD67OX//5Ablk8pK8+4d3ZeGaTRnavy2nXjI93791QQb375MHV23MJy6elvVbdmTTtq689tu3Z87KzvRpackVU5fl6zfMydOHD0ySvOh/fpkJ89akc2tXupsmX7z6/oyf3Z6nDu2fi+5eknNuX5Cund154KHO3LWgI1MWrc3O7ibfGvdgJs1fk0VrNqWllPzr+VMzc/mGXHvfilwxdXnOvOnB9GttSdMkr/32HRk6oC0dm7bnJxMW5dRLpmfNxm1pbWnJ/1w3Kz+4fUF27Gxy65z2/NfP7093k6zZuD3v/uFdWb9lRzo2bc+0JevyljET07dPS4YNbMu3fvlg/uua+zOwb5/Ma9+Uz11xX26esyqHPWVIvn7jnKzfvCNX37s8hwwbkH/87p0Z0r819y1dnzNuejDfHPdA9hvQ8zf1stNvycatXSkl+emkRfnAT+9J57aujBoxKJ+67N586eezcvhTh2blhq358AX3ZM7KzowaMSgvO/3WzFy+PvsP7Jspi9bmPT+8O0MHtOWQ/QfmG+MeyMk/mZyFazanpZR84uLpuWjykhx20JD851Uzc919K7J+y46s2bQ9H7lgagb165OmSb457oH8848n59iRwzNsYFv+5bwp+fqNczJ0QFuunL4s81ZtzL3Leu5H+MnL7s1BQ/rlJ3cuTJPktWfenlEjBqVvnz454X9vzrz2jenX2id3L1ybf/zunTn+sBFZsHpT3v/TKfn5vSty0NB+mb2yM6/45q05/pkHZH77pnzp5/fnXy+YmiOeNjTDB/XNu390V869c2H6t/bJnIc25DOX35fpS9alX2tLXvHNW/P04QMzpH9bfnT7wvzvjXNy9KH7Z/P2rvz1V27K926dn+GD2rJxW1f++dzJGTfroTzjgIH5zvh5OX/S4jy4qjPzVm3MzOUbsn7LjkycvyYX3L04M5ZtyIOrNmbF+q15zZm35+hnDMttD67OrQ+25xu/eCC3PdieWx9YnbsXdKS9c1tWrt+asRMX5dM/uy8T5q3JjfevzOeumJE1m7Zn/Oz2jJ20KN+/bX66dnanY/P2vPbbt+eWOe3ZvH1nHljZmb8/8/Z07WzytGED8q1xD+ZzV8zIPYvXpmmS1591R+a3b8qBQ/rl0z+7Lz+ZsDAr129Lkhz/1fFZ3LE5D23Ymh9PWJivXjc7qzduy9P3H5iPXDA1v5z1UA5/6pBcfe/yfOCnUzJ0QFv2G9CWT//svvzg9vmZsnBtZq/szAfH3pP2zm05YHDfvOMHk9K5rSsPbdia+5auz6vOuC3burpz4OB++dEdC3L2LfMyedHadDfJ6b94IBdMWpw1G7fn/EmLs9+AtlwxdVnmtW/K+8+bkjUbt2Ve+8ZcePfi/OeVM7P/wLbMXrkh7/jBpAzq15qpi9flxpkr86Hz78mGLTuyeuO2/MN37szUxWszuH9rbn1gdT409p485+CheWjDtrzznEk5aEi//HL2qixaszmvOuO2HDSkf4YNbMvHL5qWS6cszZ8fODg7dnbnnedMyn9fOyvPGD4oF961JKddPTOLOzZnaP/WvORr4/MXTxmcuxaszXUzVuSiu5ekrU9LurqbHPPlcVm8ZnOec8h+mbJobd7+/YmZtKAjBw/rn49dNC3DB/XNjOUbMmnBmlwyZUk6t3Zl0ZrN+ezl92XWis60tCT3L9+Q1591R+as7MyURWtz+i8eyNX3Ls+iNZtz/4oN+fDYe7Jha1d2djf56g2z87MpSzNv1cYM6Nual59+S3bsbNJSSqYsXpt3nDMpy9dtyeyVnfmnH92daUvWpU9LyQ0zV+Yr183Ozu5kVefWvGXMxMxauSEr12/NrBUb8vbvT8zg/m3Zr39bTv/FA/nq9bOzcPWmbNrWldseXJ1r7l2R1paSz15+Xxas3pTbH1yd7qbJSd+8LQtWb8p+A9py+o0P5Mrpy/K0YQPSsWl7XvDlX6a9c1u6uptcPnVpPv2z+zKwb5+MGNwv/37p9Jx6yfSUUjJ9ybrc/uDq3LN4bRat2ZwPn39PtnXtzPjZ7Vm3ZUc+9bP7MnxQ31w8eUlGXzUzKzdsTXvn1qxYvyVvGTMx27u60zRNvnDlzHz0wmnZsKUrz3zK4LzznLty4d1L8tCGrVm8ZnNOvfTeXDplaUpJLpm8JBfevTjDBrblmntXpHPrjlw9fUUG92vNqZfemwWrN2XNpm1ZunZz/u3i6Zm6eF1mLF+fT152b+as7MzWrp2ZtWJDPjT2nhw4pF/Wb9mR9/14cm64/6HMWrEh/Vr75J0/nJQ5D3XmWQcPzdhJizP66pmZvHBtlq/fkrd9f1KWrducvzio53/7fzpxUQ4eNiBbd+zMsV8el5Xrt2bh6k2Z274x7/vx5DzzoMHp29qS/752VtZu2p6J8zsyaX5Hzvjlg7/+/2//e+OczFi2PrNWdOaKqcvyLz+dkmED2pIkH7lgaqYvXZd1m3dk8sKOvGXMxOzY2Z3B/Vpz9fTlOfXS6Zm7amOapslnLr8vYyctzoC2Pjl/0uL86M6F6di0PZu2deUfv3tnSko2bevKldOW50Pn35PB/doyfHDffPbyGfnOzXMzuH9bJi/qyGlX359JC9bkrw4dli9fOyujr56Zzi1dGdDWJx+5YGqum7Eyg/q25nNXzMiE+WsyasSgzGvflNeddXteOOqANGny6Z/dlw+OvSdbtu/M0/YbkA+ff09+PGFh2vq0ZP7qjRl91czctaAjLSX53i3z85w/G5ozb5qbTdt25rSrZ2Zg39Ys6dict39/Yvq2tuS+Zetz98K1+ezlM/LCUcOzfWd3XvftO3LrA+0ZPqhvdnY3eev3J+aae5dnvwF989OJizKwb2u+9csHsrhjS8785YNZs2l7lq/bkkkLOnLuHQuzY2d3Lrtnae+/SVuzcVvPv5FOvWR6DhrSLzu7m/zNV8dnxrL1Gdy/NQvXbMq/XzI9P7h9ftr6tOS9596d8yYuyor1WzO/vWdbSym5fe7qfPnns3LltOV58KHOrFi3NW/83oR0dzcZ3L81l0xemg+OnZI+LS2Zt2pjTr3k3tyzaG26myaHPWXIY1wPHj+nnXbaitGjR495pHV7dA+hUsrIJNc0TfOc3Wy7JslXmqa5vffxL5N8smmaybtZe0p6ziLKoYce+vxFixb9xvYFCxZkyJAhOeCAA/5kotC9S9ft6xF+S9M06dq8IffMW5Ev37pmX48DAAAAT2jnn/zC/PWfj9jXY+wVe3oPoda9cazdPLfbytQ0zZgkY5Kem0rvuv2QQw7J0qVL097evhfGenw8tHbLvh7htzRpsmjdjpw5ae2+HgUAAACe8Bas3vSkCUJ7am8EoaVJnv6wx4ckWf7H7KitrS2jRo3aCyM9fl75qZ/v6xEAAAAA/iB7clPpR3JVknf1ftvYcUnWN02zYi/sFwAAAIDHwCOeIVRKuSDJS5OMKKUsTfKfSdqSpGmas5Ncm+RVSeYm2Zzknx6rYQEAAAB49B4xCDVN89ZH2N4k+dBemwgAAACAx9TeuGQMAAAAgD8hghAAAABAZQQhAAAAgMoIQgAAAACVEYQAAAAAKiMIAQAAAFRGEAIAAACojCAEAAAAUBlBCAAAAKAyghAAAABAZQQhAAAAgMoIQgAAAACVEYQAAAAAKiMIAQAAAFRGEAIAAACojCAEAAAAUBlBCAAAAKAyghAAAABAZQQhAAAAgMoIQgAAAACVEYQAAAAAKiMIAQAAAFRGEAIAAACojCAEAAAAUBlBCAAAAKAyghAAAABAZQQhAAAAoGpNs68nePwJQgAAAACVEYQAAAAAKiMIAQD/7pv0AAAgAElEQVQAAFRGEAIAAACojCAEAAAAUBlBCAAAAKAyghAAAABAZQQhAAAAgMoIQgAAAACVEYQAAAAAKiMIAQAAAFRGEAIAAACojCAEAAAAUBlBCAAAAKAyghAAAABAZQQhAAAAgMoIQgAAAACVEYQAAAAAKiMIAQAAAFRGEAIAAACojCAEAAAAUBlBCAAAAKAyghAAAABAZQQhAAAAgMoIQgAAAACVEYQAAAAAKiMIAQAAAFRGEAIAAACojCAEAAAAUBlBCAAAAKAyghAAAABAZQQhAAAAoGrNvh5gHxCEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAgLo1zb6e4HEnCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAgKo1+3qAfUAQAgAAAKiMIAQAAABQGUEIAAAAoDKCEAAAAEBlBCEAAACAyghCAAAAAJURhAAAAAAqIwgBAAAAVEYQAgAAAKiMIAQAAABQGUEIAAAAoDKCEAAAAEBlBCEAAACAyghCAAAAAJURhAAAAAAqIwgBAAAAVGaPglAp5aRSypxSytxSyqd2s/3QUsr4UsrUUsq9pZRX7f1RAQAAANgbHjEIlVL6JDkrySuTPCvJW0spz9pl2eeSXNw0zV8leUuS7+ztQQEAAADYO/bkDKEXJJnbNM38pmm2J7kwyet2WdMkGdr7+35Jlu+9EQEAAADYm/YkCP1ZkiUPe7y097mHG53kHaWUpUmuTfKvu9tRKeWUUsrkUsrk9vb2P2JcAAAAAB6tPQlCZTfPNbs8fmuSc5umOSTJq5KcV0r5rX03TTOmaZpjmqY55sADD/zDpwUAAADgUduTILQ0ydMf9viQ/PYlYf+c5OIkaZpmQpL+SUbsjQEBAAAA2Lv2JAjdneSwUsqoUkrf9Nw0+qpd1ixOcmKSlFKOSE8Qck0YAAAAwBPQIwahpmm6knw4yQ1JZqXn28RmllK+WEp5be+yf0tycillepILkrynaZpdLysDAAAA4AmgdU8WNU1zbXpuFv3w577wsN/vT/LivTsaAAAAAI+FPblkDAAAAIAnEUEIAAAAoDKCEAAAAEBlBCEAAACAyghCAAAAAJURhAAAAAAqIwgBAAAAVWuafT3B408QAgAAAKiMIAQAAABQGUEIAAAAoDKCEAAAAEBlBCEAAACAyghCAAAAAJURhAAAAAAqIwgBAAAAVEYQAgAAAKiMIAQAAABQGUEIAAAAoDKCEAAAAEBlBCEAAACAyghCAAAAAJURhAAAAAAqIwgBAAAAVEYQAgAAAKiMIAQAAABQGUEIAAAAoDKCEAAAAEBlBCEAAACAyghCAAAAAJURhAAAAAAqIwgBAAAAVEYQAgAAAKpWyr6e4PEnCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAABA1ZpmX0/w+BOEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAgKo1TbOvR3jcCUIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAKBqzb4eYB8QhAAAAAAqIwgBAAAAVEYQAgAAAKiMIAQAAABQGUEIAAAAoDKCEAAAAEBlBCEAAACAyghCAAAAAJURhAAAAAAqIwgBAAAAVEYQAgAAAKiMIAQAAABQGUEIAAAAoDKCEAAAAEBlBCEAAACAyghCAAAAAJURhAAAAAAqIwgBAAAAVEYQAgAAAKiMIAQAAABQGUEIAAAAoDKCEAAAAEBlBCEAAACAyghCAAAAAJURhAAAAAAqIwgBAAAAVEYQAgAAAKiMIAQAAABQGUEIAAAAoDKCEAAAAEBlBCEAAACAyghCAAAAQNWaZl9P8PgThAAAAAAqIwgBAAAAVEYQAgAAAKjMHgWhUspJpZQ5pZS5pZRP/Y41byql3F9KmVlKOX/vjgkAAADA3tL6SAtKKX2SnJXk5UmWJrm7lHJV0zT3P2zNYUk+neTFTdOsLaUc9FgNDAAAAMCjsydnCL0gydymaeY3TbM9yYVJXrfLmpOTnNU0zdokaZpm1d4dEwAAAIC9ZU+C0J8lWfKwx0t7n3u4v0jyF6WUO0opE0spJ+1uR6WUU0opk0spk9vb2/+4iQEAAAB4VPYkCJXdPNfs8rg1yWFJXprkrUl+UEoZ9lsvapoxTdMc0zTNMQceeOAfOisAAAAAe8GeBKGlSZ7+sMeHJFm+mzVXNk2zo2maBUnmpCcQAQAAAPAEsydB6O4kh5VSRpVS+iZ5S5KrdllzRZITkqSUMiI9l5DN35uDAgAAALB3PGIQapqmK8mHk9yQZFaSi5ummVlK+WIp5bW9y25IsqaUcn+S8Un+vWmaNY/V0AAAAAD88R7xa+eTpGmaa5Ncu8tzX3jY702ST/T+AAAAAPAEtieXjAEAAADwJCIIAQAAAFRGEAIAAACojCAEAAAAUBlBCAAAAKAyghAAAABAZQQhAAAAgMoIQgAAAACVEYQAAAAAKiMIAQAAAFRGEAIAAACojCAEAAAAUBlBCAAAAKAyghAAAABAZQQhAAAAgMoIQgAAAACVEYQAAAAAKiMIAQAAAFRGEAIAAACojCAEAAAAVK3Z1wPsA4IQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACoWtM0+3qEx50gBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACoWillX4/wuBOEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAKBqTdPs6xEed4IQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQAAAAQGUEIQAAAIDKCEIAAAAAlRGEAAAAACojCAEAAABURhACAAAAqIwgBAAAAFAZQQgAAACgMoIQ/P/t3WuM5fd91/HPd2dvXq/v3iSt7cRO6wImCqSsXBcQVG1onVLZPDDCUatG1MhPiBqgEjiKlEJ41AYIVA0Bqym0VVW3NQVWkVsTpUEIiRi7tHKTuE42blJvncTr+hInji9r/3hw/uucTGZ2Z8Zn54z3+3pJR3v+lznnNzO/+Z3Z955zFgAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACa2VAQqqrrq+rBqjpaVbed4rybqmpU1eHFDREAAACARTptEKqqlSQfTPK2JNckeXtVXbPGeecl+ckk9yx6kAAAAAAszkaeIXRtkqNjjIfGGM8nuSPJjWuc9y+T/GySZxc4PgAAAAAWbCNB6LIkD89tH5v2vayq3pLkijHGR051Q1V1a1XdV1X3HT9+fNODBQAAAOCV20gQqjX2jZcPVu1K8oEkP3W6Gxpj3D7GODzGOHzo0KGNjxIAAACAhdlIEDqW5Iq57cuTPDK3fV6SNyX5n1X1+STXJTnijaUBAAAAdqaNBKF7k1xdVVdV1d4kNyc5cvLgGOOpMcalY4wrxxhXJvlEkhvGGPedkREDAAAA8IqcNgiNMU4keWeSu5M8kOQ3xhifqqr3VdUNZ3qAAAAAACzW7o2cNMa4K8ldq/a9d51zv++VDwsAAACAM2UjLxkDAAAAOGuNcfpzzjaCEAAAAEAzghAAAABAM4IQAAAAQDOCEAAAAEAzghAAAABAM4IQAAAAQDOCEAAAAEAzghAAAABAM4IQAAAAQDOCEAAAAEAzghAAAABAM4IQAAAAQDOCEAAAAEAzghAAAABAM4IQAAAAQDOCEAAAAEAzghAAAABAM4IQAAAAQDOCEAAAAEAzghAAAABAM4IQAAAAQDOCEAAAAEAzghAAAABAM4IQAAAAQDOCEAAAAEAzghAAAABAM4IQAAAAQDOCEAAAAEAzghAAAABAM4IQAAAAQDOCEAAAAEAzghAAAADQ2shY9hC2nSAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAAC0NsayR7D9BCEAAACAZgQhAAAAgGYEIQAAAIBmBCEAAACAZgQhAAAAgGYEIQAAAIBmBCEAAACAZgQhAAAAgGYEIQAAAIBmBCEAAACAZgQhAAAAgGYEIQAAAIBmBCEAAACAZgQhAAAAgGYEIQAAAIBmBCEAAACAZgQhAAAAgGYEIQAAAIBmBCEAAACAZgQhAAAAgGYEIQAAAIBmBCEAAACAZgQhAAAAgGYEIQAAAIBmBCEAAACAZgQhAAAAgGYEIQAAAIBmBCEAAACAZgQhAAAAgGYEIQAAAIBmBCEAAACAZgQhAAAAoLWx7AEsgSAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAAC0VssewBIIQgAAAADNCEIAAAAAzQhCAAAAAM0IQgAAAADNCEIAAAAAzQhCAAAAAM0IQgAAAADNCEIAAAAAzQhCAAAAAM0IQgAAAADNCEIAAAAAzQhCAAAAAM0IQgAAAADNCEIAAAAAzQhCAAAAAM0IQgAAAADNCEIAAAAAzQhCAAAAAM0IQgAAAADNCEIAAAAAzQhCAAAAAM0IQgAAAADNCEIAAABAa2PZA1gCQQgAAACgGUEIAAAAoBlBCAAAAKAZQQgAAACgGUEIAAAAoBlBCAAAAKAZQQgAAACgGUEIAAAAoBlBCAAAAKCZDQWhqrq+qh6sqqNVddsax/9JVX26qu6vqo9V1RsWP1QAAAAAFuG0QaiqVpJ8MMnbklyT5O1Vdc2q034/yeExxpuT3JnkZxc9UAAAAAAWYyPPELo2ydExxkNjjOeT3JHkxvkTxhgfH2M8M21+Isnlix0mAAAAAIuykSB0WZKH57aPTfvWc0uS317rQFXdWlX3VdV9x48f3/goAQAAAFiYjQShWmPfWPPEqh9LcjjJ+9c6Psa4fYxxeIxx+NChQxsfJQAAAAALs3sD5xxLcsXc9uVJHll9UlW9Ncl7kvzNMcZzixkeAAAAAIu2kWcI3Zvk6qq6qqr2Jrk5yZH5E6rqLUn+Y5IbxhiPLn6YAAAAACzKaYPQGONEkncmuTvJA0l+Y4zxqap6X1XdMJ32/iQHk/xmVf1BVR1Z5+YAAAAAWLKNvGQsY4y7kty1at97566/dcHjAgAAAOAM2chLxgAAAAA4iwhCAAAAAM0IQgAAAADNCEIAAAAAzQhCAAAAAM0IQgAAAADNCEIAAAAAzQhCAAAAAM0IQgAAAADNCEIAAAAAzQhCAAAAAM0IQgAAAADNCEIAAAAAzQhCAAAAQGtjLHsE208QAgAAAGhGEAIAAABoRhACAAAAaEYQAgAAAGhGEAIAAABoRhACAAAAaEYQAgAAAGhGEAIAAABoRhACAAAAaEYQAgAAAGhGEAIAAABoRhACAAAAaEYQAgAAAGhGEAIAAABoRhACAAAAaEYQAgAAAGhGEAIAAABoRhACAAAAaEYQAgAAAGhGEAIAAABoRhACAAAAaEYQAgAAAGhGEAIAAABoRhACAAAAaEYQAgAAAGhGEAIAAABoRhACAAAAaEYQAgAAAGhGEAIAAABoRhACAAAAaEYQAgAAAGhGEAIAAABoRhACAAAAWhsZyx7CthOEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAIDWxlj2CLafIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQzIaCUFVdX1UPVtXRqrptjeP7qurXp+P3VNWVix4oAAAAAIux+3QnVNVKkg8m+VtJjiW5t6qOjDE+PXfaLUmeGGN8Z1XdnORnkvy9MzHgnWZXXlr2EAAAAIBX4KUXT2S89FJqV58XUp02CCW5NsnRMcZDSVJVdyS5Mcl8ELoxyT+frt+Z5OerqsYYY4Fj3ZHu3/cPcrCeXfYwAAAAgK3638lj19yfS7/9DcseybbZSBC6LMnDc9vHknzPeueMMU5U1VNJLkny2PxJVXVrkluT5PWvf/0Wh7yz/M7FP5YvPPrkpj/uwgN78uQzL3zL/n17duW5F77xrKOVXZU9u3fl2edfPOXt7VnZldeevy/Hnvh6kuSic/fmK19/IS++tPkmt2dlV154ce1nPq3sqi3d5qmcf86efOXr3/q1SJKD+3fnq8+eeHn70Hn7cvzp5xZ6/5txJj7/jTp03r48/eyJPPvCbC4c2LuSZ04zL9Zyzt6VfH3u43avVE68ONY9vp5Tfd9W+67XnpfPfPnp05536cG9eeyrz0/X9+XcfSv5wp89s+5YX+m4doKtzqlFzcVF/UzNj2f++7jTrF5TFmGrX8OqZP6fTS6/6JyX1/BF3ceZup3tXgvP2787T6/zfXvt+fvy5a9843O6+Ny9efxrm59/Fx/cm8fXmbcXnbs3T6xzm9/1uvPymS+dfn1bbfXn9B2vOZjPPfrVTd/Oet/T1b9PzNu9q3Ji1ffvDZcc+Kb1dj3fduH+fPHJZ1++712Vb/r6v1os6rFi/ut/xcUH8vDj3/gavu6C/fnSU2v/o+Hqn/95G3msW5bXnL8vj07f7wN7V3Le/t1b+v6fu293vvbcbP5fduE5+dMn1177Xk0uOLAnT63xu/1m7F6p7KrK8yfW/tndjt+Dt/oYfqo5vVXz681qq78WB/btzjPPrf048cZDB/PQ8bXX1/17V07796y17KrKSwv4hC85uDd/ts7X+8pLz83nH/vaaW9j/jHqwgN7csE5e75pPd+/Z+Xlvz+s51Rf69Ved8H+7KrKI3M/t1t97D2VMzGn9q7syvPr/D03Sb73Oy7Jmw+ev9g73eE2EoRqjX2rvzUbOSdjjNuT3J4khw8f3pmPdJt007v+9bKHAAAAALApG3lx3LEkV8xtX57kkfXOqardSS5I8vgiBggAAADAYm0kCN2b5Oqquqqq9ia5OcmRVeccSfKO6fpNSX63w/sHAQAAALwanfYlY9N7Ar0zyd1JVpL84hjjU1X1viT3jTGOJPlwkl+pqqOZPTPo5jM5aAAAAAC2biPvIZQxxl1J7lq1771z159N8ncXOzQAAAAAzoSNvGQMAAAAgLOIIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANCMIAQAAADQjCAEAAAA0IwgBAAAANBMjTGWc8dVx5N8YSl3vniXJnls2YOAVcxLdhpzkp3IvGQnMi/ZicxLdhpzcn1vGGMcOt1JSwtCZ5Oqum+McXjZ44B55iU7jTnJTmReshOZl+xE5iU7jTn5ynnJGAAAAEAzghAAAABAM4LQYty+7AHAGsxLdhpzkp3IvGQnMi/ZicxLdhpz8hXyHkIAAAAAzXiGEAAAAEAzghAAAABAM4LQK1BV11fVg1V1tKpuW/Z4OPtU1RVV9fGqeqCqPlVV75r2X1xVH62qz05/XjTtr6r6uWlO3l9V3z13W++Yzv9sVb1jbv9fqao/nD7m56qqtv8z5dWmqlaq6ver6iPT9lVVdc80v369qvZO+/dN20en41fO3ca7p/0PVtUPze23trJpVXVhVd1ZVX80rZnfa61k2arqH0+P35+sql+rqv3WS7ZbVf1iVT1aVZ+c23fG18f17gOSdefl+6fH8fur6r9W1YVzxza1Dm5lre1IENqiqlpJ8sEkb0tyTZK3V9U1yx0VZ6ETSX5qjPEXklyX5B9O8+y2JB8bY1yd5GPTdjKbj1dPl1uTfCiZPSAn+ekk35Pk2iQ/Pfeg/KHp3JMfd/02fF68+r0ryQNz2z+T5APTnHwiyS3T/luSPDHG+M4kH5jOyzSPb07yFzObc/++ZpHJ2spW/bskvzPG+PNJ/lJm89NaydJU1WVJfjLJ4THGm5KsZLbuWS/Zbv8537pmbcf6uDdOOgcAAARlSURBVN59QLL2vPxokjeNMd6c5DNJ3p1seR3c1FrblSC0ddcmOTrGeGiM8XySO5LcuOQxcZYZY3xxjPH/putPZ/YXnMsym2u/NJ32S0n+znT9xiS/PGY+keTCqvq2JD+U5KNjjMfHGE9ktthePx07f4zxf8bsHeZ/ee62YE1VdXmSv53kF6btSvL9Se6cTlk9J0/O1TuT/MB0/o1J7hhjPDfG+OMkRzNbV62tbFpVnZ/kbyT5cJKMMZ4fYzwZayXLtzvJOVW1O8mBJF+M9ZJtNsb4X0keX7V7O9bH9e4D1pyXY4z/McY4MW1+Isnl0/VNrYNb/N20JUFo6y5L8vDc9rFpH5wR09MZ35LkniSvHWN8MZlFoySvmU5bb16eav+xNfbDqfzbJP80yUvT9iVJnpx7AJ+fRy/Pven4U9P5m52rcCpvTHI8yX+q2UsZf6Gqzo21kiUaY/xpkn+V5E8yC0FPJfm9WC/ZGbZjfVzvPmAjfiLJb0/XNzsvt/K7aUuC0NatVRHHto+CFqrqYJL/kuQfjTG+cqpT19g3trAf1lRVP5Lk0THG783vXuPUcZpj5iSLtDvJdyf50BjjLUm+llO/NMG85IybXk5zY5Krknx7knMze1nDatZLdhLzkKWrqvdk9tYZv3py1xqnbXVemrNzBKGtO5bkirnty5M8sqSxcBarqj2ZxaBfHWP81rT7y9NTdDP9+ei0f715ear9l6+xH9bz15LcUFWfz+xpud+f2TOGLpxeEpF88zx6ee5Nxy/I7OnBm52rcCrHkhwbY9wzbd+ZWSCyVrJMb03yx2OM42OMF5L8VpK/GuslO8N2rI/r3Qesa3rD8h9J8qPTyxCTzc/Lx7L5tbYlQWjr7k1y9fTu5Xsze5OrI0seE2eZ6fWsH07ywBjj38wdOpLk5P/u8I4k/31u/49P/0PEdUmemp6ie3eSH6yqi6Z/sfzBJHdPx56uquum+/rxuduCbzHGePcY4/IxxpWZrXu/O8b40SQfT3LTdNrqOXlyrt40nT+m/TdP/9PDVZm9CeX/jbWVLRhjfCnJw1X156ZdP5Dk07FWslx/kuS6qjowzZuT89J6yU6wHevjevcBa6qq65P8syQ3jDGemTu0qXVwWjs3u9b2NMZw2eIlyQ9n9u7nn0vynmWPx+XsuyT565k9hfH+JH8wXX44s9e5fizJZ6c/L57Or8zeaf9zSf4ws//Z5ORt/URmb8B2NMnfn9t/OMknp4/5+SS17M/b5dVxSfJ9ST4yXX9jZg/MR5P8ZpJ90/790/bR6fgb5z7+PdO8ezDJ2+b2W1tdNn1J8peT3Detl/8tyUXWSpdlX5L8iyR/NM2dX0myz3rpst2XJL+W2ftYvZDZsyNu2Y71cb37cHEZY915eTSz9/c5+fee/zB3/qbWwa2stR0vJ39YAQAAAGjCS8YAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmhGEAAAAAJoRhAAAAACaEYQAAAAAmvn/kSlM+wWisu0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_df, y_df, test_size=test_split)\n",
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_validate, y_validate, test_size=.5)\n",
    "X_validate = X_validate.values\n",
    "y_validate = y_validate.values\n",
    "X_test = X_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "print('\\nReshaping Training Frames')\n",
    "print(\"X_train shape [\" + str(X_train.shape) + \"] Type - \" + str(type(X_train)))\n",
    "print(\"X_validate shape [\" + str(X_validate.shape) + \"] Type - \" + str(type(X_validate)))\n",
    "print(\"X_test shape [\" + str(X_test.shape) + \"] Type - \" + str(type(X_test)))\n",
    "print(\"y_train shape [\" + str(y_train.shape) + \"] Type - \" + str(type(y_train)))\n",
    "print(\"y_validate shape [\" + str(y_validate.shape) + \"] Type - \" + str(type(y_validate)))\n",
    "print(\"y_test shape [\" + str(y_test.shape) + \"] Type - \" + str(type(y_test)))\n",
    "   \n",
    "model = NeuralNet(X=X_train,\n",
    "                  y=y_train,\n",
    "                  lag=lag,\n",
    "                  loss_func='binary_crossentropy',\n",
    "                  activation=activation,\n",
    "                  optimizer='adam',\n",
    "                  layers=layers,\n",
    "                  dropout=dropout,\n",
    "                  initializer=initializer)\n",
    "\n",
    "model.fit_model(X_train=X_train,\n",
    "                X_test=X_validate,\n",
    "                y_train=y_train,\n",
    "                y_test=y_validate,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                verbose=2,\n",
    "                shuffle=False,\n",
    "                plot=True)\n",
    "\n",
    "yhat = []\n",
    "for i in range(0, X_validate.shape[0]):\n",
    "    X = np.array([X_validate[i,:]])\n",
    "    y = model.predict(X, batch_size=batch_size)\n",
    "    model.fit_model(X_train=X,\n",
    "                    y_train=y,\n",
    "                    epochs=2, \n",
    "                    batch_size=1,\n",
    "                    verbose=1, \n",
    "                    shuffle=False,\n",
    "                    plot=False) # Online Learning, Training on validation predictions. \n",
    "    yhat.extend(y)    \n",
    "model.evaluate(y=y_validate,\n",
    "               yhat=np.array(yhat),\n",
    "               plot=True)\n",
    "\n",
    "yhat = []\n",
    "for i in range(0, X_test.shape[0]):\n",
    "    X = np.array([X_test[i,:]])\n",
    "    y = model.predict(X, batch_size=batch_size)\n",
    "    model.fit_model(X_train=X,\n",
    "                    y_train=y,\n",
    "                    epochs=2, \n",
    "                    batch_size=1,\n",
    "                    verbose=1, \n",
    "                    shuffle=False,\n",
    "                    plot=False) # Online Learning, Training on validation predictions. \n",
    "    yhat.extend(y)    \n",
    "model.evaluate(y=y_test,\n",
    "               yhat=np.array(yhat),\n",
    "               plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
