{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Sequence Analysis (RFC)\n",
    "\n",
    "This notebook focuses on sequence analysis, when presented with a workload schedule / sequence of queries. In an average day to day work activity, particular query patterns can be discerned. This pattern distinction allows us to discern which queries will be susceptible to execution over time, allowing us to know ahead of time which queries will be executed against the database.\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "### Module Installation and Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy: 1.1.0\n",
      "numpy: 1.15.4\n",
      "pandas: 0.23.4\n",
      "sklearn: 0.20.2\n"
     ]
    }
   ],
   "source": [
    "# scipy\n",
    "import scipy as sc\n",
    "print('scipy: %s' % sc.__version__)\n",
    "# numpy\n",
    "import numpy as np\n",
    "print('numpy: %s' % np.__version__)\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "# pandas\n",
    "import pandas as pd\n",
    "print('pandas: %s' % pd.__version__)\n",
    "# scikit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "import sklearn as sk\n",
    "print('sklearn: %s' % sk.__version__)\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Cell\n",
    "\n",
    "Tweak parametric changes from this cell to influence outcome of experiment. \n",
    "NB: This experiment demonstrates at time  step = 1 (1 minute in advance). Further down in experiment, other timestep results are also featured and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Config\n",
    "tpcds='TPCDS1' # Schema upon which to operate test\n",
    "lag=12 # Time Series shift / Lag Step. Each lag value equates to 1 minute. Cannot be less than 1\n",
    "if lag < 1:\n",
    "    raise ValueError('Lag value must be greater than 1!')\n",
    "\n",
    "nrows = None\n",
    "test_split=.5 # Denotes which Data Split to operate under when it comes to training / validation\n",
    "\n",
    "# Top Consumer Identification\n",
    "y_label = ['COST','CARDINALITY','BYTES','IO_COST','TEMP_SPACE','TIME']\n",
    "black_list = ['TIMESTAMP','SQL_ID'] # Columns which will be ignored during type conversion, and later used for aggregation\n",
    "contamination = .1\n",
    "\n",
    "# Forest Config\n",
    "parallel_degree = -1\n",
    "n_estimators = 300\n",
    "max_depth = None\n",
    "max_features='log2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from file into Pandas Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3018: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3018: DtypeWarning: Columns (6,19,20,21,22,25,26,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SNAP_ID' 'DBID' 'INSTANCE_NUMBER' 'SQL_ID' 'PLAN_HASH_VALUE'\n",
      " 'OPTIMIZER_COST' 'OPTIMIZER_MODE' 'OPTIMIZER_ENV_HASH_VALUE'\n",
      " 'SHARABLE_MEM' 'LOADED_VERSIONS' 'VERSION_COUNT' 'MODULE' 'ACTION'\n",
      " 'SQL_PROFILE' 'FORCE_MATCHING_SIGNATURE' 'PARSING_SCHEMA_ID'\n",
      " 'PARSING_SCHEMA_NAME' 'PARSING_USER_ID' 'FETCHES_TOTAL' 'FETCHES_DELTA'\n",
      " 'END_OF_FETCH_COUNT_TOTAL' 'END_OF_FETCH_COUNT_DELTA' 'SORTS_TOTAL'\n",
      " 'SORTS_DELTA' 'EXECUTIONS_TOTAL' 'EXECUTIONS_DELTA'\n",
      " 'PX_SERVERS_EXECS_TOTAL' 'PX_SERVERS_EXECS_DELTA' 'LOADS_TOTAL'\n",
      " 'LOADS_DELTA' 'INVALIDATIONS_TOTAL' 'INVALIDATIONS_DELTA'\n",
      " 'PARSE_CALLS_TOTAL' 'PARSE_CALLS_DELTA' 'DISK_READS_TOTAL'\n",
      " 'DISK_READS_DELTA' 'BUFFER_GETS_TOTAL' 'BUFFER_GETS_DELTA'\n",
      " 'ROWS_PROCESSED_TOTAL' 'ROWS_PROCESSED_DELTA' 'CPU_TIME_TOTAL'\n",
      " 'CPU_TIME_DELTA' 'ELAPSED_TIME_TOTAL' 'ELAPSED_TIME_DELTA' 'IOWAIT_TOTAL'\n",
      " 'IOWAIT_DELTA' 'CLWAIT_TOTAL' 'CLWAIT_DELTA' 'APWAIT_TOTAL'\n",
      " 'APWAIT_DELTA' 'CCWAIT_TOTAL' 'CCWAIT_DELTA' 'DIRECT_WRITES_TOTAL'\n",
      " 'DIRECT_WRITES_DELTA' 'PLSEXEC_TIME_TOTAL' 'PLSEXEC_TIME_DELTA'\n",
      " 'JAVEXEC_TIME_TOTAL' 'JAVEXEC_TIME_DELTA' 'IO_OFFLOAD_ELIG_BYTES_TOTAL'\n",
      " 'IO_OFFLOAD_ELIG_BYTES_DELTA' 'IO_INTERCONNECT_BYTES_TOTAL'\n",
      " 'IO_INTERCONNECT_BYTES_DELTA' 'PHYSICAL_READ_REQUESTS_TOTAL'\n",
      " 'PHYSICAL_READ_REQUESTS_DELTA' 'PHYSICAL_READ_BYTES_TOTAL'\n",
      " 'PHYSICAL_READ_BYTES_DELTA' 'PHYSICAL_WRITE_REQUESTS_TOTAL'\n",
      " 'PHYSICAL_WRITE_REQUESTS_DELTA' 'PHYSICAL_WRITE_BYTES_TOTAL'\n",
      " 'PHYSICAL_WRITE_BYTES_DELTA' 'OPTIMIZED_PHYSICAL_READS_TOTAL'\n",
      " 'OPTIMIZED_PHYSICAL_READS_DELTA' 'CELL_UNCOMPRESSED_BYTES_TOTAL'\n",
      " 'CELL_UNCOMPRESSED_BYTES_DELTA' 'IO_OFFLOAD_RETURN_BYTES_TOTAL'\n",
      " 'IO_OFFLOAD_RETURN_BYTES_DELTA' 'BIND_DATA' 'FLAG' 'CON_DBID' 'CON_ID'\n",
      " 'SQL_TEXT' 'COMMAND_TYPE' 'STARTUP_TIME' 'BEGIN_INTERVAL_TIME'\n",
      " 'END_INTERVAL_TIME' 'FLUSH_ELAPSED' 'SNAP_LEVEL' 'ERROR_COUNT'\n",
      " 'SNAP_FLAG' 'SNAP_TIMEZONE']\n",
      "------------------------------------------\n",
      "Index(['DBID', 'SQL_ID', 'PLAN_HASH_VALUE', 'ID', 'OPERATION', 'OPTIONS',\n",
      "       'OBJECT_NODE', 'OBJECT#', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS',\n",
      "       'OBJECT_TYPE', 'OPTIMIZER', 'PARENT_ID', 'DEPTH', 'POSITION',\n",
      "       'SEARCH_COLUMNS', 'COST', 'CARDINALITY', 'BYTES', 'OTHER_TAG',\n",
      "       'PARTITION_START', 'PARTITION_STOP', 'PARTITION_ID', 'OTHER',\n",
      "       'DISTRIBUTION', 'CPU_COST', 'IO_COST', 'TEMP_SPACE',\n",
      "       'ACCESS_PREDICATES', 'FILTER_PREDICATES', 'PROJECTION', 'TIME',\n",
      "       'QBLOCK_NAME', 'REMARKS', 'TIMESTAMP', 'OTHER_XML', 'CON_DBID',\n",
      "       'CON_ID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Root path\n",
    "#root_dir = 'C:/Users/gabriel.sammut/University/Data_ICS5200/Schedule/' + tpcds\n",
    "root_dir = 'D:/Projects/Datagenerated_ICS5200/Schedule/' + tpcds\n",
    "\n",
    "# Open Data'\n",
    "rep_hist_snapshot_path = root_dir + '/rep_hist_snapshot.csv'\n",
    "rep_vsql_plan_path = root_dir + '/rep_vsql_plan.csv'\n",
    "\n",
    "rep_hist_snapshot_df = pd.read_csv(rep_hist_snapshot_path,nrows=nrows)\n",
    "rep_vsql_plan_df = pd.read_csv(rep_vsql_plan_path, nrows=2000000)\n",
    "\n",
    "def prettify_header(headers):\n",
    "    \"\"\"\n",
    "    Cleans header list from unwated character strings\n",
    "    \"\"\"\n",
    "    header_list = []\n",
    "    [header_list.append(header.replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"\").replace(\",\",\"\")) for header in headers]\n",
    "    return header_list\n",
    "\n",
    "rep_hist_snapshot_df.columns = prettify_header(rep_hist_snapshot_df.columns.values)\n",
    "rep_vsql_plan_df.columns = prettify_header(rep_vsql_plan_df.columns.values)\n",
    "\n",
    "print(rep_hist_snapshot_df.columns.values)\n",
    "print('------------------------------------------')\n",
    "print(rep_vsql_plan_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with empty values\n",
    "\n",
    "Subsituating N/A values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N/A Columns\n",
      "\n",
      "\n",
      " REP_HIST_SNAPSHOT Features 90: ['OPTIMIZER_COST', 'OPTIMIZER_MODE', 'OPTIMIZER_ENV_HASH_VALUE', 'LOADED_VERSIONS', 'MODULE', 'ACTION', 'SQL_PROFILE', 'PARSING_SCHEMA_ID', 'PARSING_SCHEMA_NAME', 'PARSING_USER_ID', 'FETCHES_TOTAL', 'FETCHES_DELTA', 'END_OF_FETCH_COUNT_TOTAL', 'END_OF_FETCH_COUNT_DELTA', 'SORTS_TOTAL', 'SORTS_DELTA', 'EXECUTIONS_TOTAL', 'EXECUTIONS_DELTA', 'PX_SERVERS_EXECS_TOTAL', 'PX_SERVERS_EXECS_DELTA', 'LOADS_TOTAL', 'LOADS_DELTA', 'INVALIDATIONS_TOTAL', 'INVALIDATIONS_DELTA', 'PARSE_CALLS_TOTAL', 'DISK_READS_TOTAL', 'DISK_READS_DELTA', 'BUFFER_GETS_TOTAL', 'BUFFER_GETS_DELTA', 'ROWS_PROCESSED_TOTAL', 'ROWS_PROCESSED_DELTA', 'CPU_TIME_TOTAL', 'ELAPSED_TIME_TOTAL', 'IOWAIT_TOTAL', 'IOWAIT_DELTA', 'CLWAIT_TOTAL', 'CLWAIT_DELTA', 'APWAIT_TOTAL', 'APWAIT_DELTA', 'CCWAIT_TOTAL', 'CCWAIT_DELTA', 'DIRECT_WRITES_TOTAL', 'DIRECT_WRITES_DELTA', 'PLSEXEC_TIME_TOTAL', 'PLSEXEC_TIME_DELTA', 'JAVEXEC_TIME_TOTAL', 'JAVEXEC_TIME_DELTA', 'IO_OFFLOAD_ELIG_BYTES_TOTAL', 'IO_OFFLOAD_ELIG_BYTES_DELTA', 'IO_INTERCONNECT_BYTES_TOTAL', 'IO_INTERCONNECT_BYTES_DELTA', 'PHYSICAL_READ_REQUESTS_TOTAL', 'PHYSICAL_READ_REQUESTS_DELTA', 'PHYSICAL_READ_BYTES_TOTAL', 'PHYSICAL_READ_BYTES_DELTA', 'PHYSICAL_WRITE_REQUESTS_TOTAL', 'PHYSICAL_WRITE_REQUESTS_DELTA', 'PHYSICAL_WRITE_BYTES_TOTAL', 'PHYSICAL_WRITE_BYTES_DELTA', 'OPTIMIZED_PHYSICAL_READS_TOTAL', 'OPTIMIZED_PHYSICAL_READS_DELTA', 'CELL_UNCOMPRESSED_BYTES_TOTAL', 'CELL_UNCOMPRESSED_BYTES_DELTA', 'IO_OFFLOAD_RETURN_BYTES_TOTAL', 'IO_OFFLOAD_RETURN_BYTES_DELTA', 'BIND_DATA', 'FLAG']\n",
      "\n",
      "REP_VSQL_PLAN Features 39: ['OPTIONS', 'OBJECT_NODE', 'OBJECT#', 'OBJECT_OWNER', 'OBJECT_NAME', 'OBJECT_ALIAS', 'OBJECT_TYPE', 'OPTIMIZER', 'PARENT_ID', 'COST', 'CARDINALITY', 'BYTES', 'OTHER_TAG', 'PARTITION_START', 'PARTITION_STOP', 'PARTITION_ID', 'OTHER', 'DISTRIBUTION', 'CPU_COST', 'IO_COST', 'TEMP_SPACE', 'ACCESS_PREDICATES', 'FILTER_PREDICATES', 'PROJECTION', 'TIME', 'QBLOCK_NAME', 'REMARKS', 'OTHER_XML']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_na_columns(df, headers):\n",
    "    \"\"\"\n",
    "    Return columns which consist of NAN values\n",
    "    \"\"\"\n",
    "    na_list = []\n",
    "    for head in headers:\n",
    "        if df[head].isnull().values.any():\n",
    "            na_list.append(head)\n",
    "    return na_list\n",
    "\n",
    "print('N/A Columns\\n')\n",
    "print('\\n REP_HIST_SNAPSHOT Features ' + str(len(rep_hist_snapshot_df.columns)) + ': ' + str(get_na_columns(df=rep_hist_snapshot_df,headers=rep_hist_snapshot_df.columns)) + \"\\n\")\n",
    "print('REP_VSQL_PLAN Features ' + str(len(rep_vsql_plan_df.columns)) + ': ' + str(get_na_columns(df=rep_vsql_plan_df,headers=rep_vsql_plan_df.columns)) + \"\\n\")\n",
    "\n",
    "def fill_na(df):\n",
    "    \"\"\"\n",
    "    Replaces NA columns with 0s\n",
    "    \"\"\"\n",
    "    df = df.replace('', 0)\n",
    "    return df.fillna(0)\n",
    "\n",
    "# Populating NaN values with amount '0'\n",
    "rep_hist_snapshot_df = fill_na(df=rep_hist_snapshot_df)\n",
    "rep_vsql_plan_df = fill_na(df=rep_vsql_plan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type conversion\n",
    "\n",
    "Each column is converted into a column of type values which are Integer64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped column [OPERATION]\n",
      "Dropped column [OPTIONS]\n",
      "Dropped column [OBJECT_NODE]\n",
      "Dropped column [OBJECT_OWNER]\n",
      "Dropped column [OBJECT_NAME]\n",
      "Dropped column [OBJECT_ALIAS]\n",
      "Dropped column [OBJECT_TYPE]\n",
      "Dropped column [OPTIMIZER]"
     ]
    }
   ],
   "source": [
    "def handle_numeric_overflows(x):\n",
    "    \"\"\"\n",
    "    Accepts a dataframe column, and \n",
    "    \"\"\"\n",
    "    try:\n",
    "        #df = df.astype('int64')\n",
    "        x1 = pd.DataFrame([x],dtype='int64')\n",
    "    except ValueError:\n",
    "        x = 9223372036854775807 # Max int size\n",
    "    return x\n",
    "\n",
    "for col in rep_vsql_plan_df.columns:\n",
    "    try:\n",
    "        rep_vsql_plan_df[col] = rep_vsql_plan_df[col].astype('int64')\n",
    "    except OverflowError:\n",
    "        \n",
    "        # Handles numeric overflow conversions by replacing such values with max value inside the dataset.\n",
    "        rep_vsql_plan_df[col] = rep_vsql_plan_df[col].apply(handle_numeric_overflows)\n",
    "        rep_vsql_plan_df[col] = rep_vsql_plan_df[col].astype('int64')\n",
    "    except Exception as e:\n",
    "        if col not in black_list:\n",
    "            rep_vsql_plan_df.drop(columns=col, inplace=True)\n",
    "            print('Dropped column [' + col + ']')\n",
    "            \n",
    "print(rep_hist_snapshot_df.columns)\n",
    "print(rep_vsql_plan_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Matrix Shapes\n",
    "\n",
    "Changes dataframe shape, in an attempt to drop all numeric data. Below's aggregated data is done so on:\n",
    "* SNAP_ID\n",
    "* INSTANCE_NUMBER\n",
    "* DBID\n",
    "* SQL_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape Before Aggregation: \" + str(rep_hist_snapshot_df.shape))\n",
    "\n",
    "# Group By Values by SNAP_ID , sum all metrics (for table REP_HIST_SNAPSHOT) and drop all numeric\n",
    "df = rep_hist_snapshot_df.groupby(['SNAP_ID'])['SQL_ID'].apply(list).reset_index()\n",
    "\n",
    "print(\"Shape After Aggregation: \" + str(df.shape))\n",
    "print(type(df))\n",
    "print(df.head(100))\n",
    "\n",
    "print('---------------------------')\n",
    "\n",
    "# Further Aggregation on V$SQL table\n",
    "print('Header Lengths [Before Pivot]')\n",
    "print('REP_VSQL_PLAN: ' + str(len(rep_vsql_plan_df.columns)))\n",
    "# Group By Values by PLAN_HASH_VALUE,TIMESTAMP, sum all metrics (for table REP_VSQL_PLAN\n",
    "rep_vsql_plan_df = rep_vsql_plan_df.groupby(['SQL_ID']).sum()\n",
    "rep_vsql_plan_df.reset_index(inplace=True)\n",
    "print('\\nHeader Lengths [After Pivot]')\n",
    "print('REP_VSQL_PLAN: ' + str(len(rep_vsql_plan_df.columns)) + \"\\n\")\n",
    "#rep_vsql_plan_df.drop(columns=black_list, inplace=True) # This is required since it will impede future aggragate functions to be carried out.\n",
    "print(rep_vsql_plan_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ordering\n",
    "\n",
    "Sorting of datasets in order of SNAP_ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(ascending=True,inplace=True)\n",
    "print(df.shape)\n",
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Selection\n",
    "\n",
    "This sextion treats the dataset as a univariate dataset. Therefore the SNAP_ID pertaining to each set of SQL_IDs is removed, with the intent of future classifiers training solely on past SQL execution activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "del df['SNAP_ID']\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top SQL Identification\n",
    "\n",
    "This section carries out a pruning operation in an attempt to isolate the most expensive of queries within the generated trace.Only the highest expensive queries are retained for the future of the experiment, since it is considered too costly an attempt to try and predict ALL incoming SQL activity.\n",
    "\n",
    "More work concerning Top Consumer Isolation can be found within the following notebook: 'Schedule TPC-DS Top Consumer Profiling'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsolationForestWrapper:\n",
    "    \"\"\"\n",
    "    This class wraps up logic to the Isolation Forest Outlier Detection functionality.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, contamination=.1, parallel_degree=1):\n",
    "        \"\"\"\n",
    "        Constructor Method\n",
    "        \n",
    "        :param X - Pandas Dataframe\n",
    "        :param contamination - Real value\n",
    "        :param parallel_degree - Parellization parameter\n",
    "        \n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.X = X.values\n",
    "        self.model = IsolationForest(n_estimators=100, max_samples=256, contamination=contamination, random_state=0, n_jobs=parallel_degree)\n",
    "        self.model.fit(self.X)\n",
    "        self.scorings = []\n",
    "        print(self.model)\n",
    "        \n",
    "    def __get_threshold_vector(self):\n",
    "        \"\"\"\n",
    "        Calculates a vector threshold, above which will be used to identify outliers. This method is used for evaluating the \n",
    "        trained machine-learning model.\n",
    "        \n",
    "        :return: Numpy vector which represents a threshold vector\n",
    "        \"\"\"\n",
    "        mean = np.mean(self.X)\n",
    "        std = np.std(self.X)\n",
    "        std3 = np.multiply(std, 3)\n",
    "        return np.add(mean, std3)\n",
    "    \n",
    "    def __calculate_expected_labels(self):\n",
    "        \"\"\"\n",
    "        Estimates label clustering by comparing them to a threshold mean value. These labels will be used to gauge a scoring \n",
    "        for the unsupervised clustering achieved by the IForest algorithm.\n",
    "        \n",
    "        :return: A list of the expected output labels.\n",
    "        \"\"\"\n",
    "        mean_vect = self.__get_threshold_vector()\n",
    "        mean_labels = []\n",
    "        for vector in self.X:\n",
    "            if np.greater(vector, mean_vect).any():\n",
    "                mean_labels.append(-1)\n",
    "            else:\n",
    "                mean_labels.append(1)\n",
    "        return mean_labels\n",
    "    \n",
    "    def retrieve_scorings(self):\n",
    "        \"\"\"\n",
    "        This method retrieves the per vector IForest scorings, after the model has been trained.\n",
    "        \n",
    "        :return: List of Iforest scorings\n",
    "        \"\"\"\n",
    "        return self.model.decision_function(self.X)\n",
    "    \n",
    "    def plot_scorings(self):\n",
    "        \"\"\"\n",
    "        Distributes into 50 bin histogram.\n",
    "        \n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        scores = self.retrieve_scorings()\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.hist(scores, bins=50);\n",
    "        plt.title('Isolation Forest Scorings')\n",
    "        plt.show()\n",
    "    \n",
    "    def predict_labels(self):\n",
    "        \"\"\"\n",
    "        Caries out predicton on feature matrix 'X'\n",
    "        \n",
    "        :return: List of predicted output labels.\n",
    "        \"\"\"\n",
    "        return self.model.predict(self.X) \n",
    "    \n",
    "    def predict_labels(self, X):\n",
    "        \"\"\"\n",
    "        Caries out predicton on feature matrix 'X'\n",
    "        \n",
    "        :return: List of predicted output labels.\n",
    "        \"\"\"\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def outlier_score_accuracy(self):\n",
    "        \"\"\"\n",
    "        Returns a score which evaluates the accuracy with the number of isolated outliers. The closer to 0 the score, the more accurate the evaluation\n",
    "        \n",
    "        :return: Positive Integer (Squared and Square Rooted) denoting the delta scoring between predicted and actual\n",
    "        \"\"\"\n",
    "        if self.scorings is None or len(self.scorings) == 0:\n",
    "            raise ValueError('Scorings list is empty!')\n",
    "        elif len(self.scorings) > 2:\n",
    "            raise ValueError('Scorings list length is greater than 2! Must be composed of the following structure [scoring1, scoring2]')\n",
    "        \n",
    "        return math.sqrt((self.scorings[1] - self.scorings[0])**2)\n",
    "    \n",
    "    def evaluate_labels(self):\n",
    "        \"\"\"\n",
    "        This function calculates the expected inlier and outlier vectors based on a statistical threshold, and then matches\n",
    "        these expectations to the IForest predictions. Results are plotted, and gauge by scored ROC score, and lowest error delta\n",
    "        \n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        y = self.__calculate_expected_labels()\n",
    "        yhat = self.predict_labels()\n",
    "        \n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        print('Expected Label Distribution')\n",
    "        for i in range(len(unique)):\n",
    "            print('Label [' + str(unique[i]) + '] -> Count [' + str(counts[i]) + ']')\n",
    "            if unique[i] == -1:\n",
    "                self.scorings.append(counts[i])\n",
    "        unique, counts = np.unique(yhat, return_counts=True)\n",
    "        print('Isolated Label Distribution')\n",
    "        for i in range(len(unique)):\n",
    "            print('Label [' + str(unique[i]) + '] -> Count [' + str(counts[i]) + ']')\n",
    "            if unique[i] == -1:\n",
    "                self.scorings.append(counts[i])\n",
    "        \n",
    "        print(\"\\n----\\nAccuracy: \" + str(accuracy_score(y, yhat)))\n",
    "        print(\"F-Score: \" + str(f1_score(y, yhat, average='binary')))\n",
    "        print('---')\n",
    "        print(\"Outlier Score Precision [\" + str(self.outlier_score_accuracy()) + \"]\")\n",
    "        \n",
    "        fpr_RF, tpr_RF, thresholds_RF = roc_curve(y, yhat)\n",
    "        print(fpr_RF)\n",
    "        print(tpr_RF)\n",
    "        auc_RF = roc_auc_score(y, yhat)\n",
    "        print('AUC RF:%.3f'% auc_RF)\n",
    "        plt.plot(fpr_RF, tpr_RF,'r-',label = 'RF AUC: %.3f'%auc_RF)\n",
    "        plt.plot([0,1],[0,1],'k-',label='random')\n",
    "        plt.plot([0,0,1,1],[0,1,1,1],'g-',label='perfect')\n",
    "        plt.legend()\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.show()\n",
    "        \n",
    "ifw = IsolationForestWrapper(X=rep_vsql_plan_df[y_label], contamination=contamination, parallel_degree=parallel_degree)\n",
    "ifw.plot_scorings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stripping Inlier SQL_ID's\n",
    "\n",
    "All inliers SQL_IDs are stripped away, whilst those predicted as outliers are retained for the continuation of this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_ids = np.unique(rep_vsql_plan_df['SQL_ID'].values)\n",
    "sql_map = {}\n",
    "for sql in sql_ids:\n",
    "    df_plan = rep_vsql_plan_df.loc[rep_vsql_plan_df['SQL_ID'] == sql]\n",
    "    plan_costings = df_plan[y_label]\n",
    "    sql_map[sql] = ifw.predict_labels(plan_costings.values)[0]\n",
    "print(sql_map)\n",
    "\n",
    "outlier_ids = []\n",
    "for key, value in sql_map.items():\n",
    "    if value == -1:  # -1 Denotes Outliers, as predicted by the isolation forst\n",
    "        outlier_ids.append(key)\n",
    "print('Outlier SQL_IDs: \\n' + str(outlier_ids))\n",
    "\n",
    "for index, row_sql_ids in df.iterrows():\n",
    "    snap_list = []\n",
    "    for sql_id in row_sql_ids['SQL_ID']:\n",
    "        if sql_id in outlier_ids:\n",
    "            snap_list.append(sql_id)\n",
    "    df['SQL_ID'].iloc[index] = snap_list\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding\n",
    "\n",
    "Since this experiment deals with prediction of upcoming SQL_IDs, respectice SQL_ID strings need to labelled as a numeric representation. Label Encoder will be used here to convert SQL_ID's into a numeric format, which are in turn used for training. Evaluation (achieved predictions) is done so also in numeric format, at which point the label encoder is eventually used to decode back the labels into the original, respetive SQL_ID representation.\n",
    "\n",
    "This section of the experiment additionally converts the targetted label into a binarized version of the previous achieved categorical numeric values.\n",
    "\n",
    "* https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html\n",
    "\n",
    "NB: Since this experiment is solely focussed on Random Forest Training, One-Hot Encoding will not be used as recommended below:\n",
    "* https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder:\n",
    "    \"\"\"\n",
    "    Scikit Label Encoder was acting up with the following error whilst using the transform function, even though I tripled \n",
    "    checked that the passed data was exactly the same as the one used for training:\n",
    "    \n",
    "    * https://stackoverflow.com/questions/46288517/getting-valueerror-y-contains-new-labels-when-using-scikit-learns-labelencoder\n",
    "    \n",
    "    So I have rebuilt a similar functionality to categorize my data into numeric digits, as the LabelEncoder is supposed to do.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.__class_map = {}\n",
    "        self.__integer_counter = 0\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        :param - X: python list\n",
    "        \"\"\"\n",
    "        for val in X:\n",
    "            if val not in self.__class_map:\n",
    "                self.__class_map[val] = self.__integer_counter\n",
    "                self.__integer_counter += 1\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        param - X: python list\n",
    "        \"\"\"\n",
    "        encoded_map = []\n",
    "        for val in X:\n",
    "            if val in self.__class_map:\n",
    "                value = self.__class_map[val]\n",
    "                encoded_map.append(value)\n",
    "            else:\n",
    "                raise ValueError('Label Mismatch - Encountered a label which was not trained on.')\n",
    "        return encoded_map\n",
    "    \n",
    "    def get_class_map(self):\n",
    "        \"\"\"\n",
    "        Returns original classes as a list\n",
    "        \"\"\"\n",
    "        class_map = []\n",
    "        for key, value in self.__class_map.items():\n",
    "            class_map.append(key)\n",
    "        return class_map\n",
    "    \n",
    "    def get_encoded_map(self):\n",
    "        \"\"\"\n",
    "        Returns class encodings as a list\n",
    "        \"\"\"\n",
    "        encoded_map = []\n",
    "        for key, value in self.__class_map.items():\n",
    "            encoded_map.append(value)\n",
    "        return encoded_map\n",
    "    \n",
    "    def get_map(self):\n",
    "        return self.__class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.head(10))\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Train to SQL Encoder\n",
    "for index, row in df.iterrows():\n",
    "    sql_id_list = row['SQL_ID']\n",
    "    le.fit(sql_id_list)\n",
    "    \n",
    "# Transform SQL_IDs using above trained encoder\n",
    "for index, row in df.iterrows():\n",
    "    sql_id_list = row['SQL_ID']\n",
    "    transformed_list = le.transform(sql_id_list)\n",
    "    df['SQL_ID'].iloc[index] = transformed_list \n",
    "\n",
    "print(\"\\n----------------------------------\\n\\nAvailable Classes:\")\n",
    "print('Total SQL_ID Classes: ' + str(len(le.get_class_map())))\n",
    "print(le.get_class_map()[:10])\n",
    "print(df.shape)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization\n",
    "\n",
    "A note regarding normalization. Normalization for this experiment was purposely skipped, since value dimensionality & size is not as important for RandomForest based models. The purity split  does not benefit greatly from such a process:\n",
    "\n",
    "* https://stats.stackexchange.com/questions/57010/is-it-essential-to-do-normalization-for-svm-and-random-forest\n",
    "* https://stackoverflow.com/questions/8961586/do-i-need-to-normalize-or-scale-data-for-randomforest-r-package\n",
    "* https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/1471-2105-8-25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Padding\n",
    "\n",
    "Since there isn't a fixed number of SQL_ID's per SNAP_ID, each set of SQL_IDs need to be padded so as to assume an equal number if SQL_IDs for the purpose of model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length at index 0: \" + str(len(df['SQL_ID'].iloc[0])))\n",
    "print(df['SQL_ID'].iloc[0])\n",
    "print(\"Length at index 1: \" + str(len(df['SQL_ID'].iloc[1])))\n",
    "print(df['SQL_ID'].iloc[1])\n",
    "print(\"Length at index 2: \" + str(len(df['SQL_ID'].iloc[2])))\n",
    "print(df['SQL_ID'].iloc[2])\n",
    "\n",
    "# Retrieve largest length\n",
    "def pad_datamatrix(df):\n",
    "    \"\"\"\n",
    "    Iterates over dataframe and pads SQL_ID lists accordingly with -1 values, denoting empty SQL_ID slots.\n",
    "    \"\"\"\n",
    "    row_sizes = []\n",
    "    for index, row in df.iterrows():\n",
    "        row_sizes.append(len(row['SQL_ID']))\n",
    "    max_row_size = max(row_sizes)\n",
    "    \n",
    "    # Pad Dataframe Values\n",
    "    i = 0\n",
    "    for index, row in df.iterrows():\n",
    "        length = len(row['SQL_ID'])\n",
    "        diff = max_row_size - length\n",
    "        if diff != 0:\n",
    "            for j in range(length, max_row_size):\n",
    "                df['SQL_ID'].iloc[i] = np.append(df['SQL_ID'].iloc[i], -1) # Appends -1 to padded values\n",
    "        # print(\"Length at index \" + str(i) + \": \" + str(df['SQL_ID'].iloc[i].size))\n",
    "        i += 1\n",
    "    return df\n",
    "\n",
    "df = pad_datamatrix(df)\n",
    "\n",
    "print('\\n\\n------------------------------------------\\n\\n')\n",
    "print(\"Length at index 0: \" + str(len(df['SQL_ID'].iloc[0])))\n",
    "print(df['SQL_ID'].iloc[0])\n",
    "print(\"Length at index 1: \" + str(len(df['SQL_ID'].iloc[1])))\n",
    "print(df['SQL_ID'].iloc[1])\n",
    "print(\"Length at index 2: \" + str(len(df['SQL_ID'].iloc[2])))\n",
    "print(df['SQL_ID'].iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand Feature Lists\n",
    "\n",
    "Expand Feature Lists, where in each list element is represented as it's own features. Total feature count here equates as follows:\n",
    "\n",
    "* Features = (lag * SQL_ID per SNAP_ID count) + SQL_ID per SNAP_ID count\n",
    "* Labels = lag * SQL_ID per SNAP_ID count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence2features(df):\n",
    "    \"\"\"\n",
    "    Converts pandas sequences into full fledged columns/features\n",
    "    \"\"\"\n",
    "    feature_count = len(df[df.columns[0]].iloc[0])\n",
    "    for column_name in df.columns:\n",
    "        data_matrix = []\n",
    "        new_values = df[column_name].values\n",
    "        \n",
    "        new_values = np.stack(new_values, axis=0 )\n",
    "        \n",
    "        for i in range(1,feature_count+1):\n",
    "            new_column_name = column_name + \"_\"+str(i)\n",
    "            df[new_column_name] = new_values[:,i-1]\n",
    "        \n",
    "        # Drop original list columns\n",
    "        df.drop(column_name, inplace=True, axis=1)\n",
    "    return df\n",
    "\n",
    "print('Features')\n",
    "print('Before: ' + str(df.shape))\n",
    "df = sequence2features(df=df)\n",
    "print('After: ' + str(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "\n",
    "One hot encoding target labels for deep learning application\n",
    "\n",
    "* https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEncoder:\n",
    "    \n",
    "    def __init__(self, classes):\n",
    "        self.__mapper = pd.DataFrame(columns=classes)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        class_types = self.__mapper.columns\n",
    "        for row in X:\n",
    "            temp_row = []\n",
    "            for i in range(len(class_types)):\n",
    "                if class_types[i] in row:\n",
    "                    temp_row.append(float(1))\n",
    "                else:\n",
    "                    temp_row.append(float(0))\n",
    "            self.__mapper.loc[len(self.__mapper)] = temp_row\n",
    "        return self.__mapper\n",
    "    \n",
    "    def get_classes(self):\n",
    "        return self.__mapper.columns\n",
    "    \n",
    "    def get_unique_values(self):\n",
    "        return np.unique(self.__mapper.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding train data\n",
    "ohe = OneHotEncoder(classes=le.get_encoded_map())\n",
    "print('Training Data:')\n",
    "print(\"Before One Hot Encoding: \" + str(df.shape))\n",
    "df = ohe.fit_transform(X=df.values)\n",
    "print(\"After One Hot Encoding: \" + str(df.shape))\n",
    "print(df)\n",
    "print('Value type: ' + str(ohe.get_unique_values()))\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Shifting\n",
    "\n",
    "Shifting the datasets N lag minutes, in order to transform the problem into a supervised dataset. Each Lag Shift equates to 60 seconds (due to the way design of the data capturing tool). For each denoted lag amount, the same number of feature vectors will be stripped away at the beginning.\n",
    "\n",
    "Features and Labels are separated into seperate dataframes at this point.\n",
    "\n",
    "https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = data\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    if n_in != 0:\n",
    "        for i in range(n_in, 0, -1):\n",
    "            cols.append(df.shift(i))\n",
    "            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    n_out += 1\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "def remove_n_time_steps(data, n=1):\n",
    "    if n == 0:\n",
    "        return data\n",
    "    df = data\n",
    "    headers = df.columns\n",
    "    dropped_headers = []\n",
    "    \n",
    "    for i in range(1,n+1):\n",
    "        for header in headers:\n",
    "            if \"(t+\"+str(i)+\")\" in header:\n",
    "                dropped_headers.append(str(header))\n",
    "    \n",
    "    return df.drop(dropped_headers, axis=1) \n",
    "\n",
    "# Frame as supervised learning set\n",
    "shifted_df = series_to_supervised(df, lag, lag)\n",
    "\n",
    "# Seperate labels from features\n",
    "y_row = []\n",
    "for i in range(lag+1,(lag*2)+2):\n",
    "    y_df_column_names = shifted_df.columns[len(df.columns)*i:len(df.columns)*i + 1]\n",
    "    y_row.append(y_df_column_names)\n",
    "y_df_column_names = []   \n",
    "for row in y_row:\n",
    "    for val in row:\n",
    "        y_df_column_names.append(val)\n",
    "\n",
    "# y_df_column_names = shifted_df.columns[len(df.columns)*lag:len(df.columns)*lag + len(y_label)]\n",
    "y_df = shifted_df[y_df_column_names]\n",
    "#X_df = shifted_df\n",
    "X_df = shifted_df.drop(columns=y_df_column_names)\n",
    "print('\\n-------------\\nFeatures')\n",
    "print(X_df.columns)\n",
    "print(X_df.shape)\n",
    "print('\\n-------------\\nLabels')\n",
    "print(y_df.columns)\n",
    "print(y_df.shape)\n",
    "\n",
    "# Delete middle timesteps\n",
    "# X_df = remove_n_time_steps(data=X_df, n=lag)\n",
    "# print('\\n-------------\\nFeatures After Time Shift')\n",
    "# print(X_df.columns)\n",
    "# print(X_df.shape)\n",
    "# # y_df = remove_n_time_steps(data=y_df, n=lag)\n",
    "# print('\\n-------------\\nLabels After Time Shift')\n",
    "# print(y_df.columns)\n",
    "# print(y_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Based Model\n",
    "\n",
    "### RandomForest Classification (Many To Many)\n",
    "\n",
    "Classification attemps using RFC - https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "Model Input - Takes training data in the form of past SQL_ID sequences (stretched using a lag parameter), and trains on a number of past sequence histories, determined by the lag value.\n",
    "\n",
    "Model Output - Outpus future SQL_ID sequences, determined by the lag output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "class RandomForest:\n",
    "    \"\"\"\n",
    "    Random Forest Class (Regression + Classification)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_estimators, max_depth, parallel_degree, lag, max_features='sqrt'):\n",
    "        \"\"\"\n",
    "        Constructor method for RandomForest wrapper\n",
    "        :param: n_estimators    - Integer denoting number of decision making forests utilized by inner forests.\n",
    "        :param: max_depth       - Integer denoting tree purity cut off.\n",
    "        :param: parallel_degree - Integer denoting model parallel degree.\n",
    "        :param: y_label         - List columns consisting of labels.\n",
    "        :param: lag             - Integer denoting lag value.\n",
    "        :param: max_features    - String denoting the max amount of features to consider.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.__lag = lag\n",
    "        self.__n_estimators = n_estimators\n",
    "        self.__max_depth = max_depth\n",
    "        self.__parallel_degree = parallel_degree\n",
    "        self.__max_features = max_features\n",
    "        self.__model = RandomForestClassifier(max_depth=self.__max_depth,\n",
    "                                              n_estimators=self.__n_estimators,\n",
    "                                              n_jobs=self.__parallel_degree,\n",
    "                                              max_features=self.__max_features)\n",
    "\n",
    "    def fit_model(self, X, y):\n",
    "        \"\"\"\n",
    "        This method fits training data to target labels\n",
    "        :param: X - Numpy array consisting of input feature vectors\n",
    "        :param: y - Numpy array consisting of output label vectors\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.__model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        This method predicts the output labels based on the input feature vectors\n",
    "        :param: X - Numpy array consisting of input feature vectors\n",
    "        :return: Numpy array consisting of output label vectors\n",
    "        \"\"\"\n",
    "        yhat = self.__model.predict(X)\n",
    "        return yhat\n",
    "\n",
    "#     def evaluate(self, y, yhat, plot=False):\n",
    "#         \"\"\"\n",
    "#         Evaluates y vs yhat\n",
    "#         :param: y    - Numpy array consisting of output label vectors (Test Set)\n",
    "#         :param: yhat - Numpy array consisting of output label vectors (Prediction Set)\n",
    "#         :param: plot - Boolean value denoting whether this function should plot out it's evaluation\n",
    "#         :return: None\n",
    "#         \"\"\"\n",
    "#         if self.__mode == 'regression':\n",
    "\n",
    "#             # RMSE Evaluation\n",
    "#             rmse = math.sqrt(mean_squared_error(y, yhat))\n",
    "#             if not plot:\n",
    "#                 return rmse\n",
    "#             print('Test RFR: %.3f\\n-----------------------------\\n\\n' % rmse)\n",
    "\n",
    "#         elif self.__mode == 'classification':\n",
    "\n",
    "#             y = BinClass.discretize_value(y, bin_value)\n",
    "#             yhat = BinClass.discretize_value(yhat, bin_value)\n",
    "#             y = y.flatten()\n",
    "#             yhat = yhat.flatten()\n",
    "\n",
    "#             # Evaluation\n",
    "#             print(y)\n",
    "#             print(yhat)\n",
    "#             accuracy = accuracy_score(y, yhat)\n",
    "#             f1 = f1_score(y,\n",
    "#                           yhat,\n",
    "#                           average='macro')  # Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "#             print('Accuracy [' + str(accuracy) + ']')\n",
    "#             print('FScore [' + str(f1) + ']')\n",
    "\n",
    "#             if not plot:\n",
    "#                 return accuracy, f1\n",
    "\n",
    "#         if plot:\n",
    "#                 plt.rcParams['figure.figsize'] = [20, 15]\n",
    "#                 plt.plot(y, label='actual')\n",
    "#                 plt.plot(yhat, label='predicted')\n",
    "#                 plt.legend(['actual', 'predicted'], loc='upper left')\n",
    "#                 plt.title('Actual vs Predicted')\n",
    "#                 plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def write_results_to_disk(path, iteration, lag, test_split, max_depth, max_features, rmse, accuracy,\n",
    "                              f_score, time_train):\n",
    "        \"\"\"\n",
    "        Static method which is used for test harness utilities. This method attempts a grid search across many\n",
    "        trained RandomForest models, each denoted with different configurations.\n",
    "        Attempted configurations:\n",
    "        * Varied lag projection\n",
    "        * Varied data test split\n",
    "        * Varied forest n_estimators\n",
    "        Each configuration is denoted with a score, and used to identify the most optimal configuration.\n",
    "\n",
    "        :param: path         - String denoting path towards result csv output\n",
    "        :param: iteration    - Integer denoting test iteration (Unique per test configuration)\n",
    "        :param: lag          - Integer denoting lag value\n",
    "        :param: test_split   - Float denoting data sample sizes\n",
    "        :param: max_depth    - Integer denoting max number tree nodes to consider. This param can be 'None'.\n",
    "        :param: max_features - String denoting amount of feature subset to consider.\n",
    "        :param: rmse         - (Float) Float denoting experiment configuration RSME score.\n",
    "        :param: accuracy     - (Float) Float denoting experiment accuracy score.\n",
    "        :param: fscore       - (Float) Float denoting experiment fscore score.\n",
    "        :param: time_train   - Integer denoting number of seconds taken by LSTM training iteration\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        file_exists = os.path.isfile(path)\n",
    "        with open(path, 'a') as csvfile:\n",
    "            headers = ['iteration', 'lag', 'test_split', 'max_depth', 'max_features', 'rmse', 'accuracy', 'f_score', 'time_train']\n",
    "            writer = csv.DictWriter(csvfile, delimiter=',', lineterminator='\\n', fieldnames=headers)\n",
    "            if not file_exists:\n",
    "                writer.writeheader()  # file doesn't exist yet, write a header\n",
    "            writer.writerow({'iteration': iteration,\n",
    "                             'lag': lag,\n",
    "                             'test_split': test_split,\n",
    "                             'max_depth': max_depth,\n",
    "                             'max_features': max_features,\n",
    "                             'rmse': rmse,\n",
    "                             'accuracy': accuracy,\n",
    "                             'f_score': f_score,\n",
    "                             'time_train': time_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Training is carried out on half the trace dataset, which equates to about 7 days. The rest is left out, so as to validate the model's accuracy and f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, y_train, y_validate = train_test_split(X_df, y_df, test_size=test_split)\n",
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "X_validate = X_validate.values\n",
    "y_validate = y_validate.values\n",
    "\n",
    "# Train on discrete data (Train > Validation)\n",
    "model = RandomForest(n_estimators=n_estimators,\n",
    "                     parallel_degree=parallel_degree,\n",
    "                     max_depth=max_depth,\n",
    "                     lag=lag,\n",
    "                     max_features=max_features)\n",
    "model.fit_model(X=X_train,\n",
    "                y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "The remaining left out data (the other half of t he dataset) is used to validate the trained model. This validation set equates to 7 days worth of data points. Below's test replicates a 7 day distribution, wherein the accuracy and f1 score of the model are evaluated at the end of each day, fit to the model in an online manner, and the process repeated for each of the following days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 7\n",
    "accuracy_per_day, f1score_per_day = [], []\n",
    "for i in range(0, n):\n",
    "\n",
    "    print('Day ' + str(i + 1))\n",
    "\n",
    "    # Segregate data for specific day\n",
    "    X_validate_temp = X_validate[\n",
    "                      (int(X_validate.shape[0] / n) * i):(int(X_validate.shape[0] / n) * (i + 1)), :]\n",
    "    y_validate_temp = y_validate[\n",
    "                      (int(y_validate.shape[0] / n) * i):(int(y_validate.shape[0] / n) * (i + 1)), :]\n",
    "    print('Feature vectors: ' + str(X_validate_temp.shape))\n",
    "    print('Label vectors: ' + str(y_validate_temp.shape))\n",
    "\n",
    "    y_list, yhat_list = [], []\n",
    "    for i in range(0, X_validate_temp.shape[0]):\n",
    "\n",
    "        X = X_validate_temp[i, :]\n",
    "        X = X.reshape(1, -1)\n",
    "        # X = X.reshape((int(X.shape[0] / lag), lag, X.shape[1]))\n",
    "        y = np.array(y_validate_temp[i, :])\n",
    "        yhat = model.predict(X)\n",
    "\n",
    "        y = y.reshape(1, -1)\n",
    "        model.fit_model(X=X,\n",
    "                        y=y)  # Online Learning, Training on validation predictions.\n",
    "\n",
    "        y = y.flatten()\n",
    "        yhat = yhat.flatten()\n",
    "        y_list.append(y)\n",
    "        yhat_list.append(yhat)\n",
    "\n",
    "    y_list = np.array(y_list)\n",
    "    yhat_list = np.array(yhat_list)\n",
    "    \n",
    "    acc_score_list, f1_score_list = [], []\n",
    "    for i in range(y_list.shape[1]):\n",
    "        acc = accuracy_score(y_list[:, i], yhat_list[:, i])\n",
    "        f1 = f1_score(y_list[:, i], yhat_list[:, i], average='binary')\n",
    "        acc_score_list.append(acc)\n",
    "        f1_score_list.append(f1)\n",
    "    accuracy_per_day.append(sum(acc_score_list) / len(acc_score_list))\n",
    "    f1score_per_day.append(sum(f1_score_list) / len(f1_score_list))\n",
    "    print('Averaged Day ' + str(i+1) + ' Accuracy: ' + str(sum(accuracy_per_day)/len(accuracy_per_day)) + '\\nF1Score: ' + str(sum(f1score_per_day)/len(f1score_per_day)) + '\\n--------------------------')\n",
    "    print('-' * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring per day\n",
    "\n",
    "The following plot exhibits the general effectiveness of the model over the subsequent week upon which it was tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "plt.plot(accuracy_per_day, label='accuracy')\n",
    "plt.plot(f1score_per_day, label='f1score')\n",
    "plt.legend(['accuracy', 'f1score'], loc='upper left')\n",
    "plt.xlabel('Distribution over days')\n",
    "plt.ylabel('Score')\n",
    "plt.title(tpcds + ' model scoring over subsequent week')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
